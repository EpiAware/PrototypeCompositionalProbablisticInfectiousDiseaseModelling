---
title: "A Prototype for Compositional Probabilistic Infectious Disease Modelling"
authors:
  - name: "Samuel P. C. Brand"
    affiliations:
      - ref: cdc
    email: "usi1@cdc.gov"
    orcid: "0000-0003-0645-5367"
  - name: "Samuel Abbott"
    affiliations:
      - ref: lshtm
    email: "sam.abbott@lshtm.ac.uk"
    orcid: "0000-0001-8057-8037"
    corresponding: true

affiliations:
  - id: cdc
    name: "Center for Forecasting and Outbreak Analysis; Centers for Disease Control"
  - id: lshtm
    name: "Centre for Mathematical Modelling of Infectious Diseases, London School of Hygiene & Tropical Medicine"
date: today
abstract: |
  Recent outbreaks of Ebola, COVID-19 and mpox have demonstrated the value of modelling for synthesising data for rapid evidence to inform decision making. Effective models require integration of expert domain knowledge from clinical medicine, environmental science, behavioural research, and public health to accurately capture transmission processes, yet current modelling approaches create barriers to this integration. Methods used to synthesise available data broadly fall into pipeline approaches that chain separate models together, or joint models that are often monolithic and difficult to adapt. These barriers have prevented advances across multiple settings where models could have provided actionable insights. Composable models where components can be reused across different contexts and combined in various configurations whilst maintaining statistical rigour could address these limitations. In this work, we start by outlining the key requirements for a composable infectious disease modelling framework and then present a prototype that addresses these requirements through composable epidemiological components built on Julia's type system and Turing.jl. Our approach enables "LEGO-like" model construction where complex models emerge from composing simpler, reusable components. Through three case studies using the prototype, we show how components can be reused across different models whilst maintaining statistical rigour. The first replicates a COVID-19 analysis for South Korea using renewal processes with time-varying reproduction numbers. The second extends these components with reporting delays and day-of-week effects for real-time nowcasting applications. The third integrates ODE solvers for compartmental disease transmission models applied to influenza outbreak data. Across all case studies, the same core components combine differently to address distinct epidemiological questions. We explore other potential options and compare them to our proposed approach. The prototype demonstrates promise but future work is needed to solve remaining composability challenges, expand the component library, and integrate bridges to existing epidemiological software ecosystems.
---

# Introduction {#sec-introduction}

Recent outbreaks of Ebola, COVID-19 and mpox have demonstrated the value of modelling for synthesising data for rapid evidence to inform decision making [@whitty2015what].
Infectious diseases spread through complex interactions between biology, human behaviour, economic factors, and environmental conditions that must all be understood to control transmission effectively.
Effective models require integration of expert domain knowledge from clinical medicine, environmental science, behavioural research, and public health to accurately capture these multifaceted transmission processes, yet current modelling frameworks create barriers to this essential integration.
Individual-level data such as viral loads, biomarkers, genomic sequences, and clinical observations are routinely ignored or aggregated when informing population-level models, losing information that could improve decisions.
These barriers have prevented advances in settings where models could have provided actionable insights such as early outbreak analysis, wastewater surveillance, phylodynamics, clinical biomarkers, pooled testing, and large-scale clinical datasets.
The next infectious disease threat is unpredictable and may be exacerbated by climate change [@Tsui2024-gy], requiring adaptable response capabilities that can rapidly incorporate diverse data sources and domain expertise.

Methods used to synthesise available data in real time broadly fall into two classes: either combining results from multiple, smaller models calibrated in isolation (the pipeline approach, e.g., [@huisman2022]), or representing a single model tuned to the specific scenario (the joint model approach, e.g., [@birrell2024; @Watson2024-vj]).
Both approaches have significant downsides.
Pipeline approaches combine results from separate models without uncertainty propagation, leading to loss of detail and statistical rigour [@lison2024].
Joint approaches use single monolithic models that, whilst powerful in their ability to systematically integrate multiple processes and data streams, are too complex to enable transfer to other settings or extension with additional model components.
To adapt or extend such models, analysts need to fully comprehend all parts of the corresponding model and code, creating barriers to sharing methodology and leading to inefficient re-implementation when parts of a model could, in principle, be re-used.
Attempts to include insights from environmental scientists, economists, or behavioural researchers typically result in models that are either too complex to use practically or too simplified to capture valuable expertise.
This prevents effective integration of expertise across disciplines.
Transfer of methodology between outbreak events has proven difficult, with each posing unanticipated challenges that existing tools cannot accommodate.

Recent developments in computational statistics and scientific computing demonstrate the potential for composable approaches where components can be reused across different contexts and combined in various configurations whilst maintaining statistical rigour that could address these limitations.
Advances in Turing.jl have introduced submodel interfaces that enable composable probabilistic programming, providing a pathway for epidemiological model composition, though initial epidemiological applications revealed interoperability challenges [@Nicholson2022-ua; @fjelde2025turin].
Category theory provides the underlying mathematical frameworks for this composability through operadic composition in hierarchical model construction [@libkind2022algebraic].
The algebraic Julia ecosystem has applied these theoretical foundations to scientific computing, with HydroModels.jl and ModelingToolkit.jl demonstrating how abstract backends can support mixed equation types including differential-algebraic equations, partial differential equations, and stochastic differential equations through unified interfaces [@modelingtoolkit2021].
SpeedyWeather.jl uses an alternative approach, demonstrating "LEGO-like" atmospheric modelling with interactive domain-specific languages that enable modular component assembly [@speedyweather2024].
The key insight underlying these approaches is the separation of syntax (composition) from semantics (computation), enabling modularity and independence of components whilst maintaining mathematical rigour.

This paper presents a prototype that combines the modularity of pipeline approaches with the statistical rigour of joint models through composable epidemiological components.
Our approach enables "LEGO-like" model decisions through standardised interfaces [@speedyweather2024].
The prototype supports composability beyond ordinary differential equations, accommodating mixed equation types and the potential for different computational backends.
We implement this as a domain-specific language operating intended to be implemented as optional package extensions.
We demonstrate our approach using an autoregressive model example to illustrate the proposed compositional pattern and component swapping capabilities.
Through three case studies using the prototype, we show how components can be reused across different models: the first is inspired by @mishra2020covid; the second reuses components from the first, along with new elements, inspired by @epinow2; the third is inspired by @chatzilena2019contemporary, again reusing components, alongside the use of an ODE.
Finally, we discuss alternative design approaches, evaluate the strengths and limitations of our compositional approach, and identify key areas for future development.

# Prototype Implementation {#sec-approach}

## Requirements for Composable Infectious Disease Modelling {#sec-requirements}

Modelling infectious disease dynamics requires quantifying uncertainty at every level because decisions must account for incomplete knowledge about individual infection risk, transmission dynamics, and observation processes.
A clear separation between distinct model components, infection processes, observation processes, and latent dynamics is also key as these allows reasoning on each of these components separately.
Because diseases affect populations heterogeneously across age, location, and risk groups, the framework needs to be able to support arbitrary stratification schemes for all components.
These stratified models must also remain data-agnostic as this allows the model to be generalised to different datasets, tested based on just its prior specification, and used for forecasting.
Similarly, the book work of supporting multiple strata needs to be abstracted from the user to make the system easier to use but at the same time they need to be able to model relationships between strata in order to support partial pooling of parameters for sparse data settings.
To allow for models to be validated, the framework must support nesting models within models and programming over model structure itself, allowing simple components to compose into sophisticated models while remaining individually interrogable for debugging, validation, and mechanistic understanding.
This compositional approach requires a clear, concise modelling language so that it can be used by a wide pool of users and so that model specifications can be written quickly but with clarity.
Supporting modern inference methods is important so that complex models can be fit and this necessitates gradient computation throughout via automatic differentiation.
It is also important to allow for a wide range of inference methods so that the best approach for a given model/data combination can be used.
This means supporting abstract back-ends that seamlessly switch between inference approaches.

We also need to have model components that encapsulate both structure and prior distributions so that domain experts can contribute specialised knowledge: a virologist's understanding of within-host dynamics, an epidemiologist's of contact patterns, a clinician's of disease progression insights without reviewing the entire modelling framework.
Standardised interfaces between components are needed to allow individual components to work together, to support handling of multiple strata, and to allow for proper uncertainty propagation.
As there are a range of different potential ways to express infectious disease models including ordinary differential equations, agent-based models, network models, stochastic processes, and discrete time models these all need to be supported both independently and in combination.
Importantly, the design must enable incremental adoption without requiring complete rebuilds of existing models, and components should remain functional as standalone tools outside the compositional framework to maximise their utility and adoption.
Finally, we need a framework that can be composed with out of domain approaches and expertise, such as neural networks, Gaussian processes, and other machine learning approaches.

## Our approach {#sec-design}

Meeting these requirements requires programming with probabilities, for which probabilistic programming languages are designed.
We also need a probabilistic programming language that supports automatic differentiation for modern inference, the ability to program over model structure itself to enable model nesting and composition, and crucially access to as wide an ecosystem as possible to avoid lock-in and enable integration with existing scientific computing tools.
As far as we are aware, only probabilistic programming languages built in Julia provide the metaprogramming capabilities needed to create domain-specific abstractions that can handle arbitrary stratification, standardised interfaces between components, and programming over the model structure.
Among Julia's options, Turing.jl best meets our requirements with mature submodel support for nesting models within models, extensive inference algorithm choices, and it's implementation as a light abstraction layer on top of the wider Julia ecosystem.
Additional benefits of Julia include eliminating the two-language problem, leveraging multiple dispatch for clean component composition, and accessing the mature SciML ecosystem for differential equations and other scientific computing tools.

Our approach uses a two-layer architecture with high-level domain-specific language (DSL) for epidemiological modelling and a low-level implementation using Turing.jl (though importantly we are not locked in to this choice as the DSL is agnostic of the backed used).
This separation enables incremental adoption without rebuilding existing models to use our DSL, with all components remaining functional as standalone tools outside the compositional framework.
The domain-specific language layer provides clear, concise model specification using epidemiological concepts, enabling domain experts to contribute components encapsulating their specialised knowledge without understanding the full framework.
The backend layer handles the automated bookkeeping of stratification, interface validation, and uncertainty propagation whilst supporting multiple inference approaches and auto differentiation options by leveraging the Turing.jl and wider Julia ecosystems.
Alternative approaches using category theory or symbolic-numeric frameworks remain accessible through Julia's interoperability and could be made parts of future backends [@libkind2022algebraic; @modelingtoolkit2021].

## Domain-Specific Language Structure {#sec-dsl}

<!-- Reference to Panel A of Figure 1 -->

Our prototype domain-specific language builds on Julia's type system to enable composable epidemiological modelling through two key design patterns.
First, abstract types define interfaces that implementations must follow, analogous to contracts specifying what operations a model component must support rather than how it implements them.
All model components inherit from a parent `AbstractModel` type, establishing a common foundation whilst allowing specialised behaviour through subtypes.
Second, structures contain other structures as fields (a struct-in-struct pattern), allowing complex models to be built by nesting simpler components.
This pattern enables models to be assembled like building blocks whilst maintaining clear boundaries between different epidemiological processes.

We organise model components into three abstract type hierarchies, each of which inherits from `AbstractModel`, corresponding to distinct epidemiological processes.
`AbstractEpiModel` represents infection generation processes such as renewal models or ordinary differential equation transmission dynamics.
`AbstractLatentModel` captures time-varying parameters and unobserved processes such as changing reproduction numbers or reporting rates, implemented through structures like autoregressive processes, random walks, or moving averages.
`AbstractObservationModel` links latent states to observed data by encoding measurement processes such as reporting delays, aggregation over time periods, and observation error distributions.
These structures are data-agnostic, specifying what to do when they encounter data rather than containing data themselves, making model definitions reusable across different datasets and scenarios.
Each hierarchy supports multiple concrete implementations that can be swapped to compare modelling assumptions whilst keeping other components fixed.

Models can compose across these hierarchies rather than being restricted to combining components within a single type.
An observation model can contain a latent process as a field to represent time-varying ascertainment, or wrap another observation model to add reporting delays.
This cross-hierarchy composition extends the building block analogy to include more complex models.
For instance, we can construct a delay convolution observation model, `LatentDelay`, using an underlying observation model and a delay distribution model.

The `EpiProblem` structure serves as the top-level container assembling these components into a complete epidemiological model.
It holds an infection process (`epi_model`), a latent process (`latent_model`), an observation process (`observation_model`), and a time span for inference or simulation.
Structures can be modified in place using tools like Accessors.jl, enabling both rapid model iteration and complex patterns such as partially pooled models that dynamically update low-level priors based on grouping structures.
The abstract type system enables shared methods across all model components, such as print methods (shown below) for displaying model specifications or functions for visualising model directed acyclic graphs.
This approach also allows for the creation of mappings between submodels such as one to one, one to many, and many to many mappings so that, for example, a single infection process can be linked to multiple observations models by specifying a mapping model.

<!-- Reference to Panel B of Figure 1 -->

To demonstrate the structure and use of `AbstractLatentModels`, we start with an autoregressive order two (AR(2)) process, which mathematically is:

$$Z_t = \rho_1 Z_{t-1} + \rho_2 Z_{t-2} + \epsilon_t, \quad \epsilon_t \sim \text{Normal}(0, \sigma)$$

In our prototype DSL, this is defined using the `AR` struct.
We use priors based on @mishra which we will reuse in case study 1.

```{julia}
using EpiAware, Distributions
ar2 = AR(;
    damp_priors=[truncated(Normal(0.8, 0.1), 0, 1),
                 truncated(Normal(0.1, 0.05), 0, 1)],
    init_priors=[Normal(-1.0, 0.1), Normal(-1.0, 0.5)],
    ϵ_t=HierarchicalNormal(std_prior=HalfNormal(0.5))
)
display(ar2)
```

Another common latent model is the moving average model

$$Z_t = \epsilon_t + \theta \epsilon_{t-1}, \quad \epsilon_t \sim \text{Normal}(0, \sigma)$$

The `MA` struct encapsulates this:

```{julia}
ma1 = MA(;
    θ_priors=[truncated(Normal(0.0, 0.05), -1, 1)],
    ϵ_t=HierarchicalNormal(std_prior=HalfNormal(0.5))
)
```

A popular combination of these models is the autoregressive moving average (ARMA) model that can have different orders for both the AR and MA components.
An ARMA(2,1) can be defined as:

$$Z_t = \rho_1 Z_{t-1} + \rho_2 Z_{t-2} + \epsilon_t + \theta \epsilon_{t-1}$$

In our DSL this can be represented as a composition of the AR and MA structs by updating the AR error term:

```{julia}
using Accessors
arma21 = @set ar2.ϵ_t = ma1
display(arma21)
```

Similarly, autoregressive integrated moving average (ARIMA) models extend ARMA by adding differencing for non-stationary series:

$$\Delta Z_t = \rho_1 \Delta Z_{t-1} + \rho_2 \Delta Z_{t-2} + \epsilon_t + \theta \epsilon_{t-1}$$

We compose the ARMA model with a differencing operation using the `DiffLatentModel` wrapper:

```{julia}
arima211 = DiffLatentModel(arma21, Normal(); d=1)
display(arima211)
```

Alternatively, EpiAware provides an `arima()` constructor function that simplifies this specification.

Other latent models extend modelling options through combining models additively, multiplicative scaling, and piecewise processes.
This approach enables representation of arbitrary latent processes through composition.

<!-- -->

## Backend Implementation: Turing Interface {#sec-backend}

<!-- Reference to Panel D of Figure 1 -->

Our DSL translates to Turing models through generate functions that dispatch on abstract type hierarchies.
Each abstract type (`AbstractLatentModel`, `AbstractEpiModel`, `AbstractObservationModel`) defines a generate function interface that concrete model types must implement.
When a generate function receives a model component, Julia's multiple dispatch automatically selects the appropriate implementation based on the component's type, producing Turing code using the `@model` macro.
Unit tests are used to ensure concrete implementations satisfy interface requirements, enabling all components to interoperate correctly regardless of which specific model types are composed together.
This systematic approach means new model types integrate seamlessly without modifying existing code, and users can swap components to compare modelling assumptions whilst keeping other parts of the model fixed.

The generated Turing models serve dual purposes: simulation by sampling from prior distributions, or inference by conditioning on observed data and applying Turing's suite of algorithms including gradient-based methods like NUTS.
These are standard Turing models with no special constraints beyond those imposed by the Turing.jl framework itself, supporting all DynamicPPL.jl operations such as parameter fixing, model conditioning, and posterior predictive sampling.
Generated components can be used directly as standalone models or nested within other Turing models using the `@submodel` macro, enabling incremental adoption where only parts of a model use the compositional framework whilst other parts use custom Turing code.

Many computational components are backend-agnostic, containing no probabilistic programming constructs and therefore portable to other frameworks.
The `accumulate_scan` pattern implements iterative temporal processes through step functions, with examples including `ARStep`, `RWStep`, and `ConstantRenewalStep` for autoregressive models, random walks, and renewal equations.
These step functions are structs built on the `AbstractAccumulationStep` interface that implement a callable defining the single-step update rule.
Mathematical utilities such as functions for converting between reproduction numbers and growth rates, discretising continuous delay distributions, and reparameterising observation error models are similarly backend-agnostic.
This separation enables a package extension pattern where standard Julia packages provide domain-specific functionality whilst the compositional layer is added as an optional extension, allowing users to adopt the framework incrementally without requiring their entire workflow to commit to the compositional approach.

Returning to our example from the DSL section, the autoregressive process can be mapped from its high-level representation to a Turing model using the `generate_latent` function:

```{julia}
using CodeTracking, Revise
print(@code_string EpiAwareBase.generate_latent(ar2, 50))
```

The key line `@submodel ε_t = generate_latent(latent_model.ε_t, n - p)` enables composition by delegating to whatever error model was provided. The AR dynamics are implemented through a custom accumulation step that maintains the autoregressive state:

```{julia}
print(@code_string EpiLatentModels.ARStep([1, 2, 1])(1, 1))
```

This step function works with `accumulate_scan` to build the AR series by applying the autoregressive equation at each time step.
The MA model has a similar structure with its own internal step function.
The `accumulate_scan` pattern enables composable iteration steps, allowing complex processes like renewal models with susceptible depletion to be built by composing simple step operations.
This design means we only need to write the single-step operation without worrying about the iteration process, making components more modular and reusable.

The full ARIMA(2,1,1) model we defined in the DSL section can then be generated using the same approach:

```{julia}
print(@code_string generate_latent(arima211, 50))
```

The DiffLatentModel's `@submodel diff_latent = generate_latent(latent_model.model, n - d)` calls the ARMA model, which in turn calls its composed AR and MA components, then applies differencing through cumulative summing.
This recursive delegation through `@submodel` enables arbitrary depth composition while maintaining clean separation between components.

The generated models are standard Turing models supporting all DynamicPPL.jl functionality.
To demonstrate we create a model that uses our ARIMA(2,1,1) model as submodel combining it with a normal observation error process.

```{julia}
using DynamicPPL, Turing, LinearAlgebra

@model function arima_with_obs(arima_spec, n_timesteps)
    @submodel Z_t = generate_latent(arima_spec, n_timesteps)
    σ_obs ~ truncated(Normal(0.0, 0.01), 0, Inf)
    y_obs ~ MvNormal(Z_t, σ_obs * I)
    return y_obs;
end
```

We can then generate synthetic data with fixed parameters which we sample from the prior distribution using the `rand`, and `fix` functions and calling the model to simulate the observations. We first define the model.

```{julia}
n_timesteps = 20
gen_model = arima_with_obs(arima211, n_timesteps)
```

Then sample from it,

```{julia}
simulated_params = rand(gen_model)
```

Now we have parameters we can simulated some data using the generative model by fixing the random variables using the sampled parameters and the `fix` function. We can then call it, like any normal function, to get simulated observations for `y`.

```{julia}
fixed_model = fix(gen_model, simulated_params)
y_observed = fixed_model()
```

For inference, we condition on the generative model using simulated observations and the  `condition` function or here the equivalent `|` notation. Now we have a model conditioned on data we can fit it using our choice of approach supported by `Turing.jl`. Here we decide to use the No-U-turn sampler (a popular variant of MCMC).

```{julia}
conditioned_model = gen_model | (; y_obs = y_observed)
chains = sample(conditioned_model, NUTS(), MCMCThreads(), 2000, 4)
```

We can then compare our posterior distributions to the true sampled values from our ARIMA(2, 1, 1) model using `PairsPlots.jl`.

```{julia}
#| output: true
#| label: fig-ar-pp
#| echo: false
using PairPlots, CairoMakie
params = [:damp_AR, :ar_init, :θ]

function plot_fit_with_truth(chain, truth, params)

    params_with_names = mapreduce(param -> namesingroup(chain, param), vcat, params)
    filtered_chains = chain[params_with_names]

    filtered_truth = reduce(vcat, truth[params])
    filtered_truth = Dict(
        zip(params_with_names, reduce(vcat, truth[params]))
    )

    f = pairplot(
        filtered_chains,
        PairPlots.Truth(
            filtered_truth,
            label="True Values"
        )
    )
    return f
end

plot_fit_with_truth(
    chains,
    simulated_params,
    params
)
```

**Figure 1**: Compositional Modelling Architecture *Panel A*: Generic composition pattern showing struct-in-struct hierarchy with recursive dispatch through abstract type system.
*Panel B*: ARIMA composition example demonstrating component stacking with struct definitions.
*Panel C*: Prior predictive checks demonstrating model behavior before data conditioning.
*Panel D*: Backend abstraction architecture with Turing as current implementation and potential for ODE, agent-based, and other computational backends.

# Case Studies {#sec-case-studies}

All code and data for reproducing the analyses in this paper are available at: https://github.com/EpiAware/PrototypeCompositionalProbablisticInfectiousDiseaseModelling.

## Standard Case Study Format

Each case study follows this standardised structure to ensure consistency and clarity:

A concise paragraph explaining: - The original paper and its contribution - Why we selected this study as inspiration - Key features of our compositional prototype demonstrated (e.g., model modularity, component reusability, transparent priors) - How our implementation differs from the original where relevant

### Data

Brief description of the dataset with a single code block loading the data.

### Model

Compositional model specification with subsections.
Give a high level overview of the model in text, then present the complete probabilistic model with full mathematical formulation showing all components and their relationships.

#### Latent Model (if applicable)

-   Code implementation using latent process types (e.g., AR, RandomWalk)
-   Component-specific mathematical details as needed
-   Prior predictive checking

#### Infection Generating Process

-   Code implementation using `AbstractEpiModel` types (e.g., Renewal, DirectInfections)
-   Component-specific mathematical details as needed
-   Prior predictive checking

#### Observation Model

-   Code implementation using `ObservationModel` types (e.g., NegativeBinomialError, PoissonError)
-   Component-specific mathematical details as needed
-   Prior predictive checking

### Fitting to Data

-   Training data preparation
-   Model composition into `EpiProblem` (combining latent model, infection generating process, and observation model)
-   Inference configuration
-   Posterior sampling
-   Posterior predictive checking

Panel figure combining all visualisations: - Prior predictive plots for each model component - Posterior predictive plots showing model fit - Parameter inference summaries

### **Code Organisation Principles**

-   Dependencies imported when first needed, not in large blocks
-   Each code statement in separate block with explanatory text before and after
-   Minimal, clear code focused on demonstrating compositional concepts
-   Use the same dependencies across each case study where possible i.e. chained dataframesmeta verbs, pairplot for prior and posterior output, a single plotting library, don't use package.function form unless can't be avoided.
-   Complete mathematical model presented upfront in Model section, before component implementations

## On the derivation of the renewal equation from an age-dependent branching process: an epidemic modelling perspective {#sec-example1}

<!-- Reference: https://arxiv.org/abs/2006.16487 -->

<!-- Implementation: https://cdcgov.github.io/Rt-without-renewal/stable/showcase/replications/mishra-2020/ -->

In _On the derivation of the renewal equation from an age-dependent branching process: an epidemic modelling perspective, *Mishra et al* (2020)_ @mishra demonstrate the mathematical correspondance between age-dependent branching processes and time-since-infection epidemiological models, as a renewal model with time-varying reproduction number $R_t$.
Renewal models use the renewal equation to model how new infections arise from previous infections, weighted by the generation time distribution (or serial interval) [@cori2013new].
This is analogous to an autoregressive process where the weights have epidemiological meaning rather than being estimated parameters.
They show how solutions to the renewal equation, when combined with a negative binomial observation model, define a Bayesian hierarchical framework for inference on reported case time series data, demonstrating this on test-confirmed cases of COVID-19 in South Korea.
This simple three-component structure (AR(2) latent process, renewal infection model, negative binomial observation model) demonstrates component modularity and independent prior predictive checking before composition.

### Data

_Mishra et al_ used daily reported test-confirmed cases of COVID-19 in South Korea between January to July 2020.
This data is curated by the [`covidregionaldata`](https://github.com/epiforecasts/covidregionaldata) package, but we have saved the South Korean data locally.

```{julia}
using Chain, CSV, DataFramesMeta, Dates
datapath = "data/south_korea_data.csv"
south_korea_data = @chain datapath begin
    CSV.read(DataFrame)
    (y_t = _.cases_new, dates = _.date)
end
```

### Model

Our model is inspired by _Mishra et al_ and uses a log-scale time-varying reproductive number $\log R_t$ modelled as an AR(2) process, which in turn specifies the latent infections $I_t$ as a solution to the renewal equation conditional on the trajectory of $\log R_t$.
The latent infection process is then linked directly to reported cases $C_t$ on matching days using a negative binomial link distribution.
The key difference from _Mishra et al_ is in the initialization: they seed the renewal equation with importations (independent daily effects $\mu_t \sim \text{Exponential}(0.5)$), whilst we initialize by solving for the growth rate corresponding to the initial reproduction number and extrapolating backwards without allowing for ongoing importations.

$$
\begin{aligned}
Z_t & = \log R_t, \\
\rho_1, \rho_2, Z_0, Z_{-1}, I_0,  \sigma, \phi &\sim \pi(\cdot), \\
\epsilon_t & \sim \text{Normal}(0, \sigma)~~ \text{i.i.d } \forall t, \\
Z_t &= \rho_1 Z_{t-1} + \rho_2 Z_{t-2} + \epsilon_t,~~ t = 1, 2, 3, \dots\\
r & \text{ solves } G(r) = 1 / R_1, \\
I_{t} & = I_0 e^{rt},~~ t = 0, -1, -2, -3,-n+1, \\
I_t &= R_t \sum_{s \geq 1} g_s I_{t-s}, ~~ t = 1, 2, 3, \dots, \\
y_t & \sim \text{NegBin}(I_t, \phi), ~~ t = 1, 2, 3, \dots.
\end{aligned}
$$

Where $\pi$ is a prior distribution for the hyperparmeters of the AR(2) model, initial states $Z_0, Z_{-1}$, the damping parameters $\rho_1,\rho_2$ and innovations standard deviation $\sigma$, along with initial condition value for the latent infections $I_0$ and observation overdispersion $\phi$.
$g_t$ is the generation distribution probability mass function (pmf).
$r$ is the growth rate determined by the by $R_1 = \exp(Z_1)$ using the implicit relationship @wallinga2007generation.

$$
G(r) = \sum_{j \geq 1} g_j \exp(- r j) = 1 / R_1.
$$

This means that we determine the initial condition of the latent infecteds before $t=0$, $I_{-1}, I_{-2}, \dots, I_{-n+1}$ jointly with sampling $R_1$ where $n$ is the maximum support value of the $g_t$ pmf.

#### Latent Model

We reuse the AR(2) model `ar2` defined in @sec-dsl, which has the appropriate priors from _Mishra et al_.
Prior predictive samples (Figure @fig-posterior-preds-CS1, top left panel) show that *a priori* these priors assign a few percent chance of achieving very high $R_t$ values, i.e. $R_t \sim 10-1000$ is not excluded.

```{julia}
#| echo: false
using CairoMakie, Random
Random.seed!(1234)

ar_mdl = generate_latent(ar2, 50)

function ar_sample_plot!(ax, ar_mdl; n_samples = 100)
    ar_mdl_samples = mapreduce(hcat, 1:n_samples) do _
        ar_mdl() .|> exp
    end
    for col in eachcol(ar_mdl_samples)
        lines!(ax, col, color = (:grey, 0.1))
    end
    return nothing
end
```

#### Infection Generating Process

The renewal equation requires a discrete generation time pmf $g_t$.
Our prototype provides a constructor that converts continuous distributions into the required discrete pmf using double interval censoring @charniga2024best.
_Mishra et al_ used a $\text{Gamma}(6.5, 0.62)$ serial interval distribution,

```{julia}
truth_SI = Gamma(6.5, 0.62)
model_data = EpiData(gen_distribution = truth_SI)
display(model_data.gen_int)
```

Figure @fig-posterior-preds-CS1 (bottom left panel) compares the discretized generation interval with the underlying continuous distribution.

```{julia}
#| echo: false

function discretised_gen_plot!(ax, model_data, truth_SI)
    barplot!(ax, model_data.gen_int;
        label = "Discretized next gen pmf"
    )
    lines!(ax, truth_SI;
        label = "Continuous serial interval",
        color = :green
    )
    axislegend(ax)
    return nothing
end
```

We use a lognormal prior for the initial latent infections.
The `Renewal` model requires the discretized generation time (from `model_data`) and the initialisation prior,

```{julia}
log_I0_prior = Normal(log(1.0), 1.0)
renewal = Renewal(model_data; initialisation_prior = log_I0_prior)
display(renewal)
```

To demonstrate the infection model independently, we supply a fixed $R_t$ trajectory that decreases from 3 to 0.5 over 50 days.

```{julia}
Rt = [0.5 + 2.5 / (1 + exp(t - 15)) for t in 1:50]
renewal_mdl = generate_latent_infs(renewal, log.(Rt))
```

The implied distribution of $I_t$ trajectories conditional on this $R_t$ trajectory can be sampled independently of other model components (Figure @fig-posterior-preds-CS1, top middle panel).

```{julia}
#| echo: false

function plot_latent_infections!(ax, renewal_mdl; n_samples)
    renewal_mdl_samples = mapreduce(hcat, 1:n_samples) do _
        renewal_mdl()
    end
    for col in eachcol(renewal_mdl_samples)
        lines!(ax, col;
            color = (:grey, 0.1)
        )
    end
    return nothing
end

function plot_Rt_traj!(ax, Rt)
    lines!(ax, Rt;
            linewidth = 2
        )
    return nothing
end
```

The full infection generating process, that is the model defined in the [generative model section](#case-study-1-generative-model) without the link to case data, can be constructed by passing samples of $Z_t$ into the renewal model sampler.

#### Observation Model

In *Mishra et al* the overdispersion parameter $\phi$ sets the relationship between the mean and variance of the negative binomial errors.
We default to a prior on $\sqrt{1/\phi}$ (referred to as the cluster factor) because this quantity is approximately the coefficient of variation of the observation noise and, therefore, is easier to reason on *a priori* beliefs.
A prior for $\phi$ was not specified in *Mishra et al*, so we use $\sqrt{1/\phi} \sim \text{HalfNormal}(0.1)$.

```{julia}
negbin = NegativeBinomialError(cluster_factor_prior = HalfNormal(0.1))
display(negbin)
```

As with other components, we generate a Turing model conditional on a fixed latent infection trajectory.

```{julia}
#| echo: false
I_t = [1000 * exp(-(t - 15)^2 / (2 * 4)) for t in 1:30]
negbin_mdl = generate_observations(negbin, missing, I_t)
```

Turing uses `missing` arguments to indicate observed variables that are to be sampled rather than only used to accumulate log posterior density.
Prior predictive samples (Figure @fig-posterior-preds-CS1, top right panel) show the dispersion around the mean implied by our choice of prior.

```{julia}
#| echo: false

function neg_bin_obs_plot!(ax, negbin_mdl; n_samples)
    negbin_mdl_samples = mapreduce(hcat, 1:n_samples) do _
        θ = negbin_mdl() #Sample unconditionally the underlying parameters of the model
    end
    for col in eachcol(negbin_mdl_samples)
            scatter!(ax, col;
                color = (:grey, 0.2)
            )
        end
        lines!(ax, I_t;
            color = :red,
            linewidth = 3,
            label = "Latent infections"
        )
    axislegend(ax)
    return nothing
end
```

### Fitting to Data

We compose the three model components into an `EpiProblem`, which defines the complete generative model for the time range `tspan`.

```{julia}
tspan = (45, 80)
mishra = EpiProblem(epi_model = renewal,
    latent_model = ar2,
    observation_model = negbin,
    tspan = tspan)
display(mishra)
```

We create training data by subsetting the full data to match `tspan`.

```{julia}
training_data = @chain south_korea_data begin
    @set _.y_t = _.y_t[first(tspan):last(tspan)]
    @set _.dates = _.dates[first(tspan):last(tspan)]
end
```

We construct a Turing model using `generate_epiaware` (introduced in @sec-backend).
We condition on a fixed cluster factor value due to non-identifiability with the variance in the innovation process of $Z_t$.

```{julia}
using Turing
fixed_cluster_factor = 0.25
mishra_mdl = generate_epiaware(mishra, training_data) |
      (var"obs.cluster_factor" = fixed_cluster_factor,)
```

Following the same compositional pattern as our modelling DSL, we compose inference approaches using `EpiMethod`, which combines pre-sampling steps with sampling algorithms.
We use the No U-Turns (NUTS) sampler with a pre-sampling step of `ManyPathfinder`, a batched implementation of pathfinder variational inference @zhang2022pathfinder that returns the single pathfinder route with maximum estimated evidence lower bound.

```{julia}
using ReverseDiff
inference_method = EpiMethod(
    pre_sampler_steps = [ManyPathfinder(nruns = 5, maxiters = 100)],
    sampler = NUTSampler(
        target_acceptance = 0.9,
        adtype = AutoReverseDiff(compile = true),
        ndraws = 1000,
        nchains = 4,
        mcmc_parallel = MCMCThreads(),
        nadapts = 1000)
)
```

The `apply_method` function combines the composed epidemiological model, inference method, and training data to return samples from the posterior distribution.

```{julia}
mishra_results = apply_method(mishra_mdl,
    inference_method,
    training_data
)
summarystats(mishra_results.samples)
```

```{julia}
#| echo: false

dates_to_times(dates) = [(d - minimum(dates)).value + 1 for d in dates]

function generated_quantiles(gens, quantity, qs; transformation = x -> x)
    mapreduce(hcat, gens) do gen #loop over sampled generated quantities
        getfield(gen, quantity) |> transformation
    end |> mat -> mapreduce(hcat, qs) do q #Loop over matrix row to condense into qs
        map(eachrow(mat)) do row
            if any(ismissing, row)
                return missing
            else
                quantile(row, q)
            end
        end
    end
    
end

function identify_good_chains(chn; threshold = 3.0)
    idxs = @chain chn[:lp] begin
        mean(; dims = 1)
        vec
        findall(maximum(_) .- _ .< threshold)
    end
    return idxs
end

function posterior_gens_for_plot(inference_results, n; epi_prob, fixed_cluster_factor, threshold)
    mdl_unconditional = isnothing(fixed_cluster_factor) ?
        generate_epiaware(epi_prob,(y_t = fill(missing, n),)) :
        generate_epiaware(epi_prob, (y_t = fill(missing, n),)) | (var"obs.cluster_factor" = fixed_cluster_factor,)

    good_chns = identify_good_chains(inference_results.samples; threshold)
    posterior_gens = generated_quantities(mdl_unconditional, inference_results.samples[:, :, good_chns])

    return posterior_gens
end

function post_predictive_yt!(ax, inference_data, posterior_gens; qs)
    ts = dates_to_times(inference_data.dates)
    predicted_y_t = generated_quantiles(posterior_gens, :generated_y_t, qs)
    n = count(row -> any(ismissing.(row)), eachrow(predicted_y_t))
    predicted_y_t = predicted_y_t[(n+1):end, :] 

    lines!(ax, ts[(n+1):end], predicted_y_t[:, 3];
        color = :purple,
        linewidth = 2,
        label = "Post. median"
    )
    band!(ax, ts[(n+1):end], predicted_y_t[:, 2], predicted_y_t[:, 4];
        color = (:purple, 0.4),
        label = "50%"
    )
    band!(ax, ts[(n+1):end], predicted_y_t[:, 1], predicted_y_t[:, 5];
        color = (:purple, 0.2),
        label = "95%"
    )
    scatter!(ax, ts, inference_data.y_t;
        color = :black,
        label = "Actual cases")
    axislegend(ax)

    return nothing
end

function post_predictive_Rt!(ax, inference_data, posterior_gens; qs)
    ts = dates_to_times(inference_data.dates)
    #Prediction quantiles
    predicted_R_t = generated_quantiles(posterior_gens, :Z_t, qs;
            transformation = x -> exp.(x))

    lines!(ax, ts, predicted_R_t[:, 3];
        color = :green,
        linewidth = 2,
        label = "Post. median"
    )
    band!(ax, ts, predicted_R_t[:, 2], predicted_R_t[:, 4];
        color = (:green, 0.4),
        label = "50%"
    )
    band!(ax, ts, predicted_R_t[:, 1], predicted_R_t[:, 5];
        color = (:green, 0.2),
        label = "95%"
    )
    axislegend(ax)
end

# Older plotting left temporarily so render continues (used further down)
function plot_post_pred(inference_data, inference_results; epi_prob, 
    fixed_cluster_factor = nothing,
    qs = [0.025, 0.25, 0.5, 0.75, 0.975],
    threshold = 3.0)
    y_t = inference_data.y_t
    dates = inference_data.dates
    ts = dates .|> d -> d - minimum(dates) .|> d -> d.value + 1
    t_ticks = string.(dates)

    mdl_unconditional = isnothing(fixed_cluster_factor) ?
        generate_epiaware(epi_prob,(y_t = fill(missing, length(y_t)),)) :
        generate_epiaware(epi_prob, (y_t = fill(missing, length(y_t)),)) | (var"obs.cluster_factor" = fixed_cluster_factor,)

    good_chns = identify_good_chains(inference_results.samples; threshold)
    posterior_gens = generated_quantities(mdl_unconditional, inference_results.samples[:, :, good_chns])


    predicted_y_t = generated_quantiles(posterior_gens, :generated_y_t, qs)
    predicted_R_t = generated_quantiles(posterior_gens, :Z_t, qs;
        transformation = x -> exp.(x))

    n = count(row -> any(ismissing.(row)), eachrow(predicted_y_t))
    predicted_y_t = predicted_y_t[(n+1):end, :]

    fig = Figure()
    ax1 = Axis(fig[1, 1];
        ylabel = "Daily cases",
        xticks = (ts[1:14:end], t_ticks[1:14:end]),
        title = "Posterior predictive: Cases"
    )
    ax2 = Axis(fig[2, 1];
        yscale = log10,
        title = "Prediction: Reproduction number",
        xticks = (ts[1:14:end], t_ticks[1:14:end])
    )
    linkxaxes!(ax1, ax2)

    lines!(ax1, ts[(n+1):end], predicted_y_t[:, 3];
        color = :purple,
        linewidth = 2,
        label = "Post. median"
    )
    band!(ax1, ts[(n+1):end], predicted_y_t[:, 2], predicted_y_t[:, 4];
        color = (:purple, 0.4),
        label = "50%"
    )
    band!(ax1, ts[(n+1):end], predicted_y_t[:, 1], predicted_y_t[:, 5];
        color = (:purple, 0.2),
        label = "95%"
    )
    scatter!(ax1, ts, y_t;
        color = :black,
        label = "Actual cases")
    axislegend(ax1)

    lines!(ax2, ts, predicted_R_t[:, 3];
        color = :green,
        linewidth = 2,
        label = "Post. median"
    )
    band!(ax2, ts, predicted_R_t[:, 2], predicted_R_t[:, 4];
        color = (:green, 0.4),
        label = "50%"
    )
    band!(ax2, ts, predicted_R_t[:, 1], predicted_R_t[:, 5];
        color = (:green, 0.2),
        label = "95%"
    )
    axislegend(ax2)

    return fig
end
```

```{julia}
#| output: true
#| echo: false
#| label: fig-posterior-preds-CS1
#| fig-cap: (Top row) Prior predictive visualisation for the three submodels of case study 1. (Top Left) Samples from the log-reproductive number latent process over 50 days. (Top Middle) Samples from the renewal model with a fixed reproductive number trajectory from $R_t =3$ to $R_t =0.5$. (Top Right) Samples from the negative binomial observation submodel around a latent infection curve (Bottom row) Component using composed full generative model. (Bottom left) Comparison of continuous serial interval distribution with double censored discrete distribution used in modelling. (Bottom Middle) Posterior predictive distribution for cases from model showing posterior median per day (purple line) and credible intervals (purple ribbons). (Bottom Right) Posterior predictive distribution for time-varying reproductive number with median on each day (green line) and credible intervals (green ribbons).
figure2 = let 
    qs = [0.025, 0.25, 0.5, 0.75, 0.975]
    n_samples = 100
    t_ticks = @chain training_data begin
            _.dates
            string.(_)
        end
    ts = dates_to_times(training_data.dates)

    posterior_gens = posterior_gens_for_plot(mishra_results, length(training_data.y_t);
            epi_prob = mishra,
            fixed_cluster_factor = fixed_cluster_factor,
            threshold = 3.0)

    fig = Figure(size = (1200, 1000))
    ax11 = Axis(fig[1, 1];
        yscale = log10,
        ylabel = "Time varying Rₜ",
        title = "$(n_samples) draws from the prior Rₜ model"
    )
    n_ax12_samples = 100
    ax12 = Axis(fig[1, 2];
            title = "$(n_samples) draws from renewal model with chosen Rt",
            ylabel = "Latent infections"
        )

    ax13 = Axis(fig[1, 3];
        title = "$(n_samples) draws from neg. bin. obs model",
        ylabel = "Observed cases"
    )

    ax21 = Axis(fig[2, 1];
        xticks = 0:14,
        xlabel = "Days",
        title = "Continuous and discrete generation intervals"
    )

    ax22 = Axis(fig[2, 2];
        ylabel = "Daily cases",
        xticks = (ts[1:14:end], t_ticks[1:14:end]),
        title = "Posterior predictive: Cases"
    )
    ax23 = Axis(fig[2, 3];
        yscale = log10,
        title = "Prediction: Reproductive number",
        xticks = (ts[1:14:end], t_ticks[1:14:end])
    )

    ar_sample_plot!(ax11, ar_mdl; n_samples)
    plot_latent_infections!(ax12, renewal_mdl; n_samples)
    neg_bin_obs_plot!(ax13, negbin_mdl; n_samples)
    discretised_gen_plot!(ax21, model_data, truth_SI)
    post_predictive_yt!(ax22, training_data, posterior_gens; qs)
    post_predictive_Rt!(ax23, training_data, posterior_gens; qs)

    fig
end


figure2
```

Figure @fig-posterior-preds-CS1 shows that the compositional model defined using our prototype system recovers the main finding in *Mishra et al*; that the $R_t$ in South Korea peaked at a very high value ($R_t \sim 10$ at peak) before rapidly dropping below 1 in early March 2020.

## EpiNow2: Estimate Real-Time Case Counts and Time-Varying Epidemiological Parameters {#sec-example2}

In this case study we replicate a common `EpiNow2` configuration using our prototype framework.
EpiNow2 [@abbott-epinow2-wellcomeopenres] is a widely-used R package for estimating the time-varying reproduction number and making forecasts for epidemics in real-time.
EpiNow2 is built around three core modeling components that work together to reconstruct epidemic dynamics from delayed and noisy case count observations:

1.  **Renewal-based transmission modeling**: EpiNow2 uses the discrete renewal equation to model how new infections arise from previous infections, weighted by the generation time distribution (the time between successive infections in a transmission chain).

2.  **Delayed observation processes**: The framework explicitly accounts for the delay between infection and case reporting, which typically involves multiple sequential delays including incubation periods and reporting lags.

3.  **Temporal modifiers to observation**: Case counts are modeled using a (default) negative binomial distribution to capture overdispersion and model misspecification, with additional modifiers such as day-of-week effects to account for systematic biases in reporting patterns.

We recreate the core EpiNow2 functionality by **reusing model components from Example 1** and **composing them with new delay and temporal effect components**.
This showcases the flexibility and modularity of our approach - rather than implementing everything from scratch, we build upon previously defined components in a principled way.
We will reuse the renewal-based epidemiological model and ARIMA(2,1,1) latent process from @sec-dsl, whilst introducing new observation model components to handle reporting delays and day-of-week effects.

### Model

Our model reuses the renewal infection model and ARIMA(2,1,1) latent process from earlier sections, whilst building a complex observation model that accounts for reporting delays and day-of-week effects.
Unlike Example 1 where the serial interval distribution was used (as in _Mishra et al_), EpiNow2 uses the generation time distribution, which represents the time between successive infections in a transmission chain.
The observation model layers three effects: negative binomial observation noise (reused from Example 1), day-of-week temporal modifiers, and reporting delays via convolution.

Mathematically, we represent the complete model as:

$$
\begin{aligned}
Z_t & = \log R_t, \\
\rho_1, \rho_2, Z_0, Z_{-1}, I_0,  \sigma_Z, \sigma_\omega, \phi &\sim \pi(\cdot), \\
\epsilon_t & \sim \text{Normal}(0, \sigma_Z)~~ \text{i.i.d } \forall t, \\
Z_t - Z_{t-1} &= \rho_1 (Z_{t-1} - Z_{t-2}) + \rho_2 (Z_{t-2} - Z_{t-3}) + \epsilon_t,~~ t = 1, 2, 3, \dots\\
I_t &= R_t \sum_{s \geq 1} g_s I_{t-s}, ~~ t = 1, 2, 3, \dots, \\
D_t &= \sum_{s\geq1} I_{t-s} \xi_s,~~ \text{Delayed latent infections}\\
\tilde{\omega}_k &\sim \text{N}(0, \sigma^2_\omega),~ k = 0,\dots, 6,~~ \text{Day-of-week modifier} \\
\omega &= 7 \times \text{softmax}(\tilde{\omega}),\\
y_t &\sim \text{NegBin}( D_t \omega_{t~\text{mod}~7}, \phi),~~ \text{Link to data}.
\end{aligned}
$$ {#eq-epinow2-model}

Where $\pi$ represents prior distributions for model hyperparameters.
$g_t$ is the generation time distribution pmf and $\xi_t$ is the reporting delay distribution pmf (both obtained by double interval censoring continuous distributions @charniga2024best).
$D_t$ is a convolution on the latent infection time series that maps infections from *before* day $t$ into delayed observations *on* day $t$.
The vector $\omega = [\omega_0,\dots,\omega_6]$ encodes day-of-week effects on reporting.

#### Latent Model

We reuse the ARIMA(2,1,1) model `arima211` defined in @sec-dsl.
In EpiNow2, although stationary processes representations $R_t$ are available, the default latent process is a *differenced* stationary (Matern) Gaussian Process; that is the default $R_t$ process is stationary only on its increments.
In analogy, `arima211` applies the ARMA(2,1) model to the increments $R_{t} - R_{t-1}$.
Prior predictive samples (Figure @fig-posterior-preds-CS2, top left panel) show the behaviour of this differenced process.

```{julia}
#| echo: false

arima_mdl = generate_latent(arima211, 50)

function arima_sample_plot!(ax, arima_mdl; n_samples = 100)
    arima_mdl_samples = mapreduce(hcat, 1:n_samples) do _
        arima_mdl() .|> exp
    end
    for col in eachcol(arima_mdl_samples)
        lines!(ax, col, color = (:grey, 0.1))
    end
    return nothing
end
```

#### Infection Generating Process

The renewal equation requires a discrete generation time pmf $g_t$.
Unlike Example 1 where the serial interval distribution was used (as in _Mishra et al_), EpiNow2 uses the generation time distribution, which represents the time between successive infections in a transmission chain.
Whilst the serial interval (time between symptom onsets) is often used as a proxy for the generation time because it is more readily observable, using the serial interval can be problematic @park2023inferring and is primarily done in practice when generation time estimates are unavailable, particularly early in an outbreak @zhao2020preliminary.

We use a $\text{Gamma}(6.5, 0.62)$ generation time distribution (matching the serial interval from Example 1 for comparison purposes, though in practice these would differ).

```{julia}
gen_time_dist = Gamma(6.5, 0.62)
epinow2_data = EpiData(gen_distribution = gen_time_dist)
display(epinow2_data.gen_int)
```

We reuse the `renewal` structure from Example 1, updating it to use the generation time distribution rather than the serial interval.

```{julia}
renewal_gt = @set renewal.data = epinow2_data
display(renewal_gt)
```

To demonstrate the infection model independently, we supply a fixed $R_t$ trajectory that decreases from 3 to 0.5 over 50 days.
Figure @fig-posterior-preds-CS2 (top middle panel) shows prior samples from the renewal process conditional on this $R_t$ trajectory.

```{julia}
#| echo: false
renewal_mdl = let
    rt_process = [3.0 * (1.0 - t / 50.0)^3 + 0.5 for t in 1:50]
    _renewal_mdl = generate_latent_infs(renewal_gt, log.(rt_process))
end
```

#### Observation Model

We build the observation model through **composition** of modular components, demonstrating how complex observation processes emerge from simple building blocks.
We **reuse the negative binomial link observation model (`negbin`) from Example 1**, then layer additional modelling components on top.

```{julia}
dayofweek_negbin = ascertainment_dayofweek(negbin;
    latent_model = HierarchicalNormal(std_prior = HalfNormal(1.0))
    )
```

Unpacking this helper function we have a nested stack of modelling constructions.
First on the transformation and broadcasting,

```{julia}
print(@code_string broadcast_dayofweek(HierarchicalNormal()))
```

Which uses the `TransformLatentModel` and `BroadcastLatentModel` structs to dispatch the transformation $\omega = 7 \times \text{softmax}(\tilde{\omega})$ and then broadcast this along the time series.

And second on the action of ascertainment as a multiplier on the time series of latent infections along with the probabilistic model for $\tilde{\omega}$ and variable prefixing.

```{julia}
I_t_demo = [1000.0 for _ in 1:30]
print(@code_string generate_observations(dayofweek_negbin, missing, I_t_demo))
```

For this example we choose a latent delay distribution of median 5 days with LogNormal errors,

```{julia}
delay_distribution = LogNormal(log(5), 0.2)
```

The `LatentDelay` struct uses double interval censoring @charniga2024best to convert this continuous delay model into the pmf $\xi_t$ and stacks with the temporal modifier model defined above.

```{julia}
delay_dayofweek_negbin = LatentDelay(dayofweek_negbin, delay_distribution)
display(delay_dayofweek_negbin)
```

This code demonstrates component reuse (base `negbin` from Example 1), layered composition (adding day-of-week effects via `ascertainment_dayofweek`), and sequential composition (adding reporting delays via `LatentDelay`).
Figure @fig-posterior-preds-CS2 (top right panel) demonstrates how these delay and day-of-week effects work together to transform a latent infection signal.

```{julia}
#| echo: false
function delay_dow_sample_plot!(ax, obs_mdl, latent_infections; n_samples=100)
    obs_mdl_samples = mapreduce(hcat, 1:n_samples) do _
        obs_mdl()
    end
    for col in eachcol(obs_mdl_samples)
        scatter!(ax, col; color=(:grey, 0.2))
    end
    lines!(ax, latent_infections; color=:red, linewidth=3, label="Latent infections")
    axislegend(ax)
    return nothing
end
```

### Fitting to Data

We compose these modelling subcomponents into one `EpiProblem` model.

```{julia}
cutout = length(delay_dayofweek_negbin.rev_pmf)

epinow2 = EpiProblem(epi_model = renewal_gt,
    latent_model = arima211,
    observation_model = delay_dayofweek_negbin,
    tspan = (45-cutout, 80))
display(epinow2)
```

This `EpiProblem` uses the renewal model with generation time data (`renewal_gt`) and the ARIMA(2,1,1) latent model from @sec-dsl (`arima211`).
The observation model reuses `negbin` from Example 1, layering on delays and day-of-week effects.

We need to account for the extended time window required to handle reporting delays:

```{julia}
longer_south_korea_data = (
    y_t = south_korea_data.y_t[(epinow2.tspan[1]):epinow2.tspan[2]],
    dates = south_korea_data.dates[(epinow2.tspan[1]):epinow2.tspan[2]],
    )
```

We construct a Turing model using `generate_epiaware`.
Unlike Example 1, we let the cluster factor parameter $\phi$ of the negative binomial distribution be jointly inferred rather than conditioning on a fixed value, following EpiNow2's approach.

```{julia}
epinow2_mdl = generate_epiaware(epinow2, longer_south_korea_data)
```

We reuse the same `inference_method` defined in Example 1, showcasing how our inference setup can be applied across different model compositions.

```{julia}
epinow2_results = apply_method(epinow2_mdl,
    inference_method,
    longer_south_korea_data
)
summarystats(epinow2_results.samples)
```

```{julia}
#| output: true
#| echo: false
#| label: fig-posterior-preds-CS2
#| fig-cap: (Top row) Prior predictive visualisation for the three submodels of case study 2. (Top Left) Samples from the ARIMA(2,1,1) log-reproductive number latent process over 50 days. (Top Middle) Samples from the renewal model with a fixed reproductive number trajectory. (Top Right) Samples from the delay and day-of-week observation submodel around a latent infection curve. (Bottom row) Component using composed full generative model. (Bottom Left) Comparison of continuous delay distribution with double censored discrete distribution used in modelling. (Bottom Middle) Posterior predictive distribution for cases from model showing posterior median per day (purple line) and credible intervals (purple ribbons). (Bottom Right) Posterior predictive distribution for time-varying reproductive number with median on each day (green line) and credible intervals (green ribbons).
figure3 = let
    qs = [0.025, 0.25, 0.5, 0.75, 0.975]
    n_samples = 100
    t_ticks = @chain longer_south_korea_data begin
        _.dates
        string.(_)
    end
    ts = dates_to_times(longer_south_korea_data.dates)

    posterior_gens = posterior_gens_for_plot(epinow2_results, length(longer_south_korea_data.y_t);
        epi_prob=epinow2,
        fixed_cluster_factor=nothing,
        threshold=3.0)

    latent_infections = [500 * (1 + cospi(2 * t / 30.0)) for t = 1:(7*10)]
    log_scale_dow_effect = [1.0; zeros(6)]
    obs_mdl = generate_observations(delay_dayofweek_negbin, missing, latent_infections) |
              (var"DayofWeek.ϵ_t"=log_scale_dow_effect,)

    fig = Figure(size=(1200, 1000))
    ax11 = Axis(fig[1, 1];
        yscale=log10,
        ylabel="Time varying Rₜ",
        title="$(n_samples) draws from the prior ARIMA(2,1,1) model"
    )
    ax12 = Axis(fig[1, 2];
        title="$(n_samples) draws from renewal model with chosen Rt",
        ylabel="Latent infections"
    )

    ax13 = Axis(fig[1, 3];
        title="$(n_samples) draws from delay + day-of-week obs model",
        ylabel="Observed cases"
    )

    ax21 = Axis(fig[2, 1];
        xticks=0:5:20,
        xlabel="Days",
        title="Continuous and discrete delay distributions"
    )

    ax22 = Axis(fig[2, 2];
        ylabel="Daily cases",
        xticks=(ts[1:14:end], t_ticks[1:14:end]),
        title="Posterior predictive: Cases"
    )
    ax23 = Axis(fig[2, 3];
        yscale=log10,
        title="Prediction: Reproductive number",
        xticks=(ts[1:14:end], t_ticks[1:14:end])
    )

    arima_sample_plot!(ax11, arima_mdl; n_samples)
    plot_latent_infections!(ax12, renewal_mdl; n_samples)
    delay_dow_sample_plot!(ax13, obs_mdl, latent_infections; n_samples)

    delay_pmf = delay_dayofweek_negbin.rev_pmf[end:-1:1]
    barplot!(ax21, 0:(length(delay_pmf)-1), delay_pmf; label="Discretized delay pmf")
    lines!(ax21, 0:0.1:20, x -> pdf(delay_distribution, x);
        color=:blue, linewidth=2, label="Continuous delay dist")
    axislegend(ax21)

    post_predictive_yt!(ax22, longer_south_korea_data, posterior_gens; qs)
    post_predictive_Rt!(ax23, longer_south_korea_data, posterior_gens; qs)

    fig
end

figure3
```

Figure @fig-posterior-preds-CS2 shows that the compositional model defined using our prototype system successfully captures the EpiNow2 functionality.
The model recovers similar $R_t$ dynamics to Example 1, whilst explicitly accounting for reporting delays and day-of-week effects that were implicit in the simpler model.
The posterior predictive checks demonstrate that the model captures both the overall epidemic trajectory and the day-to-day variation in case counts, with the delay and day-of-week components helping to disentangle true transmission changes from reporting artifacts.

## Contemporary statistical inference for infectious disease models using Stan {#sec-example3}

<!-- Reference: https://www.sciencedirect.com/science/article/pii/S1755436519300325 -->
<!-- Implementation: https://cdcgov.github.io/Rt-without-renewal/stable/showcase/replications/chatzilena-2019/ -->

In this vignette, we'll demonstrate how to use `EpiAware` in conjunction with [SciML ecosystem](https://sciml.ai/) to replicate [Contemporary statistical inference for infectious disease models using Stan *Chatzilena et al. 2019*](https://www.sciencedirect.com/science/article/pii/S1755436519300325).

*This case study is currently being developed separately in `case-study-3.qmd` and will be integrated once it follows the standard case study format.*

# Discussion {#sec-discussion}

This paper has demonstrated that compositional approaches can address key barriers in epidemiological modelling.
We presented a prototype that enables "LEGO-like" model construction through standardised interfaces, maintaining the statistical rigour of joint models whilst providing the flexibility of pipeline approaches.
The autoregressive model example illustrated how complex models emerge from simple component combinations using the struct-in-struct pattern.
Our three case studies replicated previous studies [@mishra2020covid; @epinow2; @chatzilena2019contemporary], demonstrating model composability for a range of problems and using different underlying methods.

<!-- Strengths and weaknesses interwoven -->

-   Modular design enables rapid model development and component reuse, though requires learning curve for researchers familiar with monolithic approaches
-   Systematic comparison of modelling assumptions without large reimplementation, but computational overhead from abstraction layers
-   Transparent specification through explicit component interfaces improves reproducibility, yet interface standardisation may constrain some specialised approaches
-   Reduces implementation barriers for methodological advances, however current component library remains limited to basic epidemiological patterns
-   Current struct manipulation approaches require users to understand the complete nested structure when modifying deeply embedded model components, and cannot coordinate updates of related parameters such as model order and corresponding priors without manual intervention
 - The Turing PPL DSL is not fully stable and since developing this prototype the submodel macro has changed syntax and had breaking changes in how it handles prefixes.
   The new version introduces automatic prefix generation and enforces that all variables in a model must be returned, meaning our current prototype implementation is not compatible with the latest Turing.jl release.
 - However, these changes allow for more flexible models as they reduce the difference between specifying something as a distribution and as a submodel.
 - Ignores category theory.
 
<!-- Comparison to literature - Algebraic Julia -->

-   Builds on algebraic Julia ecosystem (DifferentialEquations.jl, etc.)
-   Extends scientific machine learning to epidemiological contexts
-   Utilises Julia's multiple dispatch for component composition

<!-- Comparison to literature - Other approaches -->

-   Contrast with pipeline approaches (separate models passing information)
-   Comparison to modular frameworks in other scientific domains
-   Relationship to probabilistic programming languages and compositional features
-   Gen.jl and Genify (https://ztangent.github.io/assets/pdf/2021-genify.pdf)

<!-- Future work -->

Areas for future work include expanding the component library to address epidemiological applications across multiple scales and data types.
More work is also needed to allow for modifying deeply nested model specifications without the user needing to be aware of the structure of the nested model.
Methodological advances are also needed including for the joint estimation of interdependent epidemiological parameters, and then seamless integration of individual and population-level observations.
Alternative approaches also need to investigated, particularly more formal category theory based methods that use operadic composition for mathematically rigorous hierarchical model construction, as demonstrated in AlgebraicPetri.jl and AlgebraicDynamics.jl [@libkind2022algebraic].
Symbolic-numeric frameworks like ModelingToolkit.jl [@modelingtoolkit2021] offer potential performance improvements through automatic optimisation and code generation.
However, these approaches require generalisation to explicitly model probabilities and support a range of different modelling approaches which are both essential for infectious disease modelling applications.
An alternative potential abstraction approach would be to build the domain-specific language on Distributions.jl rather than Turing.jl, which would enable compatibility with multiple probabilistic programming languages like JuliaBUGS whilst trading off the expressiveness of Turing's submodel interface.
Performance optimisation through parallelisation and approximate inference methods, along with integration bridges to existing epidemiological software ecosystems, will be essential for practical adoption.

<!-- Conclusions -->

A fully featured implementation of the prototype we present here has the potential to transform real-time analysis of infectious disease dynamics by enabling "LEGO-like" assembly of epidemiological components through standardised interfaces.
This prototype establishes the feasibility of integrating diverse expertise whilst maintaining statistical rigour, addressing key limitations of both pipeline and joint modelling approaches.
Given the unpredictable nature of future infectious disease threats such adaptable modelling capabilities that can rapidly incorporate diverse data sources and domain expertise are essential for future public health decision making.

## Acknowledgements

# References {.unnumbered}

::: {#refs}
:::