---
title: "A Prototype for Compositional Probabilistic Infectious Disease Modelling"
author:
  - name: "Samuel P. C. Brand"
    affiliation: "Center for Forecasting and Outbreak Analysis; Centers for Disease Control"
    email: "usi1@cdc.gov"
    orcid: "0000-0003-0645-5367"
  - name: "Samuel Abbott"
    affiliation: "Centre for Mathematical Modelling of Infectious Diseases, London School of Hygiene & Tropical Medicine"
    email: "sam.abbott@lshtm.ac.uk" 
    orcid: "0000-0001-8057-8037"
date: today
abstract: |
  This paper presents a compositional approach to epidemiological modelling that enables "swap-in/swap-out" modelling decisions. We demonstrate the flexibility and power of this paradigm through three case studies that recreate existing infectious disease models using compositional components, showing how this design facilitates model comparison, validation, and methodological transparency in epidemiological research.
format:
  pdf:
    documentclass: article
    geometry: margin=1in
    fontsize: 11pt
    linestretch: 1.5
    keep-tex: false
    number-sections: false
    colorlinks: true
  html:
    toc: true
    number-sections: true
    embed-resources: true
bibliography: references.bib
csl: https://www.zotero.org/styles/plos-computational-biology
execute:
  echo: true
  warning: false
  cache: true
  output: false
julia: 
  exeflags: ["+1.11.6", "--threads=8", "-O3"]
---

# Introduction {#sec-introduction}

<!-- Problem statement -->
- Recent outbreaks of Ebola, COVID-19 and mpox have demonstrated the value of modelling for synthesising data for rapid evidence to inform decision making.
- Infectious diseases spread through complex interactions between biology, human behaviour, economic factors, and environmental conditions that must all be understood to control transmission effectively.
- However, it can be difficult for infectious disease modellers to work effectively with experts from other fields.
- Attempts to include insights from environmental scientists, economists, or behavioural researchers typically result in models that are either too complex to use practically or too simplified to capture valuable expertise.
- Individual-level data sources such as viral loads, biomarkers, and clinical measurements are often ignored or crudely aggregated when informing population-level models, losing information that could help improve decisions.
- This creates barriers to sharing methods and leads to inefficient rebuilding of models when components from existing models could be reused.

<!-- Current approaches in epidemiology -->
- Existing approaches for real-time modelling of infectious disease dynamics usually fall into one of two categories, each with significant drawbacks.
- Pipeline approaches combine results from separate models without uncertainty propagation, leading to loss of detail and statistical rigour.
- Joint approaches use single monolithic models designed for specific scenarios.
- Whilst powerful in their ability to systematically integrate multiple processes and data streams, such models and their implementations are too complex to enable transfer to other settings or extension with additional model components or data sets, preventing effective integration of expertise across disciplines.
- Model inflexibility has been identified by major public health agencies including WHO, UKHSA, and CDC as a key barrier to effective outbreak response.

<!-- Solutions from other fields -->
- Recent advances in other scientific computing domains demonstrate the potential of compositional approaches to overcome these limitations.
- Category theory provides mathematical foundations through operadic composition that enables hierarchical model construction where complex models are built by composing simpler submodels using mathematically rigorous operations.
- SpeedyWeather.jl exemplifies this "LEGO-like" approach in atmospheric modelling, providing an interactive domain-specific language that emphasises rapid prototyping and modular component assembly.
- ModelingToolkit.jl extends composability beyond ordinary differential equations to support mixed equation types including differential-algebraic equations, partial differential equations, and stochastic differential equations through abstract computational backends.
- Recent developments in probabilistic programming, particularly in Turing.jl, enable composable approaches through submodel interfaces that properly propagate uncertainty whilst maintaining modular design.

<!-- This prototype work -->
- This work presents a prototype compositional probabilistic infectious disease modelling framework that combines the modularity of pipeline approaches with the statistical rigour of joint models.
- Our prototype enables "swap-in/swap-out" modelling decisions through standardised interfaces that properly propagate uncertainty whilst supporting composability beyond ordinary differential equations through mixed component models and abstract backends.
- We create a domain-specific language operating as a package extension that provides dual interfaces: a high-level interface for epidemiologists through the EpiProblem constructor, and a low-level Turing interface for methodologists requiring fine-grained control.
- The framework enables domain experts to develop models tailored to their specific expertise and combine them with components developed by specialists in other fields, bridging individual-level clinical data with population-level transmission models.
- We demonstrate the prototype's capabilities through three epidemiological case studies using our EpiAware package, showing how this design facilitates model comparison, validation, and methodological transparency in epidemiological research.

# Prototype Implementation {#sec-approach}

## Requirements for Compositional Systems {#sec-requirements}

- Our compositional approach must satisfy several key requirements to enable effective epidemiological modelling across diverse scenarios and expertise domains.
- The framework requires abstract types for generic model objects that can represent different classes of epidemiological processes whilst maintaining clear interfaces between components.
- Model definitions must be data-agnostic to enhance generalisability whilst ensuring proper uncertainty propagation through standardised interfaces that maintain statistical rigour when components are combined.
- The system must support stratification handling for arbitrary groupings such as age groups, locations, or risk groups with easy-to-use interfaces for common mappings between process and observation models.
- Crucially, the framework must extend beyond ordinary differential equations to support mixed equation types, abstract computational backends, and integration with diverse modelling approaches including agent-based models and symbolic-numeric computation.
- Interface enforcement through Julia's type system and tools like Interfaces.jl ensures consistent APIs across components whilst maintaining the type stability necessary for computational performance.

## Design Philosophy {#sec-design}

- Our prototype treats epidemiological models as collections of interchangeable components that maintain full uncertainty propagation when combined through standardised interfaces.
- The framework leverages Julia's advanced type system and multiple dispatch to create a domain-specific language for epidemiological modelling where complex models emerge from composing simpler, reusable components.
- Dispatch occurs at the Turing probabilistic programming language level, but the architecture is designed to support arbitrary computational backends including ODE solvers, agent-based models, and symbolic-numeric systems.
- We chose Turing.jl as our initial backend because it provides a flexible probabilistic programming framework with robust submodel support, extensive inference algorithms applicable to epidemiological models, and the ability to handle complex hierarchical model structures with minimal boilerplate code.
- This design eliminates the "two-language problem" by allowing high-level model specifications that compile to efficient code whilst Julia's metaprogramming capabilities enable domain-specific abstractions that hide implementation complexity from users.

## Domain-Specific Language Structure {#sec-dsl}

<!-- Reference to Panel A of Figure 1 -->
- The core of our prototype is a domain-specific language built on Julia's type system using abstract types to define a hierarchy of epidemiological model components.
- We employ a struct-in-struct composition pattern that enables recursive model building where complex models are constructed by nesting simpler component models within container structures.
- The abstract type hierarchy includes `AbstractEpiModel` for infection generating processes, `AbstractLatentModel` for time-varying parameter evolution, and `ObservationModel` for linking latent processes to observed data.
- Multiple dispatch enables flexible component combination at the Turing level whilst maintaining the potential to abstract this dispatch to target different computational backends such as ODE solvers or agent-based modelling frameworks.
- Our domain-specific language operates as a package extension pattern where the high-level epidemiological interface is built as a layer over a standard Julia package, ensuring that all tools maintain dual interfaces for different user needs.

## Dual Interface Design {#sec-interfaces}

<!-- Reference to Panel C of Figure 1 -->
- The prototype provides two complementary interfaces to accommodate users with different expertise levels and requirements.
- The high-level interface centres around the `EpiProblem` constructor that combines an `epi_model`, `latent_model`, and `observation_model` with a time span, providing an accessible entry point for epidemiologists who want to focus on model structure rather than implementation details.
- The low-level interface exposes direct Turing model construction for methodologists requiring fine-grained control over probabilistic model specification, inference configuration, and computational optimization.
- Both interfaces maintain full composability and uncertainty propagation, ensuring that domain experts can use the simplified high-level approach whilst methods developers can extend and customize using the flexible low-level interface.
- This design pattern enables the framework to serve as both a user-friendly tool for applied epidemiologists and a research platform for methodological development.

## Example: Composing ARIMA Models {#sec-arima-example}

<!-- Reference to Panel B of Figure 1 -->
- To illustrate the compositional approach, we demonstrate building an ARIMA model as a stack of reusable components.
- In our framework, an ARIMA(p,d,q) process can be constructed by composing a moving average (`MA`) component, an autoregressive (`AR`) component, and a differencing (`DiffLatentModel`) component.

```julia
# Example struct definitions showing composition
struct MA <: AbstractLatentModel
    q::Int
    ma_priors::Vector{Distribution}
    init_priors::Vector{Distribution}
    ϵ_t::HierarchicalNormal
end

struct AR <: AbstractLatentModel
    damp_priors::Vector{Distribution}
    init_priors::Vector{Distribution}
    ϵ_t::HierarchicalNormal
end

struct DiffLatentModel <: AbstractLatentModel
    d::Int
    model::AbstractLatentModel
end

# Composition through nesting
arima_model = DiffLatentModel(
    d = 1,
    model = AR(
        damp_priors = [Normal(0.5, 0.2)],
        init_priors = [Normal(0.0, 1.0)],
        ϵ_t = HierarchicalNormal(std_prior = HalfNormal(0.5))
    )
)
```

- The dispatch system automatically handles the recursive composition, with each component contributing its probabilistic behaviour to the overall model whilst maintaining mathematical consistency and enabling component swapping for model comparison.

**Figure 1**: Compositional Modelling Architecture
*Panel A*: Generic composition pattern showing struct-in-struct hierarchy with recursive dispatch through abstract type system.
*Panel B*: ARIMA composition example demonstrating component stacking with struct definitions.
*Panel C*: Dual interface schematic showing high-level EpiProblem and low-level Turing interfaces operating as package extension.
*Panel D*: Backend abstraction architecture with Turing as current implementation and potential for ODE, agent-based, and other computational backends.

# Case Studies {#sec-case-studies}

All code and data for reproducing the analyses in this paper are available at: https://github.com/EpiAware/PrototypeCompositionalProbablisticInfectiousDiseaseModelling.

## Standard Case Study Format

Each case study follows this standardised structure to ensure consistency and clarity:

### **Overview**
A concise paragraph explaining:
- The original paper and its contribution
- Why we selected this study for replication
- Key features of our compositional prototype demonstrated (e.g., model modularity, component reusability, transparent priors)

### **Data**
Brief description of the dataset with a single code block loading the data.

### **Model**
Compositional model specification with subsections:

#### **Infection Generating Process**
- Mathematical formulation
- Code implementation using `AbstractEpiModel` types
- Prior predictive checking

#### **Observation Model**
- Mathematical formulation
- Code implementation using `ObservationModel` types
- Prior predictive checking

### **Fitting to Data**
- Model composition into `EpiProblem`
- Inference configuration
- Posterior sampling
- Posterior predictive checking

### **Summary Figure**
Panel figure combining all visualisations:
- Prior predictive plots for each model component
- Posterior predictive plots showing model fit
- Parameter inference summaries

### **Code Organisation Principles**
- Dependencies imported when first needed, not in large blocks
- Each code statement in separate block with explanatory text before and after
- Minimal, clear code focused on demonstrating compositional concepts
- Mathematical formulation precedes code implementation for each component

## On the derivation of the renewal equation from an age-dependent branching process: an epidemic modelling perspective {#sec-example1}

<!-- Reference: https://arxiv.org/abs/2006.16487 -->

<!-- Implementation: https://cdcgov.github.io/Rt-without-renewal/stable/showcase/replications/mishra-2020/ -->

In this example we use `EpiAware` functionality to largely recreate an epidemiological model presented in [On the derivation of the renewal equation from an age-dependent branching process: an epidemic modelling perspective, *Mishra et al* (2020)](https://arxiv.org/abs/2006.16487).
*Mishra et al* consider test-confirmed cases of COVID-19 in South Korea between January to July 2020.
The components of the epidemilogical model they consider are:

-   The time varying reproductive number modelled as an [AR(2) process](https://en.wikipedia.org/wiki/Autoregressive_model) on the log-scale $\log R_t \sim \text{AR(2)}$.
-   The latent infection ($I_t$) generating process is a renewal model (note that we leave out external infections in this note): $$
    I_t = R_t \sum_{s\geq 1} I_{t-s} g_s.
    $$
-   The discrete generation interval $g_t$ is a daily discretisation of the probability mass function of an estimated serial interval distribution for SARS-CoV-2: $$
    G \sim \text{Gamma}(6.5,0.62).
    $$
-   Observed cases $C_t$ are distributed around latent infections with negative binomial errors: $$
    C_t \sim \text{NegBin}(\text{mean} = I_t,~ \text{overdispersion} = \phi).
    $$

In the examples below we are going to largely recreate the *Mishra et al* model, whilst emphasing that each component of the overall epidemiological model is, itself, a stand alone model that can be sampled from.

### Dependencies and setup

```{julia}
using EpiAware
using Turing, DynamicPPL #Underlying Turing ecosystem packages to interact with models
using Distributions, Statistics #Statistics packages
using CSV, DataFramesMeta #Data wrangling
using CairoMakie, PairPlots, TimeSeries #Plotting backend
using ReverseDiff #Automatic differentiation backend
CairoMakie.activate!(type = "png") # Compatible format

#Date utility and set Random seed
using Dates
using Random
Random.seed!(1234)
```

### Load early SARS-2 case data for South Korea

First, we make sure that we have the data we want to analysis in scope by downloading it for where we have saved a copy in the `EpiAware` repository.

NB: The case data is curated by the [`covidregionaldata`](https://github.com/epiforecasts/covidregionaldata) package.
We accessed the South Korean case data using a short [R script](https://github.com/CDCgov/Rt-without-renewal/blob/main/EpiAware/docs/src/showcase/replications/mishra-2020/get_data.R).
It is possible to interface directly from a Julia session using the `RCall.jl` package, but we do not do this in this notebook to reduce the number of underlying dependencies required to run this notebook.

```{julia}
data = CSV.read("data/south_korea_data.csv", DataFrame)
```

### Time-varying reproduction number as an `AbstractLatentModel` type

`EpiAware` exposes a `AbstractLatentModel` abstract type; the purpose of which is to group stochastic processes which can be interpreted as generating time-varying parameters/quantities of interest which we call latent process models.

In the *Mishra et al* model the log-time varying reproductive number $Z_t$ is assumed to evolve as an auto-regressive process, AR(2):

\begin{align}
R_t &= \exp Z_t, \\
Z_t &= \rho_1 Z_{t-1} + \rho_2 Z_{t-2} + \epsilon_t, \\
\epsilon_t &\sim \text{Normal}(0, \sigma^*).
\end{align}

Where $\rho_1,\rho_2$, which are the parameters of AR process, and $\epsilon_t$ is a white noise process with standard deviation $\sigma^*$.

In `EpiAware` we determine the behaviour of a latent process by choosing a concrete subtype (i.e. a struct) of `AbstractLatentModel` which has fields that set the priors of the various parameters required for the latent process.

The AR process has the struct `AR <: AbstractLatentModel`.
The user can supply the priors for $\rho_1,\rho_2$ in the field `damp_priors`, for $\sigma^*$ in the field `std_prior`, and the initial values $Z_1, Z_2$ in the field `init_priors`.

We choose priors based on *Mishra et al* using the `Distributions.jl` interface to probability distributions.
Note that we condition the AR parameters onto $[0,1]$, as in *Mishra et al*, using the `truncated` function.

In *Mishra et al* the standard deviation of the *stationary distribution* of $Z_t$ which has a standard normal distribution conditioned to be positive $\sigma \sim \mathcal{N}^+(0,1)$.
The value $σ^*$ was determined from a nonlinear function of sampled $\sigma, ~\rho_1, ~\rho_2$ values.
Since, *Mishra et al* give sharply informative priors for $\rho_1,~\rho_2$ (see below) we simplify by calculating $\sigma^*$ at the prior mode of $\rho_1,~\rho_2$.
This results in a $\sigma^* \sim \mathcal{N}^+(0, 0.5)$ prior.

```{julia}
ar = AR(
    damp_priors = [truncated(Normal(0.1, 0.05), 0, 1),
        truncated(Normal(0.8, 0.05), 0, 1)],
    init_priors = [Normal(-1.0, 0.1), Normal(-1.0, 0.5)],
    ϵ_t = HierarchicalNormal(std_prior = HalfNormal(0.5))
)
```

#### `Turing` model interface to the AR process

As mentioned above, we can use this instance of the `AR` latent model to construct a [`Turing`](https://turinglang.org/) model object which implements the probabilistic behaviour determined by `ar`.
We do this with the constructor function exposed by `EpiAware`: `generate_latent` which combines an `AbstractLatentModel` substype struct with the number of time steps for which we want to generate the latent process.

As a refresher, we remind that the `Turing.Model` object has the following properties:

-   The model object parameters are sampleable using `rand`; that is we can generate parameters from the specified priors e.g. `θ = rand(mdl)`.
-   The model object is generative as a callable; that is we can sample instances of $Z_t$ e.g. `Z_t = mdl()`.
-   The model object can construct new model objects by conditioning parameters using the [`DynamicPPL.jl`](https://turinglang.org/DynamicPPL.jl/stable/) syntax, e.g. `conditional_mdl = mdl | (σ_AR = 1.0, )`.

As a concrete example we create a model object for the AR(2) process we specified above for 50 time steps:

```{julia}
ar_mdl = generate_latent(ar, 50)
```

Ultimately, this will only be one component of the full epidemiological model.
However, it is useful to visualise its probabilistic behaviour for model diagnostic and prior predictive checking.

We can spaghetti plot generative samples from the AR(2) process with the priors specified above.

```{julia}
#| output: true
#| label: fig-ar-sample
#| echo: false
n_samples = 100
ar_mdl_samples = mapreduce(hcat, 1:n_samples) do _
    ar_mdl() .|> exp #Sample Z_t trajectories for the model
end

fig = Figure()
ax = Axis(fig[1, 1];
    yscale = log10,
    ylabel = "Time varying Rₜ",
    title = "$(n_samples) draws from the prior Rₜ model"
)
for col in eachcol(ar_mdl_samples)
    lines!(ax, col, color = (:grey, 0.1))
end
fig
```

This suggests that *a priori* we believe that there is a few percent chance of achieving very high $R_t$ values, i.e. $R_t \sim 10-1000$ is not excluded by our priors.

### The Renewal model as an `AbstractEpiModel` type

The abstract type for models that generate infections exposed by `EpiAware` is called `AbstractEpiModel`.
As with latent models different concrete subtypes of `AbstractEpiModel` define different classes of infection generating process.
In this case we want to implement a renewal model.

The `Renewal <: AbstractEpiModel` type of struct needs two fields:

-   Data about the generation interval of the infectious disease so it can construct $g_t$.
-   A prior for the initial numbers of infected.

In *Mishra et al* they use an estimate of the serial interval of SARS-CoV-2 as an estimate of the generation interval.

```{julia}
truth_GI = Gamma(6.5, 0.62)
```

This is a representation of the generation interval distribution as continuous whereas the infection process will be formulated in discrete daily time steps.
By default, `EpiAware` performs [double interval censoring](https://www.medrxiv.org/content/10.1101/2024.01.12.24301247v1) to convert our continuous estimate of the generation interval into a discretized version $g_t$, whilst also applying left truncation such that $g_0 = 0$ and normalising $\sum_t g_t = 1.$

The constructor for converting a continuous estimate of the generation interval distribution into a usable discrete time estimate is `EpiData`.

```{julia}
model_data = EpiData(gen_distribution = truth_GI)
```

We can compare the discretized generation interval with the continuous estimate, which in this example is the serial interval estimate.

```{julia}
#| output: true
#| echo: false
#| label: fig-discretised-gen-pmf
fig = Figure()
ax = Axis(fig[1, 1];
    xticks = 0:14,
    xlabel = "Days",
    title = "Continuous and discrete generation intervals"
)
barplot!(ax, model_data.gen_int;
    label = "Discretized next gen pmf"
)
lines!(truth_GI;
    label = "Continuous serial interval",
    color = :green
)
axislegend(ax)
fig
```

The user also needs to specify a prior for the log incidence at time zero, $\log I_0$.
The initial *history* of latent infections $I_{-1}, I_{-2},\dots$ is constructed as $$
I_t = e^{rt} I_0,\qquad t = 0, -1, -2,...
$$ Where the exponential growth rate $r$ is determined by the initial reproductive number $R_1$ via the solution to the implicit equation, $$
R_1 = 1 \Big{/} \sum_{t\geq 1} e^{-rt} g_t
$$

```{julia}
log_I0_prior = Normal(log(1.0), 1.0)
epi = Renewal(model_data; initialisation_prior = log_I0_prior)
```

*NB: We don't implement a background infection rate in this model.*

#### `Turing` model interface to `Renewal` process

As mentioned above, we can use this instance of the `Renewal` latent infection model to construct a `Turing` `Model` which implements the probabilistic behaviour determined by `epi` using the constructor function `generate_latent_infs` which combines `epi` with a provided $\log R_t$ time series.

Here we choose an example where $R_t$ decreases from $R_t = 3$ to $R_t = 0.5$ over the course of 50 days.

```{julia}
#| output: true
#| echo: false
#| label: fig-gen-epi
R_t_fixed = [0.5 + 2.5 / (1 + exp(t - 15)) for t in 1:50]
latent_inf_mdl = generate_latent_infs(epi, log.(R_t_fixed))

n_samples = 100
#Sample unconditionally the underlying parameters of the model
epi_mdl_samples = mapreduce(hcat, 1:n_samples) do _
    latent_inf_mdl()
end
fig = Figure()
ax1 = Axis(fig[1, 1];
    title = "$(n_samples) draws from renewal model with chosen Rt",
    ylabel = "Latent infections"
)
ax2 = Axis(fig[2, 1];
    ylabel = "Rt"
)
for col in eachcol(epi_mdl_samples)
    lines!(ax1, col;
        color = (:grey, 0.1)
    )
end
lines!(ax2, R_t_fixed;
    linewidth = 2
)
fig
```

### Negative Binomial Observations as an `ObservationModel` type

In *Mishra et al* latent infections were assumed to occur on their observation day with negative binomial errors, this motivates using the serial interval (the time between onset of symptoms of a primary and secondary case) rather than generation interval distribution (the time between infection time of a primary and secondary case).

Observation models are set in `EpiAware` as concrete subtypes of an `ObservationModel`.
The Negative binomial error model without observation delays is set with a `NegativeBinomialError` struct.
In *Mishra et al* the overdispersion parameter $\phi$ sets the relationship between the mean and variance of the negative binomial errors, $$
\text{var} = \text{mean} + {\text{mean}^2 \over \phi}.
$$ In `EpiAware`, we default to a prior on $\sqrt{1/\phi}$ because this quantity is approximately the coefficient of variation of the observation noise and, therefore, is easier to reason on *a priori* beliefs.
We call this quantity the cluster factor.

A prior for $\phi$ was not specified in *Mishra et al*, we select one below but we will condition a value in analysis below.

```{julia}
obs = NegativeBinomialError(cluster_factor_prior = HalfNormal(0.1))
```

#### `Turing` model interface to the `NegativeBinomialError` model

We can construct a `NegativeBinomialError` model implementation as a `Turing` `Model` using the `EpiAware` `generate_observations` functions.

`Turing` uses `missing` arguments to indicate variables that are to be sampled.
We use this to observe a forward model that samples observations, conditional on an underlying expected observation time series.

First, we set an artificial expected cases curve.

```{julia}
#| output: true
#| echo: false
#| label: fig-discretised-gen-cases
expected_cases = [1000 * exp(-(t - 15)^2 / (2 * 4)) for t in 1:30]
obs_mdl = generate_observations(obs, missing, expected_cases)

n_samples = 100
obs_mdl_samples = mapreduce(hcat, 1:n_samples) do _
    θ = obs_mdl() #Sample unconditionally the underlying parameters of the model
end
fig = Figure()
ax = Axis(fig[1, 1];
    title = "$(n_samples) draws from neg. bin. obs model",
    ylabel = "Observed cases"
)
for col in eachcol(obs_mdl_samples)
    scatter!(ax, col;
        color = (:grey, 0.2)
    )
end
lines!(ax, expected_cases;
    color = :red,
    linewidth = 3,
    label = "Expected cases"
)
axislegend(ax)
fig
```

### Composing models into an `EpiProblem`

*Mishra et al* follows a common pattern of having an infection generation process driven by a latent process with an observation model that links the infection process to a discrete valued time series of incidence data.

In `EpiAware` we provide an `EpiProblem` constructor for this common epidemiological model pattern.

The constructor for an `EpiProblem` requires: - An `epi_model`.
- A `latent_model`.
- An `observation_model`.
- A `tspan`.

The `tspan` set the range of the time index for the models.

```{julia}
epi_prob = EpiProblem(epi_model = epi,
    latent_model = ar,
    observation_model = obs,
    tspan = (45, 80))
```

### Inference Methods

We make inferences on the unobserved quantities, such as $R_t$ by sampling from the model conditioned on the observed data.
We generate the posterior samples using the No U-Turns (NUTS) sampler.

To make NUTS more robust we provide `manypathfinder`, which is built on pathfinder variational inference from [Pathfinder.jl](https://mlcolab.github.io/Pathfinder.jl/stable/).
`manypathfinder` runs `nruns` pathfinder processes on the inference problem and returns the pathfinder run with maximum estimated ELBO.

The composition of doing variational inference as a pre-sampler step which gets passed to NUTS initialisation is defined using the `EpiMethod` struct, where a sequence of pre-sampler steps can be be defined.

`EpiMethod` also allows the specification of NUTS parameters, such as type of automatic differentiation, type of parallelism and number of parallel chains to sample.

```{julia}
num_threads = min(10, Threads.nthreads())

inference_method = EpiMethod(
    pre_sampler_steps = [ManyPathfinder(nruns = 4, maxiters = 100)],
    sampler = NUTSampler(
        adtype = AutoReverseDiff(compile = true),
        ndraws = 2000,
        nchains = num_threads,
        mcmc_parallel = MCMCThreads(),
        nadapts= 500)
)
```

### Inference and analysis

We supply the data as a `NamedTuple` with the `y_t` field containing the observed data, shortened to fit the chosen `tspan` of `epi_prob`.

```{julia}
south_korea_data = (y_t = data.cases_new[epi_prob.tspan[1]:epi_prob.tspan[2]],
    dates = data.date[epi_prob.tspan[1]:epi_prob.tspan[2]])
```

In the epidemiological model it is hard to identify between the AR parameters such as the standard deviation of the AR process and the cluster factor of the negative binomial observation model.
The reason for this identifiability problem is that the model assumes no delay between infection and observation.
Therefore, on any day the data could be explained by $R_t$ changing *or* observation noise and its not easy to disentangle greater volatility in $R_t$ from higher noise in the observations.

In models with latent delays, changes in $R_t$ impact the observed cases over several days which means that it easier to disentangle trend effects from observation-to-observation fluctuations.

To counter act this problem we condition the model on a fixed cluster factor value.

```{julia}
fixed_cluster_factor = 0.25
```

`EpiAware` has the `generate_epiaware` function which joins an `EpiProblem` object with the data to produce as `Turing` model.
This `Turing` model composes the three unit `Turing` models defined above: the Renewal infection generating process, the AR latent process for $\log R_t$, and the negative binomial observation model.
Therefore, [we can condition on variables as with any other `Turing` model](https://turinglang.org/DynamicPPL.jl/stable/api/#Condition-and-decondition).

```{julia}
mdl = generate_epiaware(epi_prob, south_korea_data) |
      (var"obs.cluster_factor" = fixed_cluster_factor,)
```

#### Sampling with `apply_method`

The `apply_method` function combines the elements above: - An `EpiProblem` object or `Turing` model.
- An `EpiMethod` object.
- Data to condition the model upon.

And returns a collection of results: - The epidemiological model as a `Turing` `Model`.
- Samples from MCMC.
- Generated quantities of the model.

```{julia}
inference_results = apply_method(mdl,
    inference_method,
    south_korea_data
)
```

#### Results and Predictive plotting

To assess the quality of the inference visually we can plot predictive quantiles for generated case data from the version of the model *which hasn't conditioned on case data* using posterior parameters inferred from the version conditioned on observed data.
For this purpose, we add a `generated_quantiles` utility function.
This kind of visualisation is known as *posterior predictive checking*, and is a useful diagnostic tool for Bayesian inference (see [here](http://www.stat.columbia.edu/~gelman/book/BDA3.pdf)).

We also plot the inferred $R_t$ estimates from the model.
We find that the `EpiAware` model recovers the main finding in *Mishra et al*; that the $R_t$ in South Korea peaked at a very high value ($R_t \sim 10$ at peak) before rapidly dropping below 1 in early March 2020.

Note that, in reality, the peak $R_t$ found here and in *Mishra et al* is unrealistically high, this might be due to a combination of: - A mis-estimated generation interval/serial interval distribution.
- An ascertainment rate that was, in reality, changing over time.

In a future note, we'll demonstrate having a time-varying ascertainment rate.

```{julia}
#| output: true
#| echo: false
#| label: fig-posterior-preds
function generated_quantiles(gens, quantity, qs; transformation = x -> x)
    mapreduce(hcat, gens) do gen #loop over sampled generated quantities
        getfield(gen, quantity) |> transformation
    end |> mat -> mapreduce(hcat, qs) do q #Loop over matrix row to condense into qs
        map(eachrow(mat)) do row
            if any(ismissing, row)
                return missing
            else
                quantile(row, q)
            end
        end
    end
end

let
    C = south_korea_data.y_t
    D = south_korea_data.dates

    #Case unconditional model for posterior predictive sampling
    mdl_unconditional = generate_epiaware(epi_prob,
        (y_t = fill(missing, length(C)),)
    ) | (var"obs.cluster_factor" = fixed_cluster_factor,)
    posterior_gens = generated_quantities(mdl_unconditional, inference_results.samples)

    #plotting quantiles
    qs = [0.025, 0.25, 0.5, 0.75, 0.975]

    #Prediction quantiles
    predicted_y_t = generated_quantiles(posterior_gens, :generated_y_t, qs)
    predicted_R_t = generated_quantiles(
        posterior_gens, :Z_t, qs; transformation = x -> exp.(x))

    ts = D .|> d -> d - minimum(D) .|> d -> d.value + 1
    t_ticks = string.(D)
    fig = Figure()
    ax1 = Axis(fig[1, 1];
        ylabel = "Daily cases",
        xticks = (ts[1:14:end], t_ticks[1:14:end]),
        title = "Posterior predictive: Cases"
    )
    ax2 = Axis(fig[2, 1];
        yscale = log10,
        title = "Prediction: Reproduction number",
        xticks = (ts[1:14:end], t_ticks[1:14:end])
    )
    linkxaxes!(ax1, ax2)

    lines!(ax1, ts, predicted_y_t[:, 3];
        color = :purple,
        linewidth = 2,
        label = "Post. median"
    )
    band!(ax1, 1:size(predicted_y_t, 1), predicted_y_t[:, 2], predicted_y_t[:, 4];
        color = (:purple, 0.4),
        label = "50%"
    )
    band!(ax1, 1:size(predicted_y_t, 1), predicted_y_t[:, 1], predicted_y_t[:, 5];
        color = (:purple, 0.2),
        label = "95%"
    )
    scatter!(ax1, C;
        color = :black,
        label = "Actual cases")
    axislegend(ax1)

    lines!(ax2, ts, predicted_R_t[:, 3];
        color = :green,
        linewidth = 2,
        label = "Post. median"
    )
    band!(ax2, 1:size(predicted_R_t, 1), predicted_R_t[:, 2], predicted_R_t[:, 4];
        color = (:green, 0.4),
        label = "50%"
    )
    band!(ax2, 1:size(predicted_R_t, 1), predicted_R_t[:, 1], predicted_R_t[:, 5];
        color = (:green, 0.2),
        label = "95%"
    )
    axislegend(ax2)

    fig
end
```

#### Parameter inference

We can interrogate the sampled chains directly from the `samples` field of the `inference_results` object.

```{julia}
#| output: true
#| echo: false
#| label: fig-pairwise
sub_chn = inference_results.samples[inference_results.samples.name_map.parameters[[1:5;
                                                                                   end]]]
fig = pairplot(sub_chn)
lines!(fig[1, 1], ar.init_prior.v[1], label = "Prior")
lines!(fig[2, 2], ar.init_prior.v[2], label = "Prior")
lines!(fig[3, 3], ar.damp_prior.v[1], label = "Prior")
lines!(fig[4, 4], ar.damp_prior.v[2], label = "Prior")
lines!(fig[5, 5], ar.ϵ_t.std_prior, label = "Prior")
lines!(fig[6, 6], epi.initialisation_prior, label = "Prior")
fig
```

## EpiNow2: Estimate Real-Time Case Counts and Time-Varying Epidemiological Parameters {#sec-example2}

<!-- Reference: https://epiforecasts.io/EpiNow2/ -->

This case study recreates a representative EpiNow2 configuration, demonstrating how our compositional approach can represent a complex inference and forecasting workflow.

-   Describe modelling ideas in @epinow2
    -   Renewal based modelling with generation intervals\
    -   Delayed observations of count time series (e.g. cases)
    -   Negative binomial link with modifiers (e.g. day of week effects)
    -   Focus on core functionality already implemented
-   Describe compositional model that recreates this model
-   Figure 3: Based on existing EpiNow2 replication work
    -   **Panel ABC**: Recreate getting started first three panel plot https://epiforecasts.io/EpiNow2/articles/EpiNow2.html

## Contemporary statistical inference for infectious disease models using Stan {#sec-example3}

<!-- Reference: https://www.sciencedirect.com/science/article/pii/S1755436519300325 -->

<!-- Implementation: https://cdcgov.github.io/Rt-without-renewal/stable/showcase/replications/chatzilena-2019/ -->

In this vignette, we'll demonstrate how to use `EpiAware` in conjunction with [SciML ecosystem](https://sciml.ai/) for Bayesian inference of infectious disease dynamics.
The model and data is heavily based on [Contemporary statistical inference for infectious disease models using Stan *Chatzilena et al. 2019*](https://www.sciencedirect.com/science/article/pii/S1755436519300325).

We'll cover the following key points:

1.  Defining the deterministic ODE model from Chatzilena et al section 2.2.2 using SciML ODE functionality and an `EpiAware` observation model.
2.  Build on this to define the stochastic ODE model from Chatzilena et al section 2.2.3 using an `EpiAware` observation model.
3.  Fitting the deterministic ODE model to data from an Influenza outbreak in an English boarding school.
4.  Fitting the stochastic ODE model to data from an Influenza outbreak in an English boarding school.

### Packages used in this vignette

Alongside the `EpiAware` package we will use the `OrdinaryDiffEq` and `SciMLSensitivity` packages for interfacing with `SciML` ecosystem; this is a lower dependency usage of `DifferentialEquations.jl` that, respectively, exposes ODE solvers and adjoint methods for ODE solvees; that is the method of propagating parameter derivatives through functions containing ODE solutions.
Bayesian inference will be done with `NUTS` from the `Turing` ecosystem.
We will also use the `CairoMakie` package for plotting and `DataFramesMeta` for data manipulation.

```{julia}
using OrdinaryDiffEqTsit5, OrdinaryDiffEqRosenbrock, SciMLSensitivity #ODE solvers and adjoint methods
using LogExpFunctions #Additional statistics functions

```

### Single population SIR model

As mentioned in *Chatzilena et al* disease spread is frequently modelled in terms of ODE-based models.
The study population is divided into compartments representing a specific stage of the epidemic status.
In this case, susceptible, infected, and recovered individuals.

\begin{align}
{dS \over dt} &= - \beta \frac{I(t)}{N} S(t) \\
{dI \over dt} &= \beta \frac{I(t)}{N} S(t) - \gamma I(t) \\
{dR \over dt} &= \gamma I(t).
\end{align}

where S(t) represents the number of susceptible, I(t) the number of infected and R(t) the number of recovered individuals at time t.
The total population size is denoted by N (with N = S(t) + I(t) + R(t)), β denotes the transmission rate and γ denotes the recovery rate.

We can interface to the `SciML` ecosystem by writing a function with the signature:

> `(du, u, p, t) -> nothing`

Where: - `du` is the *vector field* of the ODE problem, e.g. ${dS \over dt}$, ${dI \over dt}$ etc.
This is calculated *in-place* (commonly denoted using ! in function names in Julia).
- `u` is the *state* of the ODE problem, e.g. $S$, $I$, etc. - `p` is an object that represents the parameters of the ODE problem, e.g. $\beta$, $\gamma$.
- `t` is the time of the ODE problem.

We do this for the SIR model described above in a function called `sir!`:

```{julia}
function sir!(du, u, p, t)
    S, I, R = u
    β, γ = p
    du[1] = -β * I * S
    du[2] = β * I * S - γ * I
    du[3] = γ * I

    return nothing
end
```

We combine vector field function `sir!` with a initial condition `u0` and the integration period `tspan` to make an `ODEProblem`.
We do not define the parameters, these will be defined within an inference approach.

Note that this is analogous to the `EpiProblem` approach we expose from `EpiAware`, as used in the [Mishra et al replication](https://cdcgov.github.io/Rt-without-renewal/dev/showcase/replications/mishra-2020/).
The difference is that here we are going to use ODE solvers from the `SciML` ecosystem to generate the dynamics of the underlying infections.
In the linked example, we use latent process generation exposed by `EpiAware` as the underlying generative process for underlying dynamics.

### Data for inference

There was a brief, but intense, outbreak of Influenza within the (semi-) closed community of a boarding school reported to the British medical journal in 1978.
The outbreak lasted from 22nd January to 4th February and it is reported that one infected child started the epidemic and then it spread rapidly.
Of the 763 children at the boarding scholl, 512 became ill.

We downloaded the data of this outbreak using the R package `outbreaks` which is maintained as part of the [R Epidemics Consortium(RECON)](http://www.%20repidemicsconsortium.org).

```{julia}
data = CSV.read("data/influenza_england_1978_school.csv", DataFrame) |>
              df -> @transform(df,
    :ts=(:date .- minimum(:date)) .|> d -> d.value + 1.0,)

N = 763

sir_prob = ODEProblem(
    sir!,
    N .* [0.99, 0.01, 0.0],
    (0.0, (Date(1978, 2, 4) - Date(1978, 1, 22)).value + 1)
)
```

### Inference for the deterministic SIR model

The boarding school data gives the number of children "in bed" and "convalescent" on each of 14 days from 22nd Jan to 4th Feb 1978.
We follow *Chatzilena et al* and treat the number "in bed" as a proxy for the number of children in the infectious (I) compartment in the ODE model.

The full observation model is:

\begin{align}
Y_t &\sim \text{Poisson}(\lambda_t)\\
\lambda_t &= I(t)\\
\beta &\sim \text{LogNormal}(\text{logmean}=0,\text{logstd}=1) \\
\gamma & \sim \text{Gamma}(\text{shape} = 0.004, \text{scale} = 50)\\
S(0) /N &\sim \text{Beta}(0.5, 0.5).
\end{align}

**NB: Chatzilena et al give** $\lambda_t = \int_0^t  \beta \frac{I(s)}{N} S(s) - \gamma I(s)ds = I(t) - I(0).$ However, this doesn't match their underlying stan code.

From `EpiAware`, we have the `PoissonError` struct which defines the probabilistic structure of this observation error model.

```{julia}
obs = PoissonError()
```

Now we can write the probabilistic model using the `Turing` PPL. Note that instead of using $I(t)$ directly we do the [softplus](https://en.wikipedia.org/wiki/Softplus) transform on $I(t)$ implemented by `LogExpFunctions.log1pexp`.
The reason is that the solver can return small negative numbers, the soft plus transform smoothly maintains positivity which being very close to $I(t)$ when $I(t) > 2$.

```{julia}
@model function deterministic_ode_mdl(y_t, ts, obs, prob, N;
        solver = AutoTsit5(Rosenbrock23())
)
    ##Priors##
    β ~ LogNormal(0.0, 1.0)
    γ ~ Gamma(0.004, 1 / 0.002)
    S₀ ~ Beta(0.5, 0.5)

    ##remake ODE model##
    _prob = remake(prob;
        u0 = [S₀, 1 - S₀, 0.0],
        p = [β, γ]
    )

    ##Solve remade ODE model##

    sol = solve(_prob, solver;
        saveat = ts,
        verbose = false)

    ##log-like accumulation using obs##
    λt = log1pexp.(N * sol[2, :]) # #expected It
    @submodel generated_y_t = generate_observations(obs, y_t, λt)

    ##Generated quantities##
    return (; sol, generated_y_t, R0 = β / γ)
end
```

We instantiate the model in two ways:

1.  `deterministic_mdl`: This conditions the generative model on the data observation. We can sample from this model to find the posterior distribution of the parameters.
2.  `deterministic_uncond_mdl`: This *doesn't* condition on the data. This is useful for prior and posterior predictive modelling.

Here we construct the `Turing` model directly, in the [Mishra et al replication](https://cdcgov.github.io/Rt-without-renewal/dev/showcase/replications/mishra-2020/) we using the `EpiProblem` functionality to build a `Turing` model under the hood.
Because in this note we are using a mix of functionality from `SciML` and `EpiAware`, we construct the model to sample from directly.

```{julia}
deterministic_mdl = deterministic_ode_mdl(data.in_bed, data.ts, obs, sir_prob, N)
deterministic_uncond_mdl = deterministic_ode_mdl(
    fill(missing, length(data.in_bed)), data.ts, obs, sir_prob, N)
```

```{julia}
#| echo: false
function plot_predYt(data, gens; title::String, ylabel::String)
    fig = Figure()
    ga = fig[1, 1:2] = GridLayout()

    ax = Axis(ga[1, 1];
        title = title,
        xticks = (data.ts[1:3:end], data.date[1:3:end] .|> string),
        ylabel = ylabel
    )
    pred_Yt = mapreduce(hcat, gens) do gen
        gen.generated_y_t
    end |> X -> mapreduce(vcat, eachrow(X)) do row
        quantile(row, [0.5, 0.025, 0.975, 0.1, 0.9, 0.25, 0.75])'
    end

    lines!(ax, data.ts, pred_Yt[:, 1]; linewidth = 3, color = :green, label = "Median")
    band!(
        ax, data.ts, pred_Yt[:, 2], pred_Yt[:, 3], color = (:green, 0.2), label = "95% CI")
    band!(
        ax, data.ts, pred_Yt[:, 4], pred_Yt[:, 5], color = (:green, 0.4), label = "80% CI")
    band!(
        ax, data.ts, pred_Yt[:, 6], pred_Yt[:, 7], color = (:green, 0.6), label = "50% CI")
    scatter!(ax, data.in_bed, label = "data")
    leg = Legend(ga[1, 2], ax; framevisible = false)
    hidespines!(ax)

    fig
end
```

**Prior predictive sampling**

```{julia}
prior_chn = sample(deterministic_uncond_mdl, Prior(), 2000)
gens = generated_quantities(deterministic_uncond_mdl, prior_chn)
```

```{julia}
#| output: true
#| echo: false
#| label: fig-prior-pred-det
    
plot_predYt(data, gens;
    title = "Prior predictive: deterministic model",
    ylabel = "Number of Infected students"
)

```

The prior predictive checking suggests that *a priori* our parameter beliefs are very far from the data.
Approaching the inference naively can lead to poor fits.

We do three things to mitigate this:

1.  We choose a switching ODE solver which switches between explicit (`Tsit5`) and implicit (`Rosenbrock23`) solvers. This helps avoid the ODE solver failing when the sampler tries extreme parameter values. This is the default `solver = AutoTsit5(Rosenbrock23())` above.
2.  We locate the maximum likelihood point, that is we ignore the influence of the priors, as a useful starting point for `NUTS`.

```{julia}
nmle_tries = 100

mle_fit = map(1:nmle_tries) do _
    fit = try
        maximum_likelihood(deterministic_mdl)
    catch
        (lp = -Inf,)
    end
end |>
          fits -> (findmax(fit -> fit.lp, fits)[2], fits) |>
                  max_and_fits -> max_and_fits[2][max_and_fits[1]]

mle_fit.optim_result.retcode
```

Note that we choose the best out of \$nmle_tries tries for the MLE estimators.

Now, we sample aiming at 1000 samples for each of 4 chains.

```{julia}
chn = sample(
    deterministic_mdl, NUTS(), MCMCThreads(), 1000, 4;
    initial_params = fill(mle_fit.values.array, 4)
)

describe(chn)
```

```{julia}
#| output: true
#| echo: false
#| label: fig-pairplot-det
pairplot(chn)
```

**Posterior predictive plotting**

```{julia}
gens = generated_quantities(deterministic_uncond_mdl, chn)
```

```{julia}
#| output: true
#| echo: false
#| label: fig-posterior-pred-det
plot_predYt(data, gens;
    title = "Fitted deterministic model",
    ylabel = "Number of Infected students"
)

```

### Inference for the Stochastic SIR model

In *Chatzilena et al*, they present an auto-regressive model for connecting the outcome of the ODE model to illness observations.
The argument is that the stochastic component of the model can absorb the noise generated by a possible mis-specification of the model.

In their approach they consider $\kappa_t = \log \lambda_t$ where $\kappa_t$ evolves according to an Ornstein-Uhlenbeck process:

$$
d\kappa_t = \phi(\mu_t - \kappa_t) dt + \sigma dB_t.
$$ Which has transition density: $$
\kappa_{t+1} | \kappa_t \sim N\Big(\mu_t + \left(\kappa_t - \mu_t\right)e^{-\phi}, {\sigma^2 \over 2 \phi} \left(1 - e^{-2\phi} \right)\Big).
$$ Where $\mu_t = \log(I(t))$.

We modify this approach since it implies that the $\mu_t$ is treated as constant between observation times.

Instead we redefine $\kappa_t$ as the log-residual:

$\kappa_t = \log(\lambda_t / I(t)).$

With the transition density:

$$
\kappa_{t+1} | \kappa_t \sim N\Big(\kappa_te^{-\phi}, {\sigma^2 \over 2 \phi} \left(1 - e^{-2\phi} \right)\Big).
$$

This is an AR(1) process.

The stochastic model is completed:

\begin{align}
Y_t &\sim \text{Poisson}(\lambda_t)\\
\lambda_t &= I(t)\exp(\kappa_t)\\
\beta &\sim \text{LogNormal}(\text{logmean}=0,\text{logstd}=1) \\
\gamma & \sim \text{Gamma}(\text{shape} = 0.004, \text{scale} = 50)\\
S(0) /N &\sim \text{Beta}(0.5, 0.5)\\
\phi & \sim \text{HalfNormal}(0, 100) \\
1 / \sigma^2 & \sim \text{InvGamma}(0.1,0.1).
\end{align}

We will using the `AR` struct from `EpiAware` to define the auto-regressive process in this model which has a direct parameterisation of the `AR` model.

To convert from the formulation above we sample from the priors, and define `HalfNormal` priors based on the sampled prior means of $e^{-\phi}$ and ${\sigma^2 \over 2 \phi} \left(1 - e^{-2\phi} \right)$.
We also add a strong prior that $\kappa_1 \approx 0$.

```{julia}
ϕs = rand(truncated(Normal(0, 100), lower = 0.0), 1000)
σ²s = rand(InverseGamma(0.1, 0.1), 1000) .|> x -> 1 / x
sampled_AR_damps = ϕs .|> ϕ -> exp(-ϕ)
sampled_AR_stds = map(ϕs, σ²s) do ϕ, σ²
    (1 - exp(-2 * ϕ)) * σ² / (2 * ϕ)
end
```

We define the AR(1) process by matching means of `HalfNormal` prior distributions for the damp parameters and std deviation parameter to the calculated the prior means from the *Chatzilena et al* definition.

```{julia}
ar = AR(
    damp_priors = [HalfNormal(mean(sampled_AR_damps))],
    init_priors = [Normal(0, 0.001)],
    ϵ_t = HierarchicalNormal(std_prior = HalfNormal(mean(sampled_AR_stds)))
)
```

We can sample directly from the behaviour specified by the `ar` struct to do prior predictive checking on the `AR(1)` process.

```{julia}
#| output: true
#| echo: false
#| label: fig-ar-prior-pred
nobs = size(data, 1)
ar_mdl = generate_latent(ar, nobs)
fig = Figure()
ax = Axis(fig[1, 1],
    xticks = (data.ts[1:3:end], data.date[1:3:end] .|> string),
    ylabel = "exp(kt)",
    title = "Prior predictive sampling for relative residual in mean pred."
)
for i in 1:500
    lines!(ax, ar_mdl() .|> exp, color = (:grey, 0.15))
end
fig
```

We see that the choice of priors implies an *a priori* belief that the extra observation noise on the mean prediction of the ODE model is fairly small, approximately 10% relative to the mean prediction.

We can now define the probabilistic model.
The stochastic model assumes a (random) time-varying ascertainment, which we implement using the `Ascertainment` struct from `EpiAware`.
Note that instead of implementing an ascertainment factor `exp.(κₜ)` directly, which can be unstable for large primal values, by default `Ascertainment` uses the `LogExpFunctions.xexpy` function which implements $x\exp(y)$ stabily for a wide range of values.

To distinguish random variables sampled by various sub-processes `EpiAware` process types create prefixes.
The default for `Ascertainment` is just the string `\"Ascertainment\"`, but in this case we use the less verbose `\"va\"` for "varying ascertainment".

```{julia}
mdl_prefix = "va"
```

Now we can construct our time varying ascertianment model.
The main keyword arguments here are `model` and `latent_model`.
`model` sets the connection between the expected observation and the actual observation.
In this case, we reuse our `PoissonError` model from above.
`latent_model` sets the modification model on the expected values.
In this case, we use the `AR` process we defined above.

```{julia}
varying_ascertainment = Ascertainment(
    model = obs,
    latent_model = ar,
    latent_prefix = mdl_prefix
)
```

Now we can declare the full model in the `Turing` PPL.

```{julia}
@model function stochastic_ode_mdl(y_t, ts, obs, prob, N;
        solver = AutoTsit5(Rosenbrock23())
)

    ##Priors##
    β ~ LogNormal(0.0, 1.0)
    γ ~ Gamma(0.004, 1 / 0.002)
    S₀ ~ Beta(0.5, 0.5)

    ##Remake ODE model##
    _prob = remake(prob;
        u0 = [S₀, 1 - S₀, 0.0],
        p = [β, γ]
    )

    ##Solve ODE model##
    sol = solve(_prob, solver;
        saveat = ts,
        verbose = false
    )
    λt = log1pexp.(N * sol[2, :])

    ##Observation##
    @submodel generated_y_t = generate_observations(obs, y_t, λt)

    ##Generated quantities##
    return (; sol, generated_y_t, R0 = β / γ)
end

stochastic_mdl = stochastic_ode_mdl(
    data.in_bed,
    data.ts,
    varying_ascertainment,
    sir_prob,
    N
)

stochastic_uncond_mdl = stochastic_ode_mdl(
    fill(missing, length(data.in_bed)),
    data.ts,
    varying_ascertainment,
    sir_prob,
    N
)
```

**Prior predictive checking**

```{julia}
prior_chn = sample(stochastic_uncond_mdl, Prior(), 2000)
gens = generated_quantities(stochastic_uncond_mdl, prior_chn)
```

```{julia}
#| output: true
#| echo: false
#| label: fig-prior-pred-stoch

plot_predYt(data, gens;
    title = "Prior predictive: stochastic model",
    ylabel = "Number of Infected students"
)

```

The prior predictive checking again shows misaligned prior beliefs; for example *a priori* without data we would not expect the median prediction of number of ill children as about 600 out of \$N after 1 day.

The latent process for the log-residuals $\kappa_t$ doesn't make much sense without priors, so we look for a reasonable MAP point to start NUTS from.
We do this by first making an initial guess which is a mixture of:

1.  The posterior averages from the deterministic model.
2.  The prior averages of the structure parameters of the AR(1) process.
3.  Zero for the time-varying noise underlying the AR(1) process.

```{julia}
initial_guess = [[mean(chn[:β]),
                     mean(chn[:γ]),
                     mean(chn[:S₀]),
                     mean(ar.init_prior)[1],
                     mean(ar.damp_prior)[1],
                     mean(ar.ϵ_t.std_prior)
                 ]
                 zeros(13)]
```

Starting from the initial guess, the MAP point is calculated rapidly in one pass.

```{julia}
map_fit_stoch_mdl = maximum_a_posteriori(stochastic_mdl;
    adtype = AutoReverseDiff(),
    initial_params = initial_guess
)
```

Now we can run NUTS, sampling 1000 posterior draws per chain for 4 chains.

```{julia}
chn2 = sample(
    stochastic_mdl,
    NUTS(; adtype = AutoReverseDiff(true)),
    MCMCThreads(), 1000, 4;
    initial_params = fill(map_fit_stoch_mdl.values.array, 4)
)

describe(chn2)
```

```{julia}
#| output: true
#| echo: false
#| label: fig-pairplot-stoch-params
pairplot(chn2[[:β, :γ, :S₀, Symbol(mdl_prefix * ".std"),
    Symbol(mdl_prefix * ".ar_init[1]"), Symbol(mdl_prefix * ".damp_AR[1]")]])
```

```{julia}
#| output: true
#| echo: false
#| label: fig-pairplot-stoch-eps
vars = mapreduce(vcat, 1:13) do i
    Symbol(mdl_prefix * ".ϵ_t[$i]")
end
pairplot(chn2[vars])
```

```{julia}
gens = generated_quantities(stochastic_uncond_mdl, chn2)
```

```{julia}
#| output: true
#| echo: false
#| label: fig-posterior-pred-stoch
plot_predYt(data, gens;
    title = "Fitted stochastic model",
    ylabel = "Number of Infected students"
)
```

# Discussion {#sec-discussion}

<!-- Summary paragraph -->
- Compositional approach to epidemiological modelling enables "swap-in/swap-out" model construction
- Three case studies demonstrate model comparison, validation, and methodological transparency
- Maintains rigour of established approaches while adding flexibility

<!-- Strengths and weaknesses interwoven -->
- Modular design enables rapid model development and component reuse, though requires learning curve for researchers familiar with monolithic approaches
- Systematic comparison of modelling assumptions without large reimplementation, but computational overhead from abstraction layers
- Transparent specification through explicit component interfaces improves reproducibility, yet interface standardisation may constrain some specialised approaches
- Reduces implementation barriers for methodological advances, however current component library remains limited to basic epidemiological patterns

<!-- Comparison to literature - Algebraic Julia -->
- Builds on algebraic Julia ecosystem (DifferentialEquations.jl, etc.)
- Extends scientific machine learning to epidemiological contexts
- Utilises Julia's multiple dispatch for component composition

<!-- Comparison to literature - Other approaches -->
- Contrast with pipeline approaches (separate models passing information)
- Comparison to modular frameworks in other scientific domains
- Relationship to probabilistic programming languages and compositional features

<!-- Future work -->
- Expanded component library for specialised epidemiological scenarios
- Automated model selection tools
- Performance optimisation for complex composed models
- Integration bridges to existing epidemiological packages

<!-- Conclusions -->
- Addresses key limitations while maintaining scientific rigour
- Potential to accelerate methodological development
- Improves accessibility of advanced epidemiological methods

## Acknowledgements

# References {.unnumbered}

::: {#refs}
:::

# Appendix: Technical details {.unnumbered}

## Component interface specifications

<!-- TODO: Detailed API documentation -->

## Performance benchmarks

<!-- TODO: Computational performance comparisons -->