---
title: "A Prototype for Compositional Probabilistic Infectious Disease Modelling"
author:
  - name: "Samuel P. C. Brand"
    affiliation: "Center for Forecasting and Outbreak Analysis; Centers for Disease Control"
    email: "usi1@cdc.gov"
    orcid: "0000-0003-0645-5367"
  - name: "Samuel Abbott"
    affiliation: "Centre for Mathematical Modelling of Infectious Diseases, London School of Hygiene & Tropical Medicine"
    email: "sam.abbott@lshtm.ac.uk" 
    orcid: "0000-0001-8057-8037"
date: today
abstract: |
  Recent outbreaks of Ebola, COVID-19 and mpox have demonstrated the value of modelling for synthesising data for rapid evidence to inform decision making. Effective models require integration of expert domain knowledge from clinical medicine, environmental science, behavioural research, and public health to accurately capture transmission processes, yet current modelling approaches create barriers to this integration. Methods used to synthesise available data broadly fall into pipeline approaches that chain separate models together, or joint models that are often monolithic and difficult to adapt. These barriers have prevented advances across multiple settings where models could have provided actionable insights. Composable models where components can be reused across different contexts and combined in various configurations whilst maintaining statistical rigour could address these limitations. In this work, we start by outlining the key requirements for a composable infectious disease modelling framework and then present a prototype that addresses these requirements through composable epidemiological components built on Julia's type system and Turing.jl. Our approach enables "LEGO-like" model construction where complex models emerge from composing simpler, reusable components. Through three case studies using the prototype, we show how components can be reused across different models whilst maintaining statistical rigour. The first replicates a COVID-19 analysis for South Korea using renewal processes with time-varying reproduction numbers. The second extends these components with reporting delays and day-of-week effects for real-time nowcasting applications. The third integrates ODE solvers for compartmental disease transmission models applied to influenza outbreak data. Across all case studies, the same core components combine differently to address distinct epidemiological questions. We explore other potential options and compare them to our proposed approach. The prototype demonstrates promise but future work is needed to solve remaining composability challenges, expand the component library, and integrate bridges to existing epidemiological software ecosystems.
format:
  pdf:
    documentclass: article
    geometry: margin=1in
    fontsize: 11pt
    linestretch: 1.5
    keep-tex: false
    number-sections: false
    colorlinks: true
bibliography: references.bib
csl: https://www.zotero.org/styles/plos-computational-biology
execute:
  echo: true
  warning: false
  cache: true
  output: false
julia: 
  exeflags: ["+1.11.6", "--threads=4", "-O3"]
---

# Introduction {#sec-introduction}

Recent outbreaks of Ebola, COVID-19 and mpox have demonstrated the value of modelling for synthesising data for rapid evidence to inform decision making [@whitty2015what].
Infectious diseases spread through complex interactions between biology, human behaviour, economic factors, and environmental conditions that must all be understood to control transmission effectively.
Effective models require integration of expert domain knowledge from clinical medicine, environmental science, behavioural research, and public health to accurately capture these multifaceted transmission processes, yet current modelling frameworks create barriers to this essential integration.
Individual-level data such as viral loads, biomarkers, genomic sequences, and clinical observations are routinely ignored or aggregated when informing population-level models, losing information that could improve decisions.
These barriers have prevented advances in settings where models could have provided actionable insights such as early outbreak analysis, wastewater surveillance, phylodynamics, clinical biomarkers, pooled testing, and large-scale clinical datasets.
The next infectious disease threat is unpredictable and may be exacerbated by climate change [@Tsui2024-gy], requiring adaptable response capabilities that can rapidly incorporate diverse data sources and domain expertise.

Methods used to synthesise available data in real time broadly fall into two classes: either combining results from multiple, smaller models calibrated in isolation (the pipeline approach, e.g., [@huisman2022]), or representing a single model tuned to the specific scenario (the joint model approach, e.g., [@birrell2024; @Watson2024-vj]).
Both approaches have significant downsides.
Pipeline approaches combine results from separate models without uncertainty propagation, leading to loss of detail and statistical rigour [@lison2024].
Joint approaches use single monolithic models that, whilst powerful in their ability to systematically integrate multiple processes and data streams, are too complex to enable transfer to other settings or extension with additional model components.
To adapt or extend such models, analysts need to fully comprehend all parts of the corresponding model and code, creating barriers to sharing methodology and leading to inefficient re-implementation when parts of a model could, in principle, be re-used.
Attempts to include insights from environmental scientists, economists, or behavioural researchers typically result in models that are either too complex to use practically or too simplified to capture valuable expertise.
This prevents effective integration of expertise across disciplines.
Transfer of methodology between outbreak events has proven difficult, with each posing unanticipated challenges that existing tools cannot accommodate.

Recent developments in computational statistics and scientific computing demonstrate the potential for composable approaches where components can be reused across different contexts and combined in various configurations whilst maintaining statistical rigour that could address these limitations.
Advances in Turing.jl have introduced submodel interfaces that enable composable probabilistic programming, providing a pathway for epidemiological model composition, though initial epidemiological applications revealed interoperability challenges [@Nicholson2022-ua; @fjelde2025turin].
Category theory provides the underlying mathematical frameworks for this composability through operadic composition in hierarchical model construction [@libkind2022algebraic].
The algebraic Julia ecosystem has applied these theoretical foundations to scientific computing, with HydroModels.jl and ModelingToolkit.jl demonstrating how abstract backends can support mixed equation types including differential-algebraic equations, partial differential equations, and stochastic differential equations through unified interfaces [@modelingtoolkit2021].
SpeedyWeather.jl uses an alternative approach, demonstrating "LEGO-like" atmospheric modelling with interactive domain-specific languages that enable modular component assembly [@speedyweather2024].
The key insight underlying these approaches is the separation of syntax (composition) from semantics (computation), enabling modularity and independence of components whilst maintaining mathematical rigour.

This paper presents a prototype that combines the modularity of pipeline approaches with the statistical rigour of joint models through composable epidemiological components.
Our approach enables "LEGO-like" model decisions through standardised interfaces [@speedyweather2024].
The prototype supports composability beyond ordinary differential equations, accommodating mixed equation types and the potential for different computational backends.
We implement this as a domain-specific language operating intended to be implemented as optional package extensions.
We demonstrate our approach using an autoregressive model example to illustrate the proposed compositional pattern and component swapping capabilities.
Through three case studies using the prototype, we show how components can be reused across different models: the first replicates @mishra2020covid; the second reuses components from the first, along with new elements, to replicate @epinow2; the third implements @chatzilena2019contemporary, again reusing components, alongside the use of an ODE.
Finally, we discuss alternative design approaches, evaluate the strengths and limitations of our compositional approach, and identify key areas for future development.

# Prototype Implementation {#sec-approach}

## Requirements for Composable Infectious Disease Modelling {#sec-requirements}

Modelling infectious disease dynamics requires quantifying uncertainty at every level because decisions must account for incomplete knowledge about individual infection risk, transmission dynamics, and observation processes.
A clear separation between distinct model components, infection processes, observation processes, and latent dynamics is also key as these allows reasoning on each of these components separately.
Because diseases affect populations heterogeneously across age, location, and risk groups, the framework needs to be able to support arbitrary stratification schemes for all components.
These stratified models must also remain data-agnostic as this allows the model to be generalised to different datasets, tested based on just its prior specification, and used for forecasting.
Similarly, the book work of supporting multiple strata needs to be abstracted from the user to make the system easier to use but at the same time they need to be able to model relationships between strata in order to support partial pooling of parameters for sparse data settings.
To allow for models to be validated, the framework must support nesting models within models and programming over model structure itself, allowing simple components to compose into sophisticated models while remaining individually interrogable for debugging, validation, and mechanistic understanding.
This compositional approach requires a clear, concise modelling language so that it can be used by a wide pool of users and so that model specifications can be written quickly but with clarity.
Supporting modern inference methods is important so that complex models can be fit and this necessitates gradient computation throughout via automatic differentiation.
It is also important to allow for a wide range of inference methods so that the best approach for a given model/data combination can be used.
This means supporting abstract back-ends that seamlessly switch between inference approaches.

We also need to have model components that encapsulate both structure and prior distributions so that domain experts can contribute specialised knowledge: a virologist's understanding of within-host dynamics, an epidemiologist's of contact patterns, a clinician's of disease progression insights without reviewing the entire modelling framework.
Standardised interfaces between components are needed to allow individual components to work together, to support handling of multiple strata, and to allow for proper uncertainty propagation.
As there are a range of different potential ways to express infectious disease models including ordinary differential equations, agent-based models, network models, stochastic processes, and discrete time models these all need to be supported both independently and in combination.
Importantly, the design must enable incremental adoption without requiring complete rebuilds of existing models, and components should remain functional as standalone tools outside the compositional framework to maximise their utility and adoption.
Finally, we need a framework that can be composed with out of domain approaches and expertise, such as neural networks, Gaussian processes, and other machine learning approaches.

## Our approach {#sec-design}

Meeting these requirements requires programming with probabilities, for which probabilistic programming languages are designed.
We also need a probabilistic programming language that supports automatic differentiation for modern inference, the ability to program over model structure itself to enable model nesting and composition, and crucially access to as wide an ecosystem as possible to avoid lock-in and enable integration with existing scientific computing tools.
As far as we are aware, only probabilistic programming languages built in Julia provide the metaprogramming capabilities needed to create domain-specific abstractions that can handle arbitrary stratification, standardised interfaces between components, and programming over the model structure.
Among Julia's options, Turing.jl best meets our requirements with mature submodel support for nesting models within models, extensive inference algorithm choices, and it's implementation as a light abstraction layer on top of the wider Julia ecosystem.
Additional benefits of Julia include eliminating the two-language problem, leveraging multiple dispatch for clean component composition, and accessing the mature SciML ecosystem for differential equations and other scientific computing tools.

Our approach uses a two-layer architecture with high-level domain-specific language (DSL) for epidemiological modelling and a low-level implementation using Turing.jl (though importantly we are not locked in to this choice as the DSL is agnostic of the backed used).
This separation enables incremental adoption without rebuilding existing models to use our DSL, with all components remaining functional as standalone tools outside the compositional framework.
The domain-specific language layer provides clear, concise model specification using epidemiological concepts, enabling domain experts to contribute components encapsulating their specialised knowledge without understanding the full framework.
The backend layer handles the automated bookkeeping of stratification, interface validation, and uncertainty propagation whilst supporting multiple inference approaches and auto differentiation options by leveraging the Turing.jl and wider Julia ecosystems.
Alternative approaches using category theory or symbolic-numeric frameworks remain accessible through Julia's interoperability and could be made parts of future backends [@libkind2022algebraic; @modelingtoolkit2021].

## Domain-Specific Language Structure {#sec-dsl}

<!-- Reference to Panel A of Figure 1 -->

-   Domain-specific language built on Julia's type system
-   Abstract types define hierarchy of epidemiological model components
-   Struct-in-struct design enables component swapping for model comparison
-   Mathematical consistency maintained through type system
-   Complex models constructed by nesting simpler components in containers
-   Type hierarchy: `AbstractEpiModel` (infection processes), `AbstractLatentModel` (time-varying parameters), `ObservationModel` (latent-to-observed links)
-   Turing specific types in the prototype but actually not needed
-   Package extension pattern: high-level epidemiological interface over standard Julia package
-   Don't focus heavily on the specialised Turing abstract types, the `EpiMethod` , `apply_method`, `EpiData` etc. as this won't likely be carried forward. Can briefly discuss in the case study as they come up and add why they aren't a good idea in the discussion of our approach in the discussion.
-   Compositional design translates abstract specifications to concrete probabilistic programs via multiple dispatch
-   Enables modular "swap-in/swap-out" functionality distinguishing from monolithic alternatives

<!-- Reference to Panel B of Figure 1 -->

To demonstrate the structure and use of `AbstractLatentModels`, we start with an autoregressive order one (AR(1)) process, which mathematically is:

$$Z_t = \rho Z_{t-1} + \epsilon_t, \quad \epsilon_t \sim \text{Normal}(0, \sigma)$$

In our prototype DSL, this is defined using the `AR` struct:

```{julia}
using EpiAware
ar_model = AR()
display(ar_model)
```

Another common latent model is the moving average model

$$Z_t = \epsilon_t + \theta \epsilon_{t-1}, \quad \epsilon_t \sim \text{Normal}(0, \sigma)$$

The `MA` struct encapsulates this:

```{julia}
using Distributions
ma_model = MA(;
    θ_priors=[truncated(Normal(0.0, 0.05), -1, 1)],
    ϵ_t=HierarchicalNormal(std_prior=HalfNormal(0.5))
)
```

A popular combination of these models is the autoregressive moving average (ARMA) model that can have different orders for both the AR and MA components.
An ARMA(2,1) can be defined as:

$$Z_t = \rho_1 Z_{t-1} + \rho_2 Z_{t-2} + \epsilon_t + \theta \epsilon_{t-1}$$

In our DSL this can be represented as a composition of the AR and MA structs by passing MA as the error term to AR:

```{julia}
arma_model = AR(;
    damp_priors=[truncated(Normal(0.8, 0.1), 0, 1),
        truncated(Normal(0.1, 0.05), 0, 1)],
    init_priors=[Normal(-1.0, 0.1), Normal(-1.0, 0.5)],
    ϵ_t=ma_model
)
```

Similarly, autoregressive integrated moving average (ARIMA) models extend ARMA by adding differencing for non-stationary series:

$$\Delta Z_t = \rho_1 \Delta Z_{t-1} + \rho_2 \Delta Z_{t-2} + \epsilon_t + \theta \epsilon_{t-1}$$

We compose the ARMA model with a differencing operation using the `DiffLatentModel` wrapper:

```{julia}
arima_model = DiffLatentModel(arma_model, Normal(); d=1)
display(arima_model)
```

Alternatively, EpiAware provides an `arima()` constructor function that simplifies this specification.
Whilst not implemented we could avoid redefining the AR process using an `update` function.

Other latent models extend possibilities through combining models additively, multiplicative scaling, and piecewise processes.
This approach enables representation of arbitrary latent processes through composition.

<!-- -->

## Backend Implementation: Turing Interface {#sec-backend}

<!-- Reference to Panel D of Figure 1 -->

-   Compositional design translates to concrete Turing models via `generate_latent` and other generator functions (by absract model type).
-   Abstract model specifications converted to executable probabilistic programs
-   AR component implementation demonstrates multiple dispatch for seamless backend integration
-   Do not dwell on the many different generate functions as not part of an ongoing design.
-   Once a generate function has been used to create a Turing.jl model these models can be used with all the functionality that Turing supports including sampling, inference with a wide range of approaches, including gradient based approaches, model conditioning and adaption, as well as includsion in other models as submodels themselves.
Returning to our example from the DSL section, the autoregressive process can be mapped from its high-level representation to a Turing model using the `generate_latent` function:

```{julia}
using CodeTracking, Revise
print(@code_string EpiAwareBase.generate_latent(ar_model, 50))
```

The key line `@submodel ε_t = generate_latent(latent_model.ε_t, n - p)` enables composition by delegating to whatever error model was provided. The AR dynamics are implemented through a custom accumulation step that maintains the autoregressive state:

```{julia}
print(@code_string EpiLatentModels.ARStep([1, 2, 1])(1, 1))
```

This step function works with `accumulate_scan` to build the AR series by applying the autoregressive equation at each time step.
The MA model has a similar structure with its own internal step function.
The `accumulate_scan` pattern enables composable iteration steps, allowing complex processes like renewal models with susceptible depletion to be built by composing simple step operations.
This design means we only need to write the single-step operation without worrying about the iteration process, making components more modular and reusable.

The full ARIMA(2,1,1) model we defined in the DSL section can then be generated using the same approach:

```{julia}
print(@code_string generate_latent(arima_model, 50))
```

The DiffLatentModel's `@submodel diff_latent = generate_latent(latent_model.model, n - d)` calls the ARMA model, which in turn calls its composed AR and MA components, then applies differencing through cumulative summing.
This recursive delegation through `@submodel` enables arbitrary depth composition while maintaining clean separation between components.


**Figure 1**: Compositional Modelling Architecture *Panel A*: Generic composition pattern showing struct-in-struct hierarchy with recursive dispatch through abstract type system.
*Panel B*: ARIMA composition example demonstrating component stacking with struct definitions.
*Panel C*: Prior predictive checks demonstrating model behavior before data conditioning.
*Panel D*: Backend abstraction architecture with Turing as current implementation and potential for ODE, agent-based, and other computational backends.

# Case Studies {#sec-case-studies}

All code and data for reproducing the analyses in this paper are available at: https://github.com/EpiAware/PrototypeCompositionalProbablisticInfectiousDiseaseModelling.

## Standard Case Study Format

Each case study follows this standardised structure to ensure consistency and clarity:

A concise paragraph explaining: - The original paper and its contribution - Why we selected this study for replication - Key features of our compositional prototype demonstrated (e.g., model modularity, component reusability, transparent priors)

### Data

Brief description of the dataset with a single code block loading the data.

### Model

Compositional model specification with subsections.
Give a very high levle overview of the model in text.

#### Infection Generating Process

-   Mathematical formulation
-   Code implementation using `AbstractEpiModel` types
-   Prior predictive checking

#### Observation Model

-   Mathematical formulation
-   Code implementation using `ObservationModel` types
-   Prior predictive checking

### Fitting to Data

-   Model composition into `EpiProblem`
-   Inference configurationn
-   Posterior sampling
-   Posterior predictive checking

Panel figure combining all visualisations: - Prior predictive plots for each model component - Posterior predictive plots showing model fit - Parameter inference summaries

### **Code Organisation Principles**

-   Dependencies imported when first needed, not in large blocks
-   Each code statement in separate block with explanatory text before and after
-   Minimal, clear code focused on demonstrating compositional concepts
-   Use the same dependencies across each case study where possible i.e. chained dataframesmeta verbs, pairplot for prior and posterior output, a single plotting library, don't use package.function form unless can't be avoided.
-   Mathematical formulation precedes code implementation for each component

## Case study 1: On the derivation of the renewal equation from an age-dependent branching process: an epidemic modelling perspective {#sec-example1}

<!-- Reference: https://arxiv.org/abs/2006.16487 -->

<!-- Implementation: https://cdcgov.github.io/Rt-without-renewal/stable/showcase/replications/mishra-2020/ -->

In _On the derivation of the renewal equation from an age-dependent branching process: an epidemic modelling perspective, *Mishra et al* (2020)_ @mishra demonstrate the mathematical correspondance between age-dependent branching processes and time-since-infection epidemiological models, originally introduced by Kermack and McKendrick @kermack1927contribution, as a renewal model with time-varying reproduction number $R_t$. 
*Mishra et al* show how solutions to the renewal equation, when combined with a negative binomial link to count data, define a Bayesian hierarchical framework for inference on reported case time series data, demonstrating this on test-confirmed cases of COVID-19 in South Korea.
The renewal equation is a flexible model for latent infections which can be thought of as a epidemiologically motivated transformation on the process $R_t$ @mishra, in the sense that it solution trajectory $I_t$ is conditional on the value of $R_t$ and initial values $I(0), I(-1), \dots$.
We show how our prototype framework compose a latent process model, reusing components from previous examples, with a renewal equation solution model and an observation link model to recreate the Bayesian framework in @mishra .
The relative simplicity of the observation model in this example makes this a good initial case study.

### Case study 1: Data

_Mishra et al_ made inference on daily reported test-confirmed cases of COVID-19 in South Korea between January to July 2020.
This data is curated by the [`covidregionaldata`](https://github.com/epiforecasts/covidregionaldata) package, but we have saved the South Korean data locally.

```{julia}
using Chain, CSV, DataFramesMeta, Dates
datapath = "data/south_korea_data.csv"
south_korea_data = @chain datapath begin
    CSV.read(DataFrame)
    (y_t = _.cases_new, dates = _.date)
end
```

### Case study 1: Generative model

The generative model for case data demonstrated in _Mishra et al_ has a hierarchical structure, consisting of a log-scale time-varying reproductive number $\log R_t$ modelled as an AR(2) process, which in turn specifies the latent infections $I_t$ as a solution to the renewal equation conditional on the trajectory of $\log R_t$.
The latent infection process is linked directly to reported cases $C_t$ on matching days using a negative binomial link distribution.

The full probabilistic model we use in this case study is,

$$
\begin{aligned}
Z_t & = \log R_t, \\
\rho_1, \rho_2, Z_0, Z_{-1}, I_0,  \sigma, \phi &\sim \pi(\cdot), \\
\epsilon_t & \sim \text{Normal}(0, \sigma)~~ \text{i.i.d } \forall t, \\
Z_t &= \rho_1 Z_{t-1} + \rho_2 Z_{t-2} + \epsilon_t,~~ t = 1, 2, 3, \dots\\
r & \text{ solves } G(r) = 1 / R_1, \\
I_{t} & = I_0 e^{rt},~~ t = 0, -1, -2, -3,-n+1, \\
I_t &= R_t \sum_{s \geq 1} g_s I_{t-s}, ~~ t = 1, 2, 3, \dots, \\
y_t & \sim \text{NegBin}(I_t, \phi), ~~ t = 1, 2, 3, \dots.
\end{aligned}
$$

Where $\pi$ is a prior distribution for the hyperparmeters of the AR(2) model, initial states $Z_0, Z_{-1}$, the damping parameters $\rho_1,\rho_2$ and innovations standard deviation $\sigma$, along with initial condition value for the latent infections $I_0$ and observation overdispersion $\phi$.
$g_t$ is the generation distribution probability mass function (pmf).
$r$ is the growth rate determined by the by $R_1 = \exp(Z_1)$ using the implicit relationship @wallinga2007generation 

$$
G(r) = \sum_{j \geq 1} g_j \exp(- r j) = 1 / R_1.
$$

This means that we determine the initial condition of the latent infecteds before $t=0$, $I_{-1}, I_{-2}, \dots, I_{-n+1}$ jointly with sampling $R_1$ where $n$ is the maximum support value of the $g_t$ pmf.
The sampling distribution for these parameters defines a generative model for the daily case data $y_t$ through solution of the renewal equation for latent infections $I_t$, therefore, this model can be used for Bayesian inference by conditioning on the observed case data.

#### Case study 1: Infection Generating Process

The priors for the latent AR(2) process we use, based on _Mishra et al_, are,

$$
\begin{aligned}
\rho_1 & \sim \text{Normal}(0.8, 0.1) \mid \{0 \geq \rho_1 \geq 1 \},\\
\rho_1 & \sim \text{Normal}(0.1, 0.05) \mid \{0 \geq \rho_1 \geq 1 \},\\
Z_0 & \sim \text{Normal}(-1.0, 0.1) ,\\
Z_{-1} & \sim \text{Normal}(-1.0, 0.5),\\
\sigma & \sim \text{HalfNormal}(0.5).
\end{aligned}
$$

The ARMA(2,1) model defined above already has these priors for the damping parameters and initial conditions.
Therefore, we reuse the ARMA(2,1) model from above by reseting its noise model to independent normal with a hyperprior for $\sigma \sim \text{HalfNormal}(0.5)$.
This transforms the ARMA(2,1) model into the AR(2) model we desire, whilst maintaining code reusability, 
 
```{julia}
using Accessors
ar = @set arma_model.ϵ_t = HierarchicalNormal(std_prior = HalfNormal(0.5))
display(ar) # FIX: Currently gives incorrect display but inspection returns correct strucutual transformation
```

The `ar` model object defines the full sampling distribution, both for hyperparameters and trajectory, for $Z_t$ defined in the [generative model](#generative-model-for-case-study-1) section.
To do prior predictive modelling on $Z_t$ we define the associated Turing model to `ar`, concretising its sampling period to 50 days using the `generate_latent` method from our prototype system.

```{julia}
ar_mdl = generate_latent(ar, 50)
```

We show our prior predictive modelling samples as spaghetti plots.

```{julia}
#| output: true
#| label: fig-ar-sample
#| echo: false
using CairoMakie, Random
Random.seed!(1234)

function ar_sample_plot!(ax, ar_mdl; n_samples = 100)
    ar_mdl_samples = mapreduce(hcat, 1:n_samples) do _
        ar_mdl() .|> exp
    end
    for col in eachcol(ar_mdl_samples)
        lines!(ax, col, color = (:grey, 0.1))
    end
    return nothing
end


ar_sample_plot = let
    n_samples = 100
    fig = Figure()
    ax = Axis(fig[1, 1];
        yscale = log10,
        ylabel = "Time varying Rₜ",
        title = "$(n_samples) draws from the prior Rₜ model"
    )
    ar_sample_plot!(ax, ar_mdl; n_samples)
    fig
end
ar_sample_plot
```

Using the decomposed models we have rapidly visualised that *a priori* the _Mishra et al_ example assigned a few percent chance of achieving very high $R_t$ values, i.e. $R_t \sim 10-1000$ is not excluded by our priors.

The renewal equation above is defined in daily time increments, but its is common to estimate and report underlying delay distributions as continuous.
In our prototype system we give a convenience constructor for the data required to solve the renewal model that convert generation interval distributions into the generation interval pmf $g_t$ required for this model.
In _Mishra et al_, the serial interval distribution is used in place of the generation interval distribution, which can be problematic @park2023inferring, but is common in practice especially early in an outbreak @zhao2020preliminary.
The specific continuous serial interval distribution used was $\text{Gamma}(6.5, 0.62)$,

```{julia}
truth_SI = Gamma(6.5, 0.62)
```

Our prototype epidemiological system offers a convenience constructor which converts this continuous distribution into the discrete pmf $g_t$ for the generative model using double interval censoring @charniga2024best.

```{julia}
model_data = EpiData(gen_distribution = truth_SI)
display(model_data.gen_int)
```

We can compare the discretized generation interval with the underlying continuous distribution to visualise the similarity between the commonly reported continous distribution and the discrete version used in modelling,

```{julia}
#| output: true
#| echo: false
#| label: fig-discretised-gen-pmf

function discretised_gen_plot!(ax, model_data, truth_SI)
    barplot!(ax, model_data.gen_int;
        label = "Discretized next gen pmf"
    )
    lines!(ax, truth_SI;
        label = "Continuous serial interval",
        color = :green
    )
    axislegend(ax)
    return nothing
end

discretised_gen_plot = let
    fig = Figure()
    ax = Axis(fig[1, 1];
        xticks = 0:14,
        xlabel = "Days",
        title = "Continuous and discrete generation intervals"
    )
    discretised_gen_plot!(ax, model_data, truth_SI)
    fig
end
discretised_gen_plot
```

We use a lognormal prior for the initial latent infections $I_0 \sim LogNormal(0., 1.0)$, as defined above the other necessary initial conditions are defined in combination with the initial sampled reproductive number $I_1$.
The `model_data` object composes with the initial latent infections prior to construct a full renewal model,

```{julia}
log_I0_prior = Normal(log(1.0), 1.0)
epi = Renewal(model_data; initialisation_prior = log_I0_prior)
display(epi)
```

The `epi` model object defines the sampling distribution for $I_t$ defined in the [generative model](#case-study-1-generative-model1) section, conditional on the time-varying reproductive number process $R_t$.
We can concretise the sampling behavious of $I_t$ by supplying the model object and a specific $R_t$ trajectory to the `generate_latent_infs` method. Here we choose an example where $R_t$ decreases from $R_t = 3$ to $R_t = 0.5$ over the course of 50 days.

```{julia}
R_t_fixed = [0.5 + 2.5 / (1 + exp(t - 15)) for t in 1:50]
latent_inf_mdl = generate_latent_infs(epi, log.(R_t_fixed))
```

The implied distribution of $I_t$ trajectories conditional on this $R_t$ trajectory can be sampled independently of other model components.

```{julia}
#| output: true
#| echo: false
#| label: fig-gen-epi

function plot_latent_infections!(ax, latent_inf_mdl; n_samples)
    epi_mdl_samples = mapreduce(hcat, 1:n_samples) do _
        latent_inf_mdl()
    end
    for col in eachcol(epi_mdl_samples)
        lines!(ax, col;
            color = (:grey, 0.1)
        )
    end
    return nothing
end

function plot_Rt_traj!(ax, R_t_fixed)
    lines!(ax, R_t_fixed;
            linewidth = 2
        )
    return nothing
end

renewal_model_plot = let
    n_samples = 100
    
    fig = Figure()
    ax1 = Axis(fig[1, 1];
        title = "$(n_samples) draws from renewal model with chosen Rt",
        ylabel = "Latent infections"
    )
    ax2 = Axis(fig[2, 1];
        ylabel = "Rt"
    )
    plot_latent_infections!(ax1, latent_inf_mdl; n_samples)
    plot_Rt_traj!(ax2, R_t_fixed)
    fig
end
renewal_model_plot
```

The full infection generating process, that is the model defined in the [generative model section](#case-study-1-generative-model) without the link to case data, can be constructed by passing samples of $Z_t$ into the renewal model sampler.

### Case study 1: Observation model

In *Mishra et al* the overdispersion parameter $\phi$ sets the relationship between the mean and variance of the negative binomial errors.
In our prototype system, we default to a prior on $\sqrt{1/\phi}$ because this quantity is approximately the coefficient of variation of the observation noise and, therefore, is easier to reason on *a priori* beliefs.
We call this quantity the cluster factor.
A prior for $\phi$ was not specified in *Mishra et al*, we select $\sqrt{1/\phi} \sim \text{HalfNormal}(0.1)$ but we will condition a value for the cluster factor in analysis below due to non-identifiability with the variance in the innovation process of $Z_t$.

```{julia}
obs = NegativeBinomialError(cluster_factor_prior = HalfNormal(0.1))
display(obs)
```

As with other component models, we can define a Turing model from the `obs` object conditional on a latent infection time series $I_t$ that defines the expected number of cases observed on each day.
With an fixed latent infection times series, we use the `generate_observations` method from our prototype system,

```{julia}
I_t = [1000 * exp(-(t - 15)^2 / (2 * 4)) for t in 1:30]
obs_mdl = generate_observations(obs, missing, I_t)
```

Turing uses `missing` arguments to indicate observed variables that are to be sampled rather than only used to accumulate log posterior density.
This Turing model can be sampled from to make a prior predictive visualisation on the dispersion around the mean implied by our choice of prior.

```{julia}
#| output: true
#| echo: false
#| label: fig-discretised-gen-cases

function neg_bin_obs_plot!(ax, obs_mdl; n_samples)
    obs_mdl_samples = mapreduce(hcat, 1:n_samples) do _
        θ = obs_mdl() #Sample unconditionally the underlying parameters of the model
    end
    for col in eachcol(obs_mdl_samples)
            scatter!(ax, col;
                color = (:grey, 0.2)
            )
        end
        lines!(ax, I_t;
            color = :red,
            linewidth = 3,
            label = "Latent infections"
        )
    axislegend(ax)
    return nothing
end
neg_bin_obs_plot = let
    n_samples = 100
    
    fig = Figure()
    ax = Axis(fig[1, 1];
        title = "$(n_samples) draws from neg. bin. obs model",
        ylabel = "Observed cases"
    )
    neg_bin_obs_plot!(ax, obs_mdl; n_samples)
    fig
end
neg_bin_obs_plot
```

### Case Study 1: Fitting to data

In each of the models defined above, samples only pass in one direction: $Z_t$ samples can be used in sampling $I_t$, and $I_t$ samples can be used to generate case data $y_t$.
At a high level this can be abstracted as a Bayesian network @heckerman1998tutorial, but at the level of fully coherent probabilistic/data-generative models rather than simple parameteric random variables.
Our prototype system has compacted the full Bayesian network implied by the full generative model into a small Bayesian network where the latent model flows into the epidemiological model for latent infections, which then flows into the observational link model to obseravable data.
We supply a constructor method for this Bayesian network struture composing the defined submodels.

```{julia}
tspan = (45, 80)
epi_prob = EpiProblem(epi_model = epi,
    latent_model = ar,
    observation_model = obs,
    tspan = tspan)
display(epi_prob) # TO DO: pretty print
```

Where the `tspan` argument set the range of the time range for the generative model.

#### Case Study 1: Training data for inference

We create our training data by reducing the range of full data onto `tspan`.

```{julia}
training_data = @chain south_korea_data begin
    @set _.y_t = _.y_t[first(tspan):last(tspan)]
    @set _.dates = _.dates[first(tspan):last(tspan)]
end 
```

#### Case Study 1: Composition into Turing model

As with the submodels, our prototype system has a method `generate_epiaware` to construct a Turing model to implement the composed Bayesian network.
We use the conditioning capability of Turing to condition on a fixed cluster factor value in the generative model to improve identifiability, as well as passing in the training data.

```{julia}
using Turing
fixed_cluster_factor = 0.25
mdl = generate_epiaware(epi_prob, training_data) |
      (var"obs.cluster_factor" = fixed_cluster_factor,)
```

#### Case Study 1: Defining sampler configuration

We make inferences on the unobserved quantities, such as $R_t$ by sampling from this composed model, further conditioned on the training data.
We generate the posterior samples using the No U-Turns (NUTS) sampler, with a pre-sampling step of drawing start points from `ManyPathfinder`, a batched implementation of pathfinder variational inference @zhang2022pathfinder that returns the single pathfinder route with maximum estimated evidence lower bound (ELBO).

```{julia}
using ReverseDiff
inference_method = EpiMethod(
    pre_sampler_steps = [ManyPathfinder(nruns = 5, maxiters = 100)],
    sampler = NUTSampler(
        target_acceptance = 0.9,
        adtype = AutoReverseDiff(compile = true),
        ndraws = 1000,
        nchains = 4,
        mcmc_parallel = MCMCThreads(),
        nadapts = 1000)
)
```

#### Case Study 1: Sampling from posterior distribution

The `apply_method` function combines the elements above: 

- The composed epidemiological model.
- A defined inference method as a combination of pre-heating and sampling method.
- Data to condition the model upon.

And deploys the inference method on the data conditioned Turing model returning samples from the posterior distribution of the composed model parameters and generated quantities.

```{julia}
inference_results = apply_method(mdl,
    inference_method,
    training_data
)
```

The `inference_results` object includes standard MCMC chain output along with the basic "R hat" chain diagnostic measure.
```{julia}
display(inference_results.samples[:, 1:10, :])
```

Note that we display a subslice of parameters for brevity.

#### Case Study 1: Predictive plotting

To assess the quality of the inference visually we can plot predictive quantiles for generated case data, as well as quantities of interest such as posterior $R_t$ samples from the model.


```{julia}
#| echo: false

dates_to_times(dates) = [(d - minimum(dates)).value + 1 for d in dates]

function generated_quantiles(gens, quantity, qs; transformation = x -> x)
    mapreduce(hcat, gens) do gen #loop over sampled generated quantities
        getfield(gen, quantity) |> transformation
    end |> mat -> mapreduce(hcat, qs) do q #Loop over matrix row to condense into qs
        map(eachrow(mat)) do row
            if any(ismissing, row)
                return missing
            else
                quantile(row, q)
            end
        end
    end
end

function identify_good_chains(chn; threshold = 3.0)
    lps = chn[:lp] |> X -> mean(X, dims =1) |> vec
    idxs = findall(maximum(lps) .- lps .< threshold)
    return idxs
end

function posterior_gens_for_plot(inference_results, n; fixed_cluster_factor, threshold)
    #Case unconditional model for posterior predictive sampling
    #Supports conditional cluster factor
    mdl_unconditional = isnothing(fixed_cluster_factor) ?
        generate_epiaware(epi_prob,(y_t = fill(missing, n),)) :
        generate_epiaware(epi_prob, (y_t = fill(missing, n),)) | (var"obs.cluster_factor" = fixed_cluster_factor,) 
    
    # Posterior predictive sampling
    good_chns = identify_good_chains(inference_results.samples; threshold)
    posterior_gens = generated_quantities(mdl_unconditional, inference_results.samples[:, :, good_chns])

    return posterior_gens
end

function post_predictive_yt!(ax, inference_data, posterior_gens; qs)
    # Convert into numbers for xaxis flexibility
    ts = dates_to_times(inference_data.dates)
    predicted_y_t = generated_quantiles(posterior_gens, :generated_y_t, qs)
    #Remove any predictions with missing values from beginning of generate y_t
    n = count(row -> any(ismissing.(row)), eachrow(predicted_y_t))
    predicted_y_t = predicted_y_t[(n+1):end, :] 

    lines!(ax, ts[(n+1):end], predicted_y_t[:, 3];
        color = :purple,
        linewidth = 2,
        label = "Post. median"
    )
    band!(ax, ts[(n+1):end], predicted_y_t[:, 2], predicted_y_t[:, 4];
        color = (:purple, 0.4),
        label = "50%"
    )
    band!(ax, ts[(n+1):end], predicted_y_t[:, 1], predicted_y_t[:, 5];
        color = (:purple, 0.2),
        label = "95%"
    )
    scatter!(ax, ts, inference_data.y_t;
        color = :black,
        label = "Actual cases")
    axislegend(ax)

    return nothing
end

function post_predictive_Rt!(ax, inference_data, posterior_gens; qs)
    ts = dates_to_times(inference_data.dates)
    #Prediction quantiles
    predicted_R_t = generated_quantiles(posterior_gens, :Z_t, qs;
            transformation = x -> exp.(x))

    lines!(ax, ts, predicted_R_t[:, 3];
        color = :green,
        linewidth = 2,
        label = "Post. median"
    )
    band!(ax, ts, predicted_R_t[:, 2], predicted_R_t[:, 4];
        color = (:green, 0.4),
        label = "50%"
    )
    band!(ax, ts, predicted_R_t[:, 1], predicted_R_t[:, 5];
        color = (:green, 0.2),
        label = "95%"
    )
    axislegend(ax)
end


```

```{julia}
#| output: true
#| echo: false
#| label: fig-posterior-preds-CS1
#| fig-cap: (Top) Comparison of continuous serial interval distribution with double censored discrete distribution used in modelling. (Middle) Posterior predictive distribution for cases from model showing posterior median per day (purple line) and credible intervals (purple ribbons). (Bottom) Posterior predictive distribution for time-varying reproductive number with median on each day (green line) and credible intervals (green ribbons).

figure2 = let 
    qs = [0.025, 0.25, 0.5, 0.75, 0.975]
    # Get Ticks
    t_ticks = @chain training_data begin
            _.dates
            string.(_)
        end
    ts = dates_to_times(training_data.dates)
    # Posterior generative plotting
    posterior_gens = posterior_gens_for_plot(inference_results, length(training_data.y_t); 
            fixed_cluster_factor = fixed_cluster_factor,
            threshold = 3.0)

    # Figure scene
    fig = Figure(size = (800, 800))

    # Axis definitions
    ax1 = Axis(fig[1, 1];
        xticks = 0:14,
        xlabel = "Days",
        title = "Continuous and discrete generation intervals"
    )
    ax2 = Axis(fig[2, 1];
        ylabel = "Daily cases",
        xticks = (ts[1:14:end], t_ticks[1:14:end]),
        title = "Posterior predictive: Cases"
    )
    ax3 = Axis(fig[3, 1];
        yscale = log10,
        title = "Prediction: Reproductive number",
        xticks = (ts[1:14:end], t_ticks[1:14:end])
    )
    linkxaxes!(ax2, ax3)

    # Plot functions into axes
    discretised_gen_plot!(ax1, model_data, truth_SI)
    post_predictive_yt!(ax2, training_data, posterior_gens; qs)
    post_predictive_Rt!(ax3, training_data, posterior_gens; qs)

    fig
end


figure2
```

Figure @fig-posterior-preds-CS1 shows that the compositional model defined using our prototype system recovers the main finding in *Mishra et al*; that the $R_t$ in South Korea peaked at a very high value ($R_t \sim 10$ at peak) before rapidly dropping below 1 in early March 2020.

We can also interrogate joint posterior distribution of selected model parameters using pair plotting.

```{julia}
#| output: true
#| echo: false
#| label: fig-pairwise-CS1
#| fig-cap: Pair plotting of joint posterior distribution of the AR(2) hyperparameters and the initial number of latent infecteds.
using PairPlots
parameters_to_plot = ["latent.ar_init[1]", 
                            "latent.ar_init[2]", 
                            "latent.damp_AR[1]",
                            "latent.damp_AR[2]",
                            "latent.std",
                            "init_incidence"]

fig = @chain inference_results.samples begin
    identify_good_chains(; threshold = 3.0)
    inference_results.samples[:, :, _]
    pairplot(_[parameters_to_plot])
end

fig
```

## EpiNow2: Estimate Real-Time Case Counts and Time-Varying Epidemiological Parameters {#sec-example2}

This case study recreates a representative EpiNow2 configuration, demonstrating how our compositional approach can represent a complex inference and forecasting workflow used in real-time epidemiological surveillance.

EpiNow2 [@abbott-epinow2-wellcomeopenres] is a widely-used R package for estimating the time-varying reproduction number and making forecasts for epidemics in real-time.
It represents a further development in Renewal-based transmission modelling compared to *Mishra et al* @mishra introduced in example 1.
EpiNow2 is built around three core modeling components that work together to reconstruct epidemic dynamics from delayed and noisy case count observations:

1.  **Renewal-based transmission modeling with generation intervals**: EpiNow2 uses the discrete renewal equation to model how new infections arise from previous infections, weighted by the generation time distribution (the time between successive infections in a transmission chain).
    This follows *Mishra et al* as demonstrated in example 1.

2.  **Delayed observation processes**: The framework explicitly accounts for the delay between infection and case reporting, which typically involves multiple sequential delays including incubation periods and reporting lags.

3.  **Temporal modifiers to observation**: Case counts are modeled using a (default) negative binomial distribution to capture overdispersion, with additional modifiers such as day-of-week effects to account for systematic biases in reporting patterns.

In this example, we use out compositional approach in `EpiAware` to demonstrate layering modelling components 2 and 3 onto the Renewal-based transmission model we already defined in example 1.
We recreate the core EpiNow2 functionality by **reusing model components from Example 1** and **composing them with new delay and temporal effect components**.
This showcases the flexibility and modularity of our approach - rather than implementing everything from scratch, we build upon previously defined components in a principled way.
We will reuse the renewal-based epidemiological model and AR latent process from Example 1, while introducing new observation model components to handle reporting delays and day-of-week effects.

### Reporting delays, incubation period and generation time

Delayed reporting of cases is a critical consideration in epidemiological modelling because it can substantially distort the apparent trajectory of an outbreak.
When cases are reported with a delay, the most recent data will systematically underestimate the true number of infections, leading to biased estimates of key epidemiological parameters such as the reproduction number ($R_t$) and growth rates.
Accurately accounting for reporting delays allows models to reconstruct the true epidemic curve, improve nowcasting, and provide more reliable situational awareness for public health decision-making.
Ignoring these delays can result in misleading trends, delayed detection of changes in transmission, and suboptimal intervention strategies.

Mathematically, we represent delays by modelling the expected number of cases observed on each day as being a weighted sum on recent latent infections:

$$
\begin{aligned}
D_t &= \sum_{s\geq1} I_{t-s} \xi_s,~~ \text{Delayed latent infections}\\
\tilde{\omega}_k &\sim \text{N}(0, \sigma^2_\omega),~ k = 0,\dots, 6,~~ \text{Day-of-week modifier} \\
\omega &= 7 \times \text{softmax}(\tilde{\omega}),\\
C_t &\sim \text{NegBin}( D_t \omega_{t~\text{mod}~7}, \phi),~~ \text{Link to data}.
\end{aligned}
$$ {#eq-epinow2-model}

Where $D_t$ is a "naive" direct convolution on the latent infection time series that maps infections from *before* day $t$ into observations *on* day $t$.
$\overline{C}(t)$ is the expected cases observed on day $t$ after further modification by a day of the week effect @abbott-epinow2-wellcomeopenres.
Equation @eq-epinow2-model is represented in code as three operations: the convolution represents delaying possible observation of latent infections $I_t$ by a random duration with pmf $\xi_t$ .
The random vector $\omega = [\omega_0,\dots,\omega_6]$ encodes a modifying effect of the day of week on the delayed observation (e.g. reporting might be suppressed on typical Sundays).
The final equation defines a negative binomial link to data, which we can reuse from example 1.

In `EpiAware`, we recreate this complex observation process through **composition** of modular components.
We **reuse the underlying negative binomial link observation model (`obs`) from Example 1**, demonstrating the modularity of our approach.
We then layer additional modeling components on top.

Because weekly temporal effects in ascertainment of latent infections are a common modelling pattern we create a helper function which takes in the link model `obs` and the model for the unconstrained ascertainment effects $\tilde{\omega}$.

```{julia}
dayofweek_logit_ascert = ascertainment_dayofweek(obs;  # Reuse obs from Example 1
    latent_model = HierarchicalNormal(std_prior = HalfNormal(1.0))
    ) 
```

Unpacking this helper function we have a nested stack of modelling constructions.
First on the transformation and broadcasting,

```{julia}
print(@code_string broadcast_dayofweek(HierarchicalNormal()))
```

Which uses the `TransformLatentModel` and `BroadcastLatentModel` structs to dispatch the transformation $\omega = 7 \times \text{softmax}(\tilde{\omega})$ and then broadcast this along the time series.

And second on the action of ascertainment as a multiplier on the time series of latent infections along with the probabilistic model for $\tilde{\omega}$ and variable prefixing.

```{julia}
print(@code_string ascertainment_dayofweek(NegativeBinomialError()))
```

For this example we choose a latent delay distribution of median 5 days with LogNormal errors,

```{julia}
delay_distribution = LogNormal(log(5), 0.2)
```

The `LatentDelay` struct uses double interval censoring to convert this continuous delay model into the pmf $\xi_t$ and stacks with the temporal modifier model defined above.

```{julia}
delayed_obs = LatentDelay(dayofweek_logit_ascert, delay_distribution)
display(delayed_obs)
```

This code demonstrates three key aspects of our compositional approach:

1.  **Component reuse**: The base observation model `obs` from Example 1 is reused without modification, showing how components can be shared across different modeling scenarios.

2.  **Layered composition**: We add day-of-week effects through `ascertainment_dayofweek()`, which wraps the base observation model with temporal modifiers.
    At this stage we add a latent model to describe the distribution of $\omega$, choosing hierarchical normal random variables with the default transformation `7 * softmax` which applies the constraints: $\omega_t \geq 0$ and $\frac{1}{7}\sum_{0}^6 \omega_t = 1$.

3.  **Sequential composition**: We then add reporting delays through `LatentDelay()`, which wraps the day-of-week modified model with a convolution delay operation.
    The delay is specified with a continuous delay distribution which is converted by double-censoring on a daily scale into the discrete pmf $\xi_t$.
    For this example, we choose a median of 5 days between latent infection and observation.

### Demonstrating the delay and day-of-week effects

The resulting `delayed_obs` model combines negative binomial observation noise, day-of-week effects, and reporting delays into a single coherent observation process.
The conversion from the continuous `delay_distribution` to a discrete (daily) probability mass function happens automatically, as described in the [renewal model section](#the-renewal-model-as-an-abstractepimodel-type).

To illustrate how these effects work together, let's examine how they transform a simple oscillating latent infection signal:

```{julia}
#| output: true
#| echo: false
#| label: fig-delay-with-dow-effect

log_scale_dow_effect = [1.0; zeros(6)]
plt_delayed_obs = let
    latent_infections = [500 * (1 + cospi(2 * t / 30.0)) for t = 1:(7*10)]
    obs_mdl = generate_observations(delayed_obs, missing, latent_infections) | 
        (var"DayofWeek.ϵ_t" = log_scale_dow_effect,)
    n_samples = 100
    obs_mdl_samples = mapreduce(hcat, 1:n_samples) do _
        θ = obs_mdl() #Sample unconditionally the underlying parameters of the model
    end
    fig = Figure()
    ax = Axis(fig[1, 1];
        title = "$(n_samples) draws from delay model with day-of-week effect",
        ylabel = "Observed cases"
    )
    for col in eachcol(obs_mdl_samples)
        scatter!(ax, col;
            color = (:grey, 0.2)
        )
    end
    lines!(ax, latent_infections;
        color = :red,
        linewidth = 3,
        label = "Latent infections"
    )
    axislegend(ax)
    fig
end
```

Compared to an oscillating latent infection signal, we can see that the generated data exhibits two key features: the observations are **delayed** (the peak observations occur after the true latent signal peaks) and can have **systematically higher observations on specific days of the week** (here, the first day of the week shows enhanced reporting).

### Building the complete EpiNow2-style model

Now we compose this new observation model with the epidemiological and latent components from Example 1.
This demonstrates a key advantage of our compositional approach: we can mix and match validated components across different modeling scenarios without any reimplementation.

In EpiNow2, although stationary processes representations $R_t$ are available, the default latent process is a *differenced* stationary (Matern) Gaussian Process; that is the default $R_t$ process is stationary only on its increments.
In analogy, we compose the latent AR(2) process used in example 1 with the modifer `DiffLatentModel`.
This reuses the latent model we had for $R_t$ in example 1 but applies it to the increments $R_{t} - R_{t-1}$.

```{julia}
diff_ar = DiffLatentModel(ar, Normal(); d = 1) # Normal prior for initial value of process
```

As in example 1 we compose these modelling subcomponents into one `EpiProblem` model.

```{julia}
cutout = length(delayed_obs.rev_pmf)

epi_prob_with_delay = EpiProblem(epi_model = epi,          # Reused from Example 1
    latent_model = diff_ar,                                # modified from Example 1  
    observation_model = delayed_obs,                       # New compositional model
    tspan = (45-cutout, 80))                               # Longer time span because of delay
```

This `EpiProblem` reuses all three core components from Example 1: - **`epi`**: The renewal-based epidemiological model with generation time distribution - **`ar`**: The AR(2) latent process model for time-varying transmission rates, used in `diff_ar` - **`obs`**: The negative binomial link model to data from expected observations.

While introducing our new compositional observation model that combines delays and day-of-week effects in the correct EpiNow2 ordering.

### Preparing data and model for inference

We need to account for the extended time window required to handle reporting delays:

```{julia}
longer_south_korea_data = (
    y_t = data.cases_new[(epi_prob_with_delay.tspan[1]):epi_prob_with_delay.tspan[2]],
    dates = data.date[(epi_prob_with_delay.tspan[1]):epi_prob_with_delay.tspan[2]],
    )
```

As mentioned in [example 1](#inference-and-analysis), adding delay effects helps disentangle reporting variance from changes in the reproductive number.
This makes the cluster factor parameter $\phi$ of the negative binomial distribution identifiable.
Unlike Example 1, we now let this parameter be jointly inferred rather than conditioning on a fixed value, following EpiNow2's approach:

```{julia}
mdl_with_delay = generate_epiaware(epi_prob_with_delay, longer_south_korea_data)
```

We can reuse the same `inference_method` defined in Example 1, showcasing how our inference setup can be applied across different model compositions:

```{julia}
inference_results_with_delay = apply_method(mdl_with_delay,
    inference_method,
    longer_south_korea_data
)
```

### Analysis of results

The EpiNow2-style model with delays and day-of-week effects provides several advantages over the simpler model in Example 1.
Most importantly, the explicit modeling of reporting delays helps disentangle true changes in transmission dynamics from observation artifacts, leading to more reliable $R_t$ estimates.

#### Posterior predictive checking

Let's examine how well our model captures the observed data patterns:

```{julia}
#| output: true
#| echo: false
#| label: fig-posterior-preds-example2
plot_post_pred(longer_south_korea_data, inference_results_with_delay; 
        epi_prob = epi_prob_with_delay
        )
```

The posterior predictive plots show that the model successfully captures both the overall epidemic trajectory and the day-to-day variation in case counts.
The inclusion of delay and day-of-week effects allows the model to account for reporting irregularities that would otherwise be attributed to changes in transmission.

#### Latent process parameters

The AR(2) latent process parameters remain well-identified even with the more complex observation model:

```{julia}
#| output: true
#| echo: false
#| label: fig-pairwise-example-2-latent-parameters

parameters_to_plot = ["latent.ar_init[1]", 
                            "latent.ar_init[2]", 
                            "latent.damp_AR[1]",
                            "latent.damp_AR[2]",
                            "latent.std",
                            "init_incidence"]

priors_to_plot = [
    ar.init_prior.v[1],
    ar.init_prior.v[2],
    ar.damp_prior.v[1],
    ar.damp_prior.v[2],
    ar.ϵ_t.std_prior,
    epi.initialisation_prior,
]

fig = pairplot(inference_results_with_delay.samples[parameters_to_plot])

fig
```

#### Observation model parameters

The newly introduced observation model components are also well-identified:

```{julia}
#| output: true
#| echo: false
#| label: fig-pairwise-example-2-obs-parameters

parameters_to_plot = ["obs.DayofWeek.std",
                            "obs.DayofWeek.ϵ_t[7]",
                            "obs.cluster_factor"]

priors_to_plot = [
    delayed_obs.model.latent_model.model.model.model.std_prior,
    nothing,
    delayed_obs.model.model.cluster_factor_prior,
]

fig = pairplot(inference_results_with_delay.samples[parameters_to_plot])

fig
```

## Contemporary statistical inference for infectious disease models using Stan {#sec-example3}

<!-- Reference: https://www.sciencedirect.com/science/article/pii/S1755436519300325 -->

<!-- Implementation: https://cdcgov.github.io/Rt-without-renewal/stable/showcase/replications/chatzilena-2019/ -->

In this vignette, we'll demonstrate how to use `EpiAware` in conjunction with [SciML ecosystem](https://sciml.ai/) for Bayesian inference of infectious disease dynamics.
The model and data is heavily based on [Contemporary statistical inference for infectious disease models using Stan *Chatzilena et al. 2019*](https://www.sciencedirect.com/science/article/pii/S1755436519300325).

We'll cover the following key points:

1.  Defining the deterministic ODE model from Chatzilena et al section 2.2.2 using SciML ODE functionality and an `EpiAware` observation model.
2.  Build on this to define the stochastic ODE model from Chatzilena et al section 2.2.3 using an `EpiAware` observation model.
3.  Fitting the deterministic ODE model to data from an Influenza outbreak in an English boarding school.
4.  Fitting the stochastic ODE model to data from an Influenza outbreak in an English boarding school.

### Packages used in this vignette

Alongside the `EpiAware` package we will use the `OrdinaryDiffEq` and `SciMLSensitivity` packages for interfacing with `SciML` ecosystem; this is a lower dependency usage of `DifferentialEquations.jl` that, respectively, exposes ODE solvers and adjoint methods for ODE solvees; that is the method of propagating parameter derivatives through functions containing ODE solutions.
Bayesian inference will be done with `NUTS` from the `Turing` ecosystem.
We will also use the `CairoMakie` package for plotting and `DataFramesMeta` for data manipulation.

```{julia}
using OrdinaryDiffEqTsit5, OrdinaryDiffEqRosenbrock, SciMLSensitivity #ODE solvers and adjoint methods
using LogExpFunctions #Additional statistics functions

```

### Single population SIR model

As mentioned in *Chatzilena et al* disease spread is frequently modelled in terms of ODE-based models.
The study population is divided into compartments representing a specific stage of the epidemic status.
In this case, susceptible, infected, and recovered individuals.

\begin{align}
{dS \over dt} &= - \beta \frac{I(t)}{N} S(t) \\
{dI \over dt} &= \beta \frac{I(t)}{N} S(t) - \gamma I(t) \\
{dR \over dt} &= \gamma I(t).
\end{align}

where S(t) represents the number of susceptible, I(t) the number of infected and R(t) the number of recovered individuals at time t.
The total population size is denoted by N (with N = S(t) + I(t) + R(t)), β denotes the transmission rate and γ denotes the recovery rate.

We can interface to the `SciML` ecosystem by writing a function with the signature:

> `(du, u, p, t) -> nothing`

Where: - `du` is the *vector field* of the ODE problem, e.g. ${dS \over dt}$, ${dI \over dt}$ etc.
This is calculated *in-place* (commonly denoted using ! in function names in Julia).
- `u` is the *state* of the ODE problem, e.g. $S$, $I$, etc. - `p` is an object that represents the parameters of the ODE problem, e.g. $\beta$, $\gamma$.
- `t` is the time of the ODE problem.

We do this for the SIR model described above in a function called `sir!`:

```{julia}
function sir!(du, u, p, t)
    S, I, R = u
    β, γ = p
    du[1] = -β * I * S
    du[2] = β * I * S - γ * I
    du[3] = γ * I

    return nothing
end
```

We combine vector field function `sir!` with a initial condition `u0` and the integration period `tspan` to make an `ODEProblem`.
We do not define the parameters, these will be defined within an inference approach.

Note that this is analogous to the `EpiProblem` approach we expose from `EpiAware`, as used in the [Mishra et al replication](https://cdcgov.github.io/Rt-without-renewal/dev/showcase/replications/mishra-2020/).
The difference is that here we are going to use ODE solvers from the `SciML` ecosystem to generate the dynamics of the underlying infections.
In the linked example, we use latent process generation exposed by `EpiAware` as the underlying generative process for underlying dynamics.

### Data for inference

There was a brief, but intense, outbreak of Influenza within the (semi-) closed community of a boarding school reported to the British medical journal in 1978.
The outbreak lasted from 22nd January to 4th February and it is reported that one infected child started the epidemic and then it spread rapidly.
Of the 763 children at the boarding scholl, 512 became ill.

We downloaded the data of this outbreak using the R package `outbreaks` which is maintained as part of the [R Epidemics Consortium(RECON)](http://www.%20repidemicsconsortium.org).

```{julia}
data = CSV.read("data/influenza_england_1978_school.csv", DataFrame) |>
              df -> @transform(df,
    :ts=(:date .- minimum(:date)) .|> d -> d.value + 1.0,)

N = 763

sir_prob = ODEProblem(
    sir!,
    N .* [0.99, 0.01, 0.0],
    (0.0, (Date(1978, 2, 4) - Date(1978, 1, 22)).value + 1)
)
```

### Inference for the deterministic SIR model

The boarding school data gives the number of children "in bed" and "convalescent" on each of 14 days from 22nd Jan to 4th Feb 1978.
We follow *Chatzilena et al* and treat the number "in bed" as a proxy for the number of children in the infectious (I) compartment in the ODE model.

The full observation model is:

\begin{align}
Y_t &\sim \text{Poisson}(\lambda_t)\\
\lambda_t &= I(t)\\
\beta &\sim \text{LogNormal}(\text{logmean}=0,\text{logstd}=1) \\
\gamma & \sim \text{Gamma}(\text{shape} = 0.004, \text{scale} = 50)\\
S(0) /N &\sim \text{Beta}(0.5, 0.5).
\end{align}

**NB: Chatzilena et al give** $\lambda_t = \int_0^t  \beta \frac{I(s)}{N} S(s) - \gamma I(s)ds = I(t) - I(0).$ However, this doesn't match their underlying stan code.

From `EpiAware`, we have the `PoissonError` struct which defines the probabilistic structure of this observation error model.

```{julia}
obs = PoissonError()
display(obs)
```

Now we can write the probabilistic model using the `Turing` PPL. Note that instead of using $I(t)$ directly we do the [softplus](https://en.wikipedia.org/wiki/Softplus) transform on $I(t)$ implemented by `LogExpFunctions.log1pexp`.
The reason is that the solver can return small negative numbers, the soft plus transform smoothly maintains positivity which being very close to $I(t)$ when $I(t) > 2$.

```{julia}
@model function deterministic_ode_mdl(y_t, ts, obs, prob, N;
        solver = AutoTsit5(Rosenbrock23())
)
    ##Priors##
    β ~ LogNormal(0.0, 1.0)
    γ ~ Gamma(0.004, 1 / 0.002)
    S₀ ~ Beta(0.5, 0.5)

    ##remake ODE model##
    _prob = remake(prob;
        u0 = [S₀, 1 - S₀, 0.0],
        p = [β, γ]
    )

    ##Solve remade ODE model##

    sol = solve(_prob, solver;
        saveat = ts,
        verbose = false)

    ##log-like accumulation using obs##
    λt = log1pexp.(N * sol[2, :]) # #expected It
    @submodel generated_y_t = generate_observations(obs, y_t, λt)

    ##Generated quantities##
    return (; sol, generated_y_t, R0 = β / γ)
end
```

We instantiate the model in two ways:

1.  `deterministic_mdl`: This conditions the generative model on the data observation. We can sample from this model to find the posterior distribution of the parameters.
2.  `deterministic_uncond_mdl`: This *doesn't* condition on the data. This is useful for prior and posterior predictive modelling.

Here we construct the `Turing` model directly, in the [Mishra et al replication](https://cdcgov.github.io/Rt-without-renewal/dev/showcase/replications/mishra-2020/) we using the `EpiProblem` functionality to build a `Turing` model under the hood.
Because in this note we are using a mix of functionality from `SciML` and `EpiAware`, we construct the model to sample from directly.

```{julia}
deterministic_mdl = deterministic_ode_mdl(data.in_bed, data.ts, obs, sir_prob, N)
deterministic_uncond_mdl = deterministic_ode_mdl(
    fill(missing, length(data.in_bed)), data.ts, obs, sir_prob, N)
```

```{julia}
#| echo: false
function plot_predYt(data, gens; title::String, ylabel::String)
    fig = Figure()
    ga = fig[1, 1:2] = GridLayout()

    ax = Axis(ga[1, 1];
        title = title,
        xticks = (data.ts[1:3:end], data.date[1:3:end] .|> string),
        ylabel = ylabel
    )
    pred_Yt = mapreduce(hcat, gens) do gen
        gen.generated_y_t
    end |> X -> mapreduce(vcat, eachrow(X)) do row
        quantile(row, [0.5, 0.025, 0.975, 0.1, 0.9, 0.25, 0.75])'
    end

    lines!(ax, data.ts, pred_Yt[:, 1]; linewidth = 3, color = :green, label = "Median")
    band!(
        ax, data.ts, pred_Yt[:, 2], pred_Yt[:, 3], color = (:green, 0.2), label = "95% CI")
    band!(
        ax, data.ts, pred_Yt[:, 4], pred_Yt[:, 5], color = (:green, 0.4), label = "80% CI")
    band!(
        ax, data.ts, pred_Yt[:, 6], pred_Yt[:, 7], color = (:green, 0.6), label = "50% CI")
    scatter!(ax, data.in_bed, label = "data")
    leg = Legend(ga[1, 2], ax; framevisible = false)
    hidespines!(ax)

    fig
end
```

**Prior predictive sampling**

```{julia}
prior_chn = sample(deterministic_uncond_mdl, Prior(), 2000)
gens = generated_quantities(deterministic_uncond_mdl, prior_chn)
```

```{julia}
#| output: true
#| echo: false
#| label: fig-prior-pred-det
    
plot_predYt(data, gens;
    title = "Prior predictive: deterministic model",
    ylabel = "Number of Infected students"
)

```

The prior predictive checking suggests that *a priori* our parameter beliefs are very far from the data.
Approaching the inference naively can lead to poor fits.

We do three things to mitigate this:

1.  We choose a switching ODE solver which switches between explicit (`Tsit5`) and implicit (`Rosenbrock23`) solvers. This helps avoid the ODE solver failing when the sampler tries extreme parameter values. This is the default `solver = AutoTsit5(Rosenbrock23())` above.
2.  We locate the maximum likelihood point, that is we ignore the influence of the priors, as a useful starting point for `NUTS`.

```{julia}
nmle_tries = 100

mle_fit = map(1:nmle_tries) do _
    fit = try
        maximum_likelihood(deterministic_mdl)
    catch
        (lp = -Inf,)
    end
end |>
          fits -> (findmax(fit -> fit.lp, fits)[2], fits) |>
                  max_and_fits -> max_and_fits[2][max_and_fits[1]]

mle_fit.optim_result.retcode
```

Note that we choose the best out of \$nmle_tries tries for the MLE estimators.

Now, we sample aiming at 1000 samples for each of 4 chains.

```{julia}
chn = sample(
    deterministic_mdl, NUTS(), MCMCThreads(), 1000, 4;
    initial_params = fill(mle_fit.values.array, 4)
)

describe(chn)
```

```{julia}
#| output: true
#| echo: false
#| label: fig-pairplot-det
pairplot(chn)
```

**Posterior predictive plotting**

```{julia}
gens = generated_quantities(deterministic_uncond_mdl, chn)
```

```{julia}
#| output: true
#| echo: false
#| label: fig-posterior-pred-det
plot_predYt(data, gens;
    title = "Fitted deterministic model",
    ylabel = "Number of Infected students"
)

```

### Inference for the Stochastic SIR model

In *Chatzilena et al*, they present an auto-regressive model for connecting the outcome of the ODE model to illness observations.
The argument is that the stochastic component of the model can absorb the noise generated by a possible mis-specification of the model.

In their approach they consider $\kappa_t = \log \lambda_t$ where $\kappa_t$ evolves according to an Ornstein-Uhlenbeck process:

$$
d\kappa_t = \phi(\mu_t - \kappa_t) dt + \sigma dB_t.
$$ Which has transition density: $$
\kappa_{t+1} | \kappa_t \sim N\Big(\mu_t + \left(\kappa_t - \mu_t\right)e^{-\phi}, {\sigma^2 \over 2 \phi} \left(1 - e^{-2\phi} \right)\Big).
$$ Where $\mu_t = \log(I(t))$.

We modify this approach since it implies that the $\mu_t$ is treated as constant between observation times.

Instead we redefine $\kappa_t$ as the log-residual:

$\kappa_t = \log(\lambda_t / I(t)).$

With the transition density:

$$
\kappa_{t+1} | \kappa_t \sim N\Big(\kappa_te^{-\phi}, {\sigma^2 \over 2 \phi} \left(1 - e^{-2\phi} \right)\Big).
$$

This is an AR(1) process.

The stochastic model is completed:

\begin{align}
Y_t &\sim \text{Poisson}(\lambda_t)\\
\lambda_t &= I(t)\exp(\kappa_t)\\
\beta &\sim \text{LogNormal}(\text{logmean}=0,\text{logstd}=1) \\
\gamma & \sim \text{Gamma}(\text{shape} = 0.004, \text{scale} = 50)\\
S(0) /N &\sim \text{Beta}(0.5, 0.5)\\
\phi & \sim \text{HalfNormal}(0, 100) \\
1 / \sigma^2 & \sim \text{InvGamma}(0.1,0.1).
\end{align}

We will using the `AR` struct from `EpiAware` to define the auto-regressive process in this model which has a direct parameterisation of the `AR` model.

To convert from the formulation above we sample from the priors, and define `HalfNormal` priors based on the sampled prior means of $e^{-\phi}$ and ${\sigma^2 \over 2 \phi} \left(1 - e^{-2\phi} \right)$.
We also add a strong prior that $\kappa_1 \approx 0$.

```{julia}
ϕs = rand(truncated(Normal(0, 100), lower = 0.0), 1000)
σ²s = rand(InverseGamma(0.1, 0.1), 1000) .|> x -> 1 / x
sampled_AR_damps = ϕs .|> ϕ -> exp(-ϕ)
sampled_AR_stds = map(ϕs, σ²s) do ϕ, σ²
    (1 - exp(-2 * ϕ)) * σ² / (2 * ϕ)
end
```

We define the AR(1) process by matching means of `HalfNormal` prior distributions for the damp parameters and std deviation parameter to the calculated the prior means from the *Chatzilena et al* definition.

```{julia}
ar = AR(
    damp_priors = [HalfNormal(mean(sampled_AR_damps))],
    init_priors = [Normal(0, 0.001)],
    ϵ_t = HierarchicalNormal(std_prior = HalfNormal(mean(sampled_AR_stds)))
)
```

We can sample directly from the behaviour specified by the `ar` struct to do prior predictive checking on the `AR(1)` process.

```{julia}
#| output: true
#| echo: false
#| label: fig-ar-prior-pred
ar_prior_pred_plot = let
    nobs = size(data, 1)
    ar_mdl = generate_latent(ar, nobs)
    fig = Figure()
    ax = Axis(fig[1, 1],
        xticks = (data.ts[1:3:end], data.date[1:3:end] .|> string),
        ylabel = "exp(kt)",
        title = "Prior predictive sampling for relative residual in mean pred."
    )
    for i in 1:500
        lines!(ax, ar_mdl() .|> exp, color = (:grey, 0.15))
    end
    fig
end
ar_prior_pred_plot
```

We see that the choice of priors implies an *a priori* belief that the extra observation noise on the mean prediction of the ODE model is fairly small, approximately 10% relative to the mean prediction.

We can now define the probabilistic model.
The stochastic model assumes a (random) time-varying ascertainment, which we implement using the `Ascertainment` struct from `EpiAware`.
Note that instead of implementing an ascertainment factor `exp.(κₜ)` directly, which can be unstable for large primal values, by default `Ascertainment` uses the `LogExpFunctions.xexpy` function which implements $x\exp(y)$ stabily for a wide range of values.

To distinguish random variables sampled by various sub-processes `EpiAware` process types create prefixes.
The default for `Ascertainment` is just the string `\"Ascertainment\"`, but in this case we use the less verbose `\"va\"` for "varying ascertainment".

```{julia}
mdl_prefix = "va"
```

Now we can construct our time varying ascertianment model.
The main keyword arguments here are `model` and `latent_model`.
`model` sets the connection between the expected observation and the actual observation.
In this case, we reuse our `PoissonError` model from above.
`latent_model` sets the modification model on the expected values.
In this case, we use the `AR` process we defined above.

```{julia}
varying_ascertainment = Ascertainment(
    model = obs,
    latent_model = ar,
    latent_prefix = mdl_prefix
)
```

Now we can declare the full model in the `Turing` PPL.

```{julia}
@model function stochastic_ode_mdl(y_t, ts, obs, prob, N;
        solver = AutoTsit5(Rosenbrock23())
)

    ##Priors##
    β ~ LogNormal(0.0, 1.0)
    γ ~ Gamma(0.004, 1 / 0.002)
    S₀ ~ Beta(0.5, 0.5)

    ##Remake ODE model##
    _prob = remake(prob;
        u0 = [S₀, 1 - S₀, 0.0],
        p = [β, γ]
    )

    ##Solve ODE model##
    sol = solve(_prob, solver;
        saveat = ts,
        verbose = false
    )
    λt = log1pexp.(N * sol[2, :])

    ##Observation##
    @submodel generated_y_t = generate_observations(obs, y_t, λt)

    ##Generated quantities##
    return (; sol, generated_y_t, R0 = β / γ)
end

stochastic_mdl = stochastic_ode_mdl(
    data.in_bed,
    data.ts,
    varying_ascertainment,
    sir_prob,
    N
)

stochastic_uncond_mdl = stochastic_ode_mdl(
    fill(missing, length(data.in_bed)),
    data.ts,
    varying_ascertainment,
    sir_prob,
    N
)
```

**Prior predictive checking**

```{julia}
prior_chn = sample(stochastic_uncond_mdl, Prior(), 2000)
gens = generated_quantities(stochastic_uncond_mdl, prior_chn)
```

```{julia}
#| output: true
#| echo: false
#| label: fig-prior-pred-stoch

plot_predYt(data, gens;
    title = "Prior predictive: stochastic model",
    ylabel = "Number of Infected students"
)

```

The prior predictive checking again shows misaligned prior beliefs; for example *a priori* without data we would not expect the median prediction of number of ill children as about 600 out of \$N after 1 day.

The latent process for the log-residuals $\kappa_t$ doesn't make much sense without priors, so we look for a reasonable MAP point to start NUTS from.
We do this by first making an initial guess which is a mixture of:

1.  The posterior averages from the deterministic model.
2.  The prior averages of the structure parameters of the AR(1) process.
3.  Zero for the time-varying noise underlying the AR(1) process.

```{julia}
initial_guess = [[mean(chn[:β]),
                     mean(chn[:γ]),
                     mean(chn[:S₀]),
                     mean(ar.init_prior)[1],
                     mean(ar.damp_prior)[1],
                     mean(ar.ϵ_t.std_prior)
                 ]
                 zeros(13)]
```

Starting from the initial guess, the MAP point is calculated rapidly in one pass.

```{julia}
map_fit_stoch_mdl = maximum_a_posteriori(stochastic_mdl;
    adtype = AutoReverseDiff(),
    initial_params = initial_guess
)
```

Now we can run NUTS, sampling 1000 posterior draws per chain for 4 chains.

```{julia}
chn2 = sample(
    stochastic_mdl,
    NUTS(; adtype = AutoReverseDiff(true)),
    MCMCThreads(), 1000, 4;
    initial_params = fill(map_fit_stoch_mdl.values.array, 4)
)

describe(chn2)
```

```{julia}
#| output: true
#| echo: false
#| label: fig-pairplot-stoch-params
pairplot(chn2[[:β, :γ, :S₀, Symbol(mdl_prefix * ".std"),
    Symbol(mdl_prefix * ".ar_init[1]"), Symbol(mdl_prefix * ".damp_AR[1]")]])
```

```{julia}
#| output: true
#| echo: false
#| label: fig-pairplot-stoch-eps
vars = mapreduce(vcat, 1:13) do i
    Symbol(mdl_prefix * ".ϵ_t[$i]")
end
pairplot(chn2[vars])
```

```{julia}
gens = generated_quantities(stochastic_uncond_mdl, chn2)
```

```{julia}
#| output: true
#| echo: false
#| label: fig-posterior-pred-stoch
plot_predYt(data, gens;
    title = "Fitted stochastic model",
    ylabel = "Number of Infected students"
)
```

# Discussion {#sec-discussion}

This paper has demonstrated that compositional approaches can address key barriers in epidemiological modelling.
We presented a prototype that enables "LEGO-like" model construction through standardised interfaces, maintaining the statistical rigour of joint models whilst providing the flexibility of pipeline approaches.
The autoregressive model example illustrated how complex models emerge from simple component combinations using the struct-in-struct pattern.
Our three case studies replicated previous studies [@mishra2020covid; @epinow2; @chatzilena2019contemporary], demonstrating model composability for a range of problems and using different underlying methods.

<!-- Strengths and weaknesses interwoven -->

-   Modular design enables rapid model development and component reuse, though requires learning curve for researchers familiar with monolithic approaches
-   Systematic comparison of modelling assumptions without large reimplementation, but computational overhead from abstraction layers
-   Transparent specification through explicit component interfaces improves reproducibility, yet interface standardisation may constrain some specialised approaches
-   Reduces implementation barriers for methodological advances, however current component library remains limited to basic epidemiological patterns
 - The Turing PPL DSL is not fully stable and since developing this prototype the submodel macro has changed syntax and had a breaking change in how it handles prefixes.
 - However, these changes allow for more flexible models as they reduce the difference betweeen specifying something as a distribution and as a sub model.
 - Ignores category theory.
 
<!-- Comparison to literature - Algebraic Julia -->

-   Builds on algebraic Julia ecosystem (DifferentialEquations.jl, etc.)
-   Extends scientific machine learning to epidemiological contexts
-   Utilises Julia's multiple dispatch for component composition

<!-- Comparison to literature - Other approaches -->

-   Contrast with pipeline approaches (separate models passing information)
-   Comparison to modular frameworks in other scientific domains
-   Relationship to probabilistic programming languages and compositional features
-   Gen.jl and Genify (https://ztangent.github.io/assets/pdf/2021-genify.pdf)

<!-- Future work -->

Areas for future work include expanding the component library to address epidemiological applications across multiple scales and data types.
Priority areas include retrospective analysis of historical outbreaks to develop robust templates for real-time response.
Integration of diverse domain expertise through models linking within-host dynamics, environmental surveillance, economic trade-offs, and behavioural feedback mechanisms is essential because disease transmission often emerges from complex interactions between biological, environmental, and social processes that single-domain models struggle to capture.
Methodological advances are also needed including for the joint estimation of interdependent epidemiological parameters, seamless integration of individual and population-level observations, and systematic evaluation of complementary surveillance approaches.
Alternative design patterns should also be investigated, particularly more formal category theory approaches that use operadic composition for mathematically rigorous hierarchical model construction, as demonstrated in AlgebraicPetri.jl and AlgebraicDynamics.jl [@libkind2022algebraic].
Symbolic-numeric frameworks like ModelingToolkit.jl [@modelingtoolkit2021] offer potential performance improvements through automatic optimisation and code generation.
However, these approaches require generalisation to explicitly model probabilities and support a range of different modelling approaches which are both essential for infectious disease modelling applications.
An alternative abstraction approach would be to build the domain-specific language on Distributions.jl rather than Turing.jl, which would enable compatibility with multiple probabilistic programming languages like JuliaBUGS whilst trading off the expressiveness of Turing's submodel interface.
Performance optimisation through parallelisation and approximate inference methods, along with integration bridges to existing epidemiological software ecosystems, will be essential for practical adoption.

<!-- Conclusions -->

A fully featured implementation of the prototype we present here has the potential to transform real-time analysis of infectious disease dynamics by enabling "LEGO-like" assembly of epidemiological components through standardised interfaces.
This prototype establishes the feasibility of integrating diverse expertise whilst maintaining statistical rigour, addressing key limitations of both pipeline and joint modelling approaches.
Given the unpredictable nature of future infectious disease threats such adaptable modelling capabilities that can rapidly incorporate diverse data sources and domain expertise are essential for future public health decision making.

## Acknowledgements

# References {.unnumbered}

::: {#refs}
:::