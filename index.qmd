---
title: "A prototype for compositional probabilistic infectious disease modelling"
authors:
  - name: "Sam Abbott"
    affiliations:
      - ref: lshtm
    email: "sam.abbott@lshtm.ac.uk"
    orcid: "0000-0001-8057-8037"
    attributes:
      corresponding: true
      equal-contributor: true
  - name: "Samuel P. C. Brand"
    affiliations:
      - ref: cdc
    email: "usi1@cdc.gov"
    orcid: "0000-0003-0645-5367"
    attributes:
      equal-contributor: true
  - name: "Hong Ge"
    affiliations:
      - ref: cambridge
    orcid: "0000-0001-9421-2677"
  - name: "Kaitlyn E. Johnson"
    affiliations:
      - ref: lshtm
    email: "kaitlyn.johnson@lshtm.ac.uk"
    orcid: "0000-0001-8011-0012"
  - name: "Anne Cori"
    affiliations:
      - ref: imperial
    orcid: "0000-0002-8443-9162"
  - name: "Sebastian Funk"
    affiliations:
      - ref: lshtm
    email: "sebastian.funk@lshtm.ac.uk"
    orcid: "0000-0002-2842-3406"

affiliations:
  - id: lshtm
    name: "Centre for Mathematical Modelling of Infectious Diseases, London School of Hygiene & Tropical Medicine, United Kingdom"
  - id: cdc
    name: "Center for Forecasting and Outbreak Analysis; Centers for Disease Control, United States of America"
  - id: cambridge
    name: "University of Cambridge, United Kingdom"
  - id: imperial
    name: "MRC Centre for Global Infectious Disease Analysis, School of Public Health, Imperial College London, United Kingdom"
date: today
monofont: JuliaMono
filters:
  - authors-block
abstract: |
  Recent outbreaks of Ebola, COVID-19 and mpox have demonstrated the value of modelling for synthesising data for rapid evidence to inform decision making. Effective models require integration of expert domain knowledge from clinical medicine, environmental science, behavioural research, and public health to accurately capture transmission processes, yet current modelling approaches create barriers to this integration. Methods used to synthesise available data broadly fall into pipeline approaches that chain separate models together, or joint models that are often monolithic and difficult to adapt. These barriers have prevented advances across multiple settings where models could have provided actionable insights. Composable models where components can be reused across different contexts and combined in various configurations whilst maintaining statistical rigour could address these limitations. In this work, we start by outlining the key requirements for a composable infectious disease modelling framework and then present a prototype that addresses these requirements through composable epidemiological components built on Julia's type system and `Turing.jl`. Our approach enables "LEGO-like" model construction where complex models emerge from composing simpler, reusable components. We demonstrate a prototype R interface showing how such frameworks bridge software ecosystems. Through three case studies, we show how components can be reused across different models whilst maintaining statistical rigour. The first replicates a COVID-19 analysis for South Korea using a renewal process with time-varying reproduction numbers. The second extends these components with reporting delays and day-of-week effects to replicate EpiNow2, a real-time nowcasting tool. The third integrates ODE solvers for compartmental disease transmission models applied to influenza outbreak data. Our approach demonstrates promise for enabling interdisciplinary collaboration by lowering technical barriers for domain experts to contribute directly to model development. Future work is needed to solve remaining composability challenges, explore other options, expand the component library, and explore opportunities for large language model assisted model construction.
---

```{julia}
#| output: false
#| echo: false
import QuartoTools
```

```{julia}
#| output: false
#| echo: false
using Random
Random.seed!(1234)
```

## Author Summary {.unnumbered}

When infectious disease outbreaks occur, mathematical models help synthesise available data to inform public health decisions.
However, building these models is time-consuming because components developed for one outbreak cannot easily be reused for another.
Current approaches either chain together separate models, which loses statistical information, or create large monolithic models that are difficult to adapt.
This means that at the start of outbreaks, modellers must rebuild models from scratch even when many underlying processes like reporting delays or contact patterns remain similar.

We developed a system that allows disease models to be built from reusable components, similar to assembling structures from building blocks.
Each component encapsulates a specific process such as how infections spread, how symptoms are reported, or how data are observed and can be swapped or combined whilst maintaining statistical rigour.
We validated this approach by recreating three published epidemiological analyses using shared components across different scenarios.

This work establishes requirements for composable modelling systems and demonstrates their feasibility through practical applications.
Such systems could enable faster response to emerging infectious disease threats by allowing researchers to adapt existing components rather than starting from scratch, and could lower barriers for domain experts to contribute specialised knowledge directly to model development.

# Introduction {#sec-introduction}

Modelling infectious disease dynamics can be a valuable tool for synthesising information and developing quantitative evidence for understanding and control [@heesterbeek15_modeling].
The utility of such models lies in their ability to combine expert knowledge about transmission with the often complex ways in which infections are ultimately observed - from environmental surveillance [e.g. in wastewater, @oreilly25_analysis] and by-products of clinical management [e.g., hospital admissions and bed occupancy, @davies21_associationcovidengland] to dedicated transmission studies [e.g., in households, @kombe19_model].
However, transmission mechanisms and observation processes vary across pathogens and settings, and, consequently, models are usually tailored to particular diseases and datasets.
This hampers transfer of learning.
For example, a model developed for real-time estimation of SARS-CoV-2 transmission integrating case counts, prevalence surveys, and severity data [@birrell2024] would not have carried over to subsequently studying the 2022 global outbreak of mpox, where contact structure and specific behaviours played a key role and would have needed to be represented explicitly in order to obtain correct insights [@Endo2022-ij].

As a consequence, modellers often have to re-implement model components in new models that used for different situations even when underlying concepts (e.g. of how prevalence surveys relate to underlying infection dynamics) are, in principle, the same.
This repeated re-implementation is wasteful and time-consuming at moments when evidence might be urgently needed [@whitty2015what].
It also limits opportunities for collaboration and co-development of robust methods that others can re-use, and raises technical barriers to building state-of-the-art models, as individual modellers must understand and implement all parts of the relevant transmission and observation models.
As an example, analyses during the COVID-19 pandemic demonstrated that cross-sectional viral-load measurements can inform epidemic dynamics [@hay21_estimating], yet this approach has not found its way into most models used to inform policy in real time even where such data was routinely available [@anderson20_reproduction].
An alternative is to use more generic modelling frameworks that are easier to generalise, but these can be difficult to adapt to capture transmission dynamics or aspects of the data generating process such as time-varying missing data [@Overton2023-dk].

Probabilistic programming languages (PPLs) such as Stan or LibBi [@Stan;@murray13_bayesian], and modelling frameworks such as pomp and monty [@king16_statistical;@fitzjohn25_monty], have transformed how infectious disease models are fitted to data.
These tools enable statistically principled inference with probabilistic reasoning across a wide range of applications.
However, they are designed for implementing complete models and do not provide straightforward ways to share or reuse model components.
The practical unit of reuse therefore remains the whole model or its codebase, not the underlying epidemiological concepts.
Building on these frameworks, several efforts have aimed for greater generality within specific modelling paradigms.
Effective reproduction number estimation illustrates this: `epidemia` [@scott2021_epidemia], `EpiNow2` [@epinow2], `epinowcast` [@epinowcast], `epimap` [@epimap], and `EpiLine` [@epiline] all estimate Rt using renewal-based approaches in Stan, yet maintain separate codebases with no shared components despite overlapping features and, in some cases, the same authors.
`epidemia` and `epimap` have had little recent development, `EpiLine` has minimal ongoing work, and whilst `EpiNow2` and `epinowcast` remain actively maintained, new features must be implemented separately in each.
Delay distribution estimation shows similar challenges.
`epidist` [@epidist] extends `brms` (Bayesian Regression Models using Stan) [@brms], a general-purpose regression tool built on Stan, allowing ecosystem integration but with limited scope for extension to other epidemiological models due to constraints in its composability.
`primarycensored` [@primarycensored] was developed to handle delays for `EpiNow2`, `epidist`, and `epinowcast` but is currently only used in `epidist` and requires maintaining parallel R and Stan codebases with the same functionality, and custom tooling to inject its code into the other packages models.
To work around these constraints, some analyses have adopted multi-stage or "pipeline" approaches, in which separate models are fitted sequentially and their outputs passed as inputs to subsequent stages [@huisman2022;@epinow2].
This allows different data sources or processes to be analysed independently and more flexibility but prevents full propagation of uncertainty and can introduce biased estimates compared with fully joint models [@lison2024].

Recent developments in computational statistics and scientific computing demonstrate the potential for composable modelling, in which components can be reused across contexts and combined in different configurations whilst maintaining statistical rigour.
Advances in `Turing.jl` have introduced submodel interfaces that enable composable probabilistic programming, offering a pathway for epidemiological model composition, though initial epidemiological applications revealed interoperability challenges [@Nicholson2022-ua; @fjelde2025turin].
These included handling data at different temporal resolutions and spatial granularities, situations where moment-matched Gaussian approximations (used in their approximate Markov melding approach) proved inadequate, and determining how best to weight different evidence sources whilst incorporating prior knowledge.
Importantly, their work focused on ad-hoc interoperable models for specific applications rather than a general system for question-agnostic interoperable modelling.
Category theory provides one mathematical framework for this composability through operadic composition (a mathematical framework for composing operations hierarchically where operations can have multiple inputs and be combined according to formal rules) in hierarchical model construction, as applied in the AlgebraicJulia ecosystem [@libkind2022algebraic].
Alternative approaches to compositional modelling include the SciML ecosystem's [@SciML] symbolic-numeric framework, where `ModelingToolkit.jl` [@modelingtoolkit2021] and `Catalyst.jl` [@loman2023catalyst] use acausal equation-based modelling with automated symbolic transformations to support mixed equation types including differential-algebraic equations, partial differential equations, and stochastic differential equations through unified interfaces.
`HydroModels.jl` [@jing2025hydromodels] demonstrates compositional hydrological modelling with differentiable neural-enhanced components, whilst `SpeedyWeather.jl` uses an interactive domain-specific language (a programming language tailored to a specific application domain that uses terminology and concepts familiar to domain experts rather than general programming constructs) approach for "LEGO-like" atmospheric modelling with modular component assembly [@speedyweather2024].
The key insight underlying these approaches is the separation of structural syntax, which defines valid compositions, from computational semantics, enabling modularity and independence of components whilst maintaining mathematical rigour.

This paper presents a prototype that combines the modularity of pipeline approaches with the statistical rigour of joint models through composable epidemiological components.
Our approach enables "LEGO-like" model decisions through standardised interfaces similar to those used in `SpeedyWeather.jl` [@speedyweather2024].
The prototype supports composability beyond ordinary differential equations, accommodating mixed equation types and the potential for different computational backends.
We implement this as a domain-specific language operating intended to be implemented as optional package extensions [@juliapackageextensions].
We demonstrate our approach using an autoregressive model example to illustrate the proposed compositional pattern and component swapping capabilities.
Through three case studies using the prototype, we show how components can be reused across different models: the first is inspired by @mishra2020covid; the second reuses components from the first, along with new elements, inspired by @epinow2; the third is inspired by @chatzilena2019contemporary, again reusing components, alongside the use of an ODE.
Finally, we discuss alternative design approaches, evaluate the strengths and limitations of our compositional approach, and identify key areas for future development.

# Prototype Implementation {#sec-approach}

## Requirements for Composable Infectious Disease Modelling {#sec-requirements}

Modelling infectious disease dynamics requires quantifying uncertainty at every level because decisions must account for incomplete knowledge about individual infection risk, transmission dynamics, and observation processes.
A clear separation between distinct model components, infection processes, observation processes, and latent dynamics is also key as these allows reasoning on each of these components separately.
Because diseases affect populations heterogeneously across age, location, and risk groups, the framework needs to be able to support arbitrary stratification schemes for all components.
These stratified models must also remain data-agnostic as this allows the model to be generalised to different datasets, tested based on just its prior specification, and used for forecasting.
Similarly, the book work of supporting multiple strata needs to be abstracted from the user to make the system easier to use but at the same time they need to be able to model relationships between strata to support partial pooling of parameters for sparse data settings.
To allow for models to be validated, the framework must support nesting models within models and programming over model structure itself, allowing simple components to compose into sophisticated models while remaining individually interrogable for debugging, validation, and mechanistic understanding.
Model specifications must serve dual purposes, supporting both forward simulation for prior predictive checks and forecasting, and inference when conditioned on observed data, without requiring separate implementations.
This compositional approach requires a clear, concise modelling language so that it can be used by a wide pool of users and so that model specifications can be written quickly but with clarity.
Supporting modern inference methods is important so that complex models can be fit and this necessitates gradient computation throughout via automatic differentiation.
It is also important to allow for a wide range of inference methods so that the best approach for a given model/data combination can be used.
This means supporting abstract back-ends that seamlessly switch between inference approaches.

We also need to have model components that encapsulate both structure and prior distributions so that domain experts can contribute specialised knowledge: a virologist's understanding of within-host dynamics, an epidemiologist's of contact patterns, a clinician's of disease progression insights without reviewing the entire modelling framework.
Standardised interfaces between components are needed to allow individual components to work together, to support handling of multiple strata, and to allow for proper uncertainty propagation.
Such interfaces also enable large language models to serve as model construction agents, composing models from component libraries whilst validation methods ensure statistical rigour [@aygun2025ai].
As there are a range of different potential ways to express infectious disease models including ordinary differential equations, agent-based models, network models, stochastic processes, and discrete time models these all need to be supported both independently and in combination.
Importantly, the design must enable incremental adoption without requiring complete rebuilds of existing models, and components should remain functional as standalone tools outside the compositional framework to maximise their utility and adoption.
Finally, we need a framework that can be composed with out of domain approaches and expertise, such as neural networks, Gaussian processes, and other machine learning approaches.

## Our approach {#sec-design}

Meeting these requirements requires programming with probabilities, for which probabilistic programming languages are designed.
We also need a probabilistic programming language that supports automatic differentiation for modern inference, the ability to program over model structure itself to enable model nesting and composition, and access to as wide an ecosystem as possible to avoid lock-in and enable integration with existing scientific computing tools.
As far as we are aware, only probabilistic programming languages built in Julia [@Julia-2017] provide the metaprogramming capabilities needed to create domain-specific abstractions that can handle arbitrary stratification, standardised interfaces between components, and programming over the model structure.
Metaprogramming is the ability to write code that generates or manipulates other code, enabling the creation of custom domain-specific syntax and automated code transformations.
Among Julia's options, `Turing.jl` [@fjelde2025turin] best meets our requirements with mature submodel support for nesting models within models, extensive inference algorithm choices, and its implementation as a light abstraction layer (a simplified interface that hides complex implementation details whilst enabling access to underlying functionality) on top of the wider Julia ecosystem.
Additional benefits of Julia include eliminating the two-language problem, leveraging multiple dispatch (programming paradigm where function behaviour is determined by the types of all arguments rather than just the first, enabling automatic selection of the most specific implementation for given inputs) for clean component composition, and accessing the mature SciML ecosystem [@SciML] for differential equations and other scientific computing tools.

Our approach uses a two-layer architecture with a high-level domain-specific language for epidemiological modelling and a low-level implementation using `Turing.jl`.
Though importantly we are not locked in to this choice as the DSL is agnostic of the backend used.
This separation enables incremental adoption without rebuilding existing models to use our DSL, with all components remaining functional as standalone tools outside the compositional framework.
The domain-specific language layer provides clear, concise model specification using epidemiological concepts, enabling domain experts to contribute components encapsulating their specialised knowledge without understanding the low-level details of all framework elements.
The backend layer aims to handle the automated bookkeeping of stratification, interface validation, and uncertainty propagation whilst supporting multiple inference approaches and auto differentiation options by leveraging the `Turing.jl` and wider Julia ecosystems.
This structure enables integration of diverse data sources by allowing researchers to add a submodel with its own latent and observation process to an existing model, for example adding wastewater measurements to a case-based renewal model or clinical biomarkers to transmission dynamics without modifying the core infection model.

To demonstrate cross-ecosystem accessibility, we also developed EpiAwareR [@EpiAwareR], an R interface to the prototype using JuliaCall [@JuliaCall].
This enables R users to access the compositional modelling framework without requiring Julia programming knowledge.

@fig-composable demonstrates how these compositional principles could enable component reuse across different epidemiological applications.
Three example applications wastewater surveillance, biomarker modelling, and early outbreak analysis each compose models from components of different types.
The schematic also highlights two examples of component reuse.
The incubation period model appears in all three applications, and the within-host viral kinetics model is shared between biomarker modelling and wastewater surveillance.
This highlights how components developed for one application could be incorporated into others when they share common underlying processes.

```{mermaid}
%%| label: fig-composable
%%| fig-cap: "Demonstration of composability showing how three applications share common components. Colours correspond to component types: infection processes (blue), statistical processes (orange), infection modifiers (yellow), epidemiological latent processes (purple), observation modifiers (red), and observation models (green). Two shared submodels are highlighted with purple borders and background fill: the Incubation Period model (reused across all applications) and the Within-host Viral Kinetics model (shared between Biomarker Modelling and Wastewater Surveillance)."
%%|
%%| fig-width: 10

%%{init: {'theme': 'base', 'themeVariables': {'fontSize': '14px', 'fontFamily': 'arial'}, 'flowchart': {'diagramPadding': 60, 'htmlLabels': true, 'curve': 'basis', 'padding': 25}}}%%
flowchart TB
    %% Class definitions
    classDef infection fill:#9fc5e8,stroke:#333,stroke-width:1px,color:black
    classDef observation fill:#b6d7a8,stroke:#333,stroke-width:1px,color:black
    classDef statistical fill:#ff9900,stroke:#333,stroke-width:1px,color:black
    classDef epiLatent fill:#d5a6bd,stroke:#333,stroke-width:1px,color:black
    classDef infectionModifier fill:#ffd966,stroke:#333,stroke-width:1px,color:black,shape:hexagon
    classDef observationModifier fill:#ff9999,stroke:#333,stroke-width:1px,color:black,shape:hexagon
    classDef observationModel fill:#b6d7a8,stroke:#333,stroke-width:1px,color:black,shape:doubleoctagon
    classDef economic fill:#d0e0e3,stroke:#333,stroke-width:1px,color:black
    classDef behavioural fill:#b4a7d6,stroke:#333,stroke-width:1px,color:black
    classDef application fill:#ea9999,stroke:#333,stroke-width:1px,color:black
    classDef title fill:none,stroke:#333,stroke-width:1px,color:black,font-weight:bold
    classDef strata stroke:#666,stroke-width:1px,stroke-dasharray:5 5,font-size:20px, fill:none,color:black
    classDef sharedModel stroke:#6600cc,stroke-width:3px,stroke-dasharray:5 5,fill:#f3e5f5,color:black

    %% Legend at the top
    subgraph Legend[" "]
        direction LR
        Legend_Title["Legend: "]:::title
        Legend_Infection["Infection Process"]:::infection
        Legend_Statistical["Statistical Model"]:::statistical
        Legend_ObservationModel["Observation Model"]:::observationModel
        Legend_ObservationModifier["Observation Modifier"]:::observationModifier
        Legend_EpiLatent["Epidemiological Latent Process"]:::epiLatent
        Legend_SharedModel["Shared Model"]:::sharedModel
    end

    %% Top row: Applications
    subgraph TopRow[" "]
        direction LR

        %% Early Outbreak Analysis
        subgraph EarlyOutbreak[" "]
            direction LR
            EOA_Title["Early Outbreak Analysis (WP4a)"]:::title
            EOA_GP["Gaussian Process"]:::statistical
            EOA_RP["Renewal Process"]:::infection
            EOA_Infections["Infections"]
            EOA_IncubationRef["Incubation Period"]:::sharedModel
            EOA_RD["Reporting Delay"]:::observationModifier
            EOA_Asc["Ascertainment"]:::observationModifier
            EOA_RT["Right Truncation"]:::observationModifier
            EOA_OM["Case Reports"]:::observationModel

            %% Connections
            EOA_GP -.-> EOA_RP
            EOA_RP ==> EOA_Infections
            EOA_Infections --> EOA_IncubationRef
            EOA_IncubationRef --> EOA_RD
            EOA_RD --> EOA_Asc
            EOA_Asc --> EOA_RT
            EOA_RT --> EOA_OM
        end

        %% Within-host Biomarker Modelling
        subgraph BiomarkerModelling[" "]
            direction LR
            BM_Title["Biomarker Modelling (WP4b.i)"]:::title
            BM_RP["Renewal Process"]:::infection
            BM_Infections["Infections"]
            BM_ViralKineticsRef["Viral Kinetics"]:::sharedModel
            BM_IncubationRef["Incubation Period"]:::sharedModel
            BM_VL["Viral Load"]:::epiLatent
            BM_OM1["PCR Testing"]:::observationModel
            BM_OM2["Symptom Onset Data"]:::observationModel

            %% Connections
            BM_RP ==> BM_Infections
            BM_Infections --> BM_ViralKineticsRef
            BM_Infections --> BM_IncubationRef
            BM_ViralKineticsRef --> BM_VL
            BM_VL --> BM_OM1
            BM_IncubationRef --> BM_OM2
        end

    %% Wastewater Analysis
    subgraph Wastewater[" "]
        direction LR
        WW_Title["Wastewater Surveillance (WP4b.ii)"]:::title

            WW_RP["Renewal Process"]:::infection
            WW_Infections["Infections"]
            WW_IncubationRef["Incubation Period"]:::sharedModel
            WW_ViralKineticsRef["Viral Kinetics"]:::sharedModel
            WW_Shedding["Viral Shedding"]:::epiLatent
            WW_EnvDeg["Environmental Decay"]:::observationModifier
            WW_RD["Reporting Delay"]:::observationModifier
            WW_Asc["Ascertainment"]:::observationModifier
            WW_RT["Right Truncation"]:::observationModifier
            WW_OM1["Wastewater Signal"]:::observationModel
            WW_OM2["Case Reports"]:::observationModel

            %% Connections
            WW_RP ==> WW_Infections
            WW_Infections --> WW_ViralKineticsRef
            WW_Infections --> WW_IncubationRef
            WW_ViralKineticsRef --> WW_Shedding
            WW_Shedding --> WW_EnvDeg
            WW_EnvDeg --> WW_OM1
            WW_IncubationRef --> WW_RD
            WW_RD --> WW_Asc
            WW_Asc --> WW_RT
            WW_RT --> WW_OM2
        end
    end

    %% Bottom row: Shared Models
    subgraph BottomRow[" "]
        direction LR

        %% Shared Incubation Period Model
        subgraph SharedIncubation[" "]
            direction TB
            SIP_Title["Shared Incubation Period Model"]:::title
            SIP_Infections["Infections"]
            SIP_Delay["Delay"]:::observationModifier
            SIP_Ascertainment["Ascertainment"]:::observationModifier
            SIP_Onset["Symptom Onset"]:::observationModel

            %% Internal connections
            SIP_Infections --> SIP_Delay
            SIP_Delay --> SIP_Ascertainment
            SIP_Ascertainment --> SIP_Onset
        end

        %% Shared Viral Kinetics Model
        subgraph SharedViralKinetics[" "]
            direction TB
            SVK_Title["Shared Viral Kinetics Model"]:::title
            SVK_Infection["Infection Time"]
            SVK_VL["Viral Load Trajectory"]:::epiLatent
            SVK_Peak["Peak Viral Load"]:::epiLatent
            SVK_Shedding["Viral Shedding"]:::epiLatent

            %% Internal connections
            SVK_Infection --> SVK_VL
            SVK_VL --> SVK_Peak
            SVK_VL --> SVK_Shedding
        end
    end

    %% Style for legend
    style Legend fill:#f5f5f5,stroke:#333,stroke-width:1px,color:black,padding:10px

    %% Style for main sections
    style TopRow fill:none,stroke:none
    style BottomRow fill:none,stroke:none

    %% Style for application subgraphs
    style EarlyOutbreak fill:none,stroke:#333,stroke-width:1px,color:black,padding:15px
    style BiomarkerModelling fill:none,stroke:#333,stroke-width:1px,color:black,padding:15px
    style Wastewater fill:none,stroke:#333,stroke-width:1px,color:black,padding:15px

    %% Style for shared model subgraphs (highlighted with purple border and light fill)
    style SharedIncubation fill:#f3e5f5,stroke:#6600cc,stroke-width:2px,stroke-dasharray:5 5,color:black,padding:15px
    style SharedViralKinetics fill:#f3e5f5,stroke:#6600cc,stroke-width:2px,stroke-dasharray:5 5,color:black,padding:15px
```

## Domain-Specific Language Structure {#sec-dsl}

<!-- Reference to Panel A of Figure 1 -->

Our prototype domain-specific language builds on Julia's type system to enable composable epidemiological modelling through two key design patterns.
First, abstract types define interfaces that implementations must follow, analogous to contracts specifying what operations a model component must support rather than how it implements them.
All model components inherit from a parent `AbstractModel` type, establishing a common foundation whilst allowing specialised behaviour through subtypes.
Second, structures (data containers that group related variables and their types together) contain other structures as fields, a struct-in-struct pattern that allows complex models to be built by nesting simpler components.
This pattern enables models to be assembled like building blocks whilst maintaining clear boundaries between different epidemiological processes.

We organise model components into three abstract type hierarchies, each of which inherits from `AbstractModel`, corresponding to distinct epidemiological processes.
`AbstractEpiModel` represents infection generation processes such as renewal models or ordinary differential equation transmission dynamics.
`AbstractLatentModel` captures time-varying parameters and unobserved processes such as changing reproduction numbers or reporting rates, implemented through structures like autoregressive processes, random walks, or moving averages.
`AbstractObservationModel` links latent states to observed data by encoding measurement processes such as reporting delays, aggregation over time periods, and observation error distributions.
These structures are data-agnostic, specifying what to do when they encounter data rather than containing data themselves, making model definitions reusable across different datasets and scenarios.
Each hierarchy supports multiple concrete implementations that can be swapped to compare modelling assumptions whilst keeping other components fixed.

Models can compose across these hierarchies rather than being restricted to combining components within a single type.
For example, an observation model can contain a latent process as a field to represent time-varying ascertainment, or wrap another observation model to add reporting delays.
This cross-hierarchy composition extends the building block analogy to include more complex models.
For instance, we can construct a delay convolution observation model, `LatentDelay`, using an underlying observation model and a delay distribution model.

The `EpiProblem` structure is a top-level container assembling these components into a complete epidemiological model.
It holds an infection process (`epi_model`), a latent process (`latent_model`), an observation process (`observation_model`), and a time span for inference or simulation.
The latent model generates time-varying epidemiological parameters, the infection model uses these parameters to simulate disease transmission and generate infections, and the observation model links these latent infections to observed data through measurement processes.
However, this is just the top-level structure: each submodel can itself contain any of these abstract types, enabling flexible composition such as observation models that include latent processes for time-varying ascertainment.
Structures can be modified in place using tools like `Accessors.jl`, enabling both model iteration and patterns such as partially pooled models that update low-level priors based on grouping structures.
The abstract type system enables shared methods across all model components, such as print methods (shown below) for displaying model specifications or functions for visualising model directed acyclic graphs.
This approach also allows for the creation of mappings between submodels such as one to one, one to many, and many to many mappings so that, for example, a single infection process can be linked to multiple observations models by specifying a mapping model.

<!-- Reference to Panel B of Figure 1 -->

To demonstrate the structure and use of `AbstractLatentModels`, we start with an autoregressive order two (AR(2)) process, which mathematically is:

$$Z_t = \rho_1 Z_{t-1} + \rho_2 Z_{t-2} + \epsilon_t, \quad \epsilon_t \sim \text{Normal}(0, \sigma)$$

In our prototype DSL, this is defined using the `AR` struct.
We use priors inspired by @mishra for illustration.
Prior distributions are specified using `Distributions.jl` [@JSSv098i16], the standard probability distributions package in the Julia ecosystem, which provides a unified interface for probability distributions that is interoperable with both our framework and `Turing.jl`.

```{julia}
#| output: false
using EpiAware, Distributions
ar2 = AR(;
    damp_priors=[truncated(Normal(0.2, 0.2), 0, 1),
        truncated(Normal(0.1, 0.05), 0, 1)],
    init_priors=[Normal(0, 0.2), Normal(0, 0.2)],
    ϵ_t=HierarchicalNormal(std_prior=HalfNormal(0.1))
)
```

This constructor has created the following struct definition.

```{julia}
#| output: true
ar2
```

Prior samples from this model are shown in @fig-arima A.
Another common latent model is the moving average model

$$Z_t = \epsilon_t + \theta \epsilon_{t-1}, \quad \epsilon_t \sim \text{Normal}(0, \sigma)$$

The `MA` struct defines this in the same way that the `AR` did for the AR process.

```{julia}
#| output: false
ma1 = MA(;
    θ_priors=[truncated(Normal(0.0, 0.2), -1, 1)],
    ϵ_t=HierarchicalNormal(std_prior=HalfNormal(0.1))
)
```

Prior samples from this process are shown in @fig-arima B.
A popular combination of these models is the autoregressive moving average (ARMA) model that can have different orders for both the AR and MA components.
An ARMA(2,1) can be defined as:

$$Z_t = \rho_1 Z_{t-1} + \rho_2 Z_{t-2} + \epsilon_t + \theta \epsilon_{t-1}$$

In our DSL this can be represented as a composition of the AR and MA structs by updating the AR error term:

```{julia}
#| output: false
using Accessors
arma21 = @set ar2.ϵ_t = ma1
```

The result of this step has been to update the `ar2` struct so that the definition of the moving average model is nested inside it. 

```{julia}
#| output: true
arma21
```

The combined model dynamics are shown in @fig-arima C.
Similarly, autoregressive integrated moving average (ARIMA) models extend ARMA by adding differencing operations that transform the series

$$\Delta Z_t = Z_{t} - Z_{t-1}$$

So that the ARIMA(2,1,1) model is defined as an ARMA(2,1) model for the first order differences:

$$\Delta Z_t = \rho_1 \Delta Z_{t-1} + \rho_2 \Delta Z_{t-2} + \epsilon_t + \theta \epsilon_{t-1}$$

We compose the ARMA model with a differencing operation using the `DiffLatentModel` wrapper:

```{julia}
#| output: false
arima211 = DiffLatentModel(arma21, Normal(0, 0.2); d=1)
```

Prior samples from the full model are shown in @fig-arima D.
Alternatively, EpiAware provides an `arima()` constructor function that simplifies this specification.

Other latent models extend modelling options through combining models additively, multiplicative scaling, and piecewise processes.
This approach enables representation of arbitrary latent processes through composition.

<!-- -->

## Backend Implementation: Turing Interface {#sec-backend}

<!-- Reference to Panel D of Figure 1 -->

Our DSL translates to Turing models through generate functions that dispatch on abstract type hierarchies.
Each abstract type (`AbstractLatentModel`, `AbstractEpiModel`, `AbstractObservationModel`) has a generate function interface that concrete model types must implement a method to dispatch upon.
When a generate function receives a model component, Julia's multiple dispatch automatically selects the appropriate implementation based on the component's type, producing `Turing.jl` [@fjelde2025turin] code using the `@model` macro.
Unit tests are used to ensure concrete implementations satisfy interface requirements, enabling all components to interoperate correctly regardless of which specific model types are composed together.
This approach means new model types integrate seamlessly without modifying existing code, and users can swap components to compare modelling assumptions whilst keeping other parts of the model fixed.

The generated Turing models serve dual purposes: simulation by sampling from prior distributions, or inference by conditioning on observed data and applying Turing's suite of algorithms including gradient-based methods like the No U-Turn Sampler (NUTS) [@hoffman2014nuts].
These are standard Turing models with no special constraints beyond those imposed by the `Turing.jl` framework itself, supporting all `DynamicPPL.jl` operations such as parameter fixing, model conditioning, and posterior predictive sampling.
Generated components can be used directly as standalone models or nested within other Turing models using the `@submodel` macro, enabling incremental adoption where only parts of a model use the compositional framework whilst other parts use custom `Turing.jl`.

Many computational components are backend-agnostic, containing no probabilistic programming constructs and therefore portable to other frameworks.
For example, we use a common pattern, `accumulate_scan`, which builds on the base accumulate function to model iterative temporal processes through step functions.
These step functions are structs built on the `AbstractAccumulationStep` interface that implement a callable (a struct that can be invoked like a function) defining the single-step update rule.
Mathematical utilities such as functions for converting between reproduction numbers and growth rates, discretising continuous delay distributions, and reparameterising observation error models are similarly backend-agnostic.
This separation enables a package extension pattern where standard Julia packages provide domain-specific functionality whilst the compositional layer is added as an optional extension, allowing users to adopt the framework incrementally without requiring their entire workflow to commit to the compositional approach.

Returning to our example from the DSL section, the autoregressive process can be mapped from its high-level representation to a Turing model using the `generate_latent` function and multiple dispatch, which generates the following `Turing.jl` model:

```{julia}
#| output: false
#| echo: false
using CodeTracking, Revise
```

```{julia}
#| echo: false
#| output: asis
println("```julia")
print(@code_string EpiAwareBase.generate_latent(ar2, 50))
println("\n```")
```

The key line `@submodel ε_t = generate_latent(latent_model.ε_t, n - p)` enables composition by delegating to whatever error model was provided. The AR dynamics are implemented through a custom accumulation step that maintains the autoregressive state.
```{julia}
#| echo: false
#| output: asis
println("```julia")
print(@code_string EpiLatentModels.ARStep([1, 2, 1])(1, 1))
println("\n```")
```

This step function works with `accumulate_scan` to build the AR series by applying the autoregressive equation at each time step.
The MA model has a similar structure with its own internal step function.
The `accumulate_scan` pattern enables composable iteration steps, allowing complex processes like renewal models with susceptible depletion to be built by composing simple step operations.
This design means we only need to write the single-step operation without worrying about the iteration process, making components more modular and reusable.

The full ARIMA(2,1,1) model we defined in the DSL section can then be generated using the same approach, producing the following `Turing.jl` model:

```{julia}
#| echo: false
#| output: asis
println("```julia")
print(@code_string generate_latent(arima211, 50))
println("\n```")
```

The DiffLatentModel's `@submodel diff_latent = generate_latent(latent_model.model, n - d)` calls the ARMA model, which in turn calls its composed AR and MA components, then applies differencing through cumulative summing.
This recursion through `@submodel` enables arbitrary composition while maintaining separation between components.

To demonstrate fitting these submodels we first create a model that uses our ARIMA(2,1,1) model as submodel combining it with a Poisson observation model.
The Poisson distribution is a simple count likelihood commonly used for epidemiological data.
We use the log-parameterised `LogPoisson` distribution which means we are modelling the growth rate using our ARIMA process.

```{julia}
#| output: false
using DynamicPPL, Turing

@model function arima_with_obs(arima_spec, n_timesteps)
    @submodel Z_t = generate_latent(arima_spec, n_timesteps)
    y_obs ~ product_distribution(LogPoisson.(Z_t))
    return y_obs
end
```

We can then generate synthetic data with fixed parameters which we sample from the prior distribution using the `rand`, and `fix` functions and calling the model to simulate the observations. We first define the model.

```{julia}
#| output: false
n_timesteps = 40
gen_model = arima_with_obs(arima211, n_timesteps)
```

Then sample from it,

```{julia}
#| output: false
simulated_params = rand(gen_model)
```

Now we have parameters we can simulated some data using the generative model by fixing the random variables using the sampled parameters and the `fix` function. We can then call it, like any normal function, to get simulated observations for `y`.

```{julia}
#| output: false
fixed_model = fix(gen_model, simulated_params)
y_observed = fixed_model()
```

For inference, we condition on the generative model using simulated observations and the  `condition` function or here the equivalent `|` notation. Now we have a model conditioned on data we can fit it using our choice of approach supported by `Turing.jl`. Here we decide to use the No-U-Turn Sampler (NUTS) [@hoffman2014nuts], a popular variant of MCMC.

```{julia}
#| output: false
#| julia:
#|   cache:
#|     enabled: true
conditioned_model = gen_model | (; y_obs = y_observed)
chains = sample(conditioned_model, NUTS(), MCMCThreads(), 2000, 4)
```

We can then compare our posterior distributions to the true sampled values from our ARIMA(2, 1, 1) model using `PairPlots.jl` [@PairPlots.jl] with the `CairoMakie.jl` [@DanischKrumbiegel2021] backend for visualisation (@fig-arima E).
The posterior distributions recover the simulated parameter values.

```{julia}
#| output: false
#| echo: false
using PairPlots, CairoMakie

function latent_sample_plot!(ax, latent_mdl; n_samples=100)
    samples = mapreduce(hcat, 1:n_samples) do _
        latent_mdl()
    end
    for col in eachcol(samples)
        lines!(ax, col, color=(:grey, 0.1))
    end
    return nothing
end

function plot_fit_with_truth(fig_position, chain, truth, params)
    params_with_names = mapreduce(param -> namesingroup(chain, param), vcat, params)
    filtered_chains = chain[params_with_names]
    filtered_truth = reduce(vcat, truth[params])
    filtered_truth = Dict(
        zip(params_with_names, reduce(vcat, truth[params]))
    )
    pairplot(fig_position,
        filtered_chains,
        PairPlots.Truth(filtered_truth, label="True Values")
    )
end
```

```{julia}
#| echo: false
#| label: fig-arima
#| fig-cap: "Prior predictive samples and posterior inference for latent time series models. (A) AR(2) process showing autoregressive dynamics. (B) MA(1) process showing moving average behaviour. (C) ARMA(2,1) combining AR and MA components. (D) ARIMA(2,1,1) with differencing. (E) Posterior density for ARIMA(2,1,1) parameters showing pairwise relationships between AR damping coefficients and MA coefficient, with true parameter values (blue) used to generate synthetic data."
fig_arima = let
    n_samples = 100
    n_timesteps = 20

    # Generate latent models
    ar_mdl = generate_latent(ar2, n_timesteps)
    ma_mdl = generate_latent(ma1, n_timesteps)
    arma_mdl = generate_latent(arma21, n_timesteps)
    arima_mdl = generate_latent(arima211, n_timesteps)

    fig = Figure(size=(1600, 800))

    # Row 1: Prior predictive samples (left 4 panels)
    ax_ar = Axis(fig[1, 1]; ylabel="Zₜ")
    ax_ma = Axis(fig[1, 2])
    ax_arma = Axis(fig[2, 1]; ylabel="Zₜ", xlabel="Time")
    ax_arima = Axis(fig[2, 2]; xlabel="Time")

    # Prior predictive plots
    latent_sample_plot!(ax_ar, ar_mdl; n_samples)
    latent_sample_plot!(ax_ma, ma_mdl; n_samples)
    latent_sample_plot!(ax_arma, arma_mdl; n_samples)
    latent_sample_plot!(ax_arima, arima_mdl; n_samples)

    # Sync y-axis limits across all prior predictive panels
    limits = (-1.5, 1.5)
    Makie.ylims!(ax_ar, limits)
    Makie.ylims!(ax_ma, limits)
    Makie.ylims!(ax_arma, limits)
    Makie.ylims!(ax_arima, limits)

    # Pairs plot spanning right 4 panels (columns 3-4, rows 1-2)
    params = [:damp_AR, :ar_init, :θ]
    plot_fit_with_truth(fig[1:2, 3:4], chains, simulated_params, params)

    # Add panel labels
    for (label, layout) in zip(["A", "B", "C", "D", "E"],
        [fig[1, 1], fig[1, 2], fig[2, 1], fig[2, 2], fig[1:2, 3:4]])
        Label(layout[1, 1, TopLeft()], label,
            fontsize=18,
            font=:bold,
            padding=(0, 5, 5, 0),
            halign=:right)
    end

    fig
end

save("figures/fig-arima.pdf", fig_arima)
save("figures/fig-arima.png", fig_arima)

fig_arima
```


# Case Studies {#sec-case-studies}

We demonstrate how our prototype compositional modelling DSL can recreate and extend existing epidemiological models through three case studies: "On the derivation of the renewal equation from an age-dependent branching process" [@mishra2020covid], "EpiNow2: Estimate Real-Time Case Counts and Time-Varying Epidemiological Parameters" [@abbott-epinow2-wellcomeopenres], and "Contemporary statistical inference for infectious disease models using Stan" [@chatzilena2019contemporary].
Each case study shows how complex models are built by composing reusable components (@fig-case-studies), with full implementation details provided in the Supplementary Information.
The first two case studies have been replicated using the EpiAwareR R interface [@EpiAwareR], demonstrating cross-ecosystem accessibility.

All code and data for reproducing the analyses are available at: [https://github.com/EpiAware/PrototypeCompositionalProbablisticInfectiousDiseaseModelling](https://github.com/EpiAware/PrototypeCompositionalProbablisticInfectiousDiseaseModelling).

```{mermaid}
%%| label: fig-case-studies
%%| fig-cap: "Model structure for the ARIMA example and three case studies showing component reuse. The ARIMA Example panel shows how AR(2) and MA(1) components compose into ARIMA(2,1,1) with Exp transformation and Poisson observation. Mishra et al. reuses the AR(2) component for modelling time-varying Rt combined with a Renewal infection process and Negative Binomial observation. EpiNow2 extends this by reusing the full ARIMA structure with weekly broadcasting, adding Latent Delay for reporting delays and day-of-week ascertainment effects. Chatzilena et al. demonstrates an alternative infection process using a SIR ODE with Softplus transformation, scaled by population size N, and AR(1)-based time-varying ascertainment. Dashed arrows indicate component reuse. Colours indicate component types: statistical models (orange), infection processes (blue), epidemiological parameters (purple), observation modifiers (red), broadcasting operations (peach), transformations (white), and observation models (green)."
%%| fig-width: 10

%%{init: {'theme': 'base', 'themeVariables': {'fontSize': '14px', 'fontFamily': 'arial'}}}%%
flowchart LR
    %% Class definitions
    classDef infection fill:#9fc5e8,stroke:#333,stroke-width:1px,color:black
    classDef statistical fill:#ff9900,stroke:#333,stroke-width:1px,color:black
    classDef epiLatent fill:#d5a6bd,stroke:#333,stroke-width:1px,color:black
    classDef observationModifier fill:#ff9999,stroke:#333,stroke-width:1px,color:black
    classDef observation fill:#b6d7a8,stroke:#333,stroke-width:1px,color:black
    classDef broadcast fill:#ffe6cc,stroke:#333,stroke-width:1px,color:black
    classDef transform fill:#ffffff,stroke:#333,stroke-width:1px,color:black

    %% Panel B: Case Study 1 - Mishra
    subgraph B["Mishra et al."]
        direction TB
        B_Exp["Exp"]:::transform
        B_Rt["Rt"]:::epiLatent
        B_GT["Generation Time"]:::epiLatent
        B_Renewal["Renewal"]:::infection
        B_Infections["Infections"]
        B_Obs["Negative Binomial"]:::observation

        B_Exp --> B_Rt
        B_Rt --> B_Renewal
        B_GT --> B_Renewal
        B_Renewal --> B_Infections
        B_Infections --> B_Obs
    end

    %% Panel C: Case Study 2 - EpiNow2
    subgraph C["EpiNow2"]
        direction TB
        C_Broadcast["Broadcast"]:::broadcast
        C_Weekly["Weekly"]:::broadcast
        C_Exp["Exp"]:::transform
        C_Rt["Rt"]:::epiLatent
        C_GT["Generation Time"]:::epiLatent
        C_Renewal["Renewal"]:::infection
        C_Infections["Infections"]
        C_Delay["Delay"]:::epiLatent
        C_LatentDelay["Latent Delay"]:::observationModifier
        C_RE["Random Effect"]:::statistical
        C_AscBroadcast["Broadcast"]:::broadcast
        C_AscDaily["Daily"]:::broadcast
        C_Obs["Negative Binomial"]:::observation

        C_Broadcast --> C_Weekly
        C_Weekly --> C_Exp
        C_Exp --> C_Rt
        C_Rt --> C_Renewal
        C_GT --> C_Renewal
        C_Renewal --> C_Infections
        C_Infections --> C_LatentDelay
        C_Delay --> C_LatentDelay
        C_LatentDelay --> C_AscBroadcast
        C_RE --> C_AscBroadcast
        C_AscBroadcast --> C_AscDaily
        C_AscDaily --> C_Obs
    end

    %% Panel D: Case Study 3 - Chatzilena et al.
    subgraph D["Chatzilena et al."]
        direction TB
        D_SIR["SIR ODE"]:::infection
        D_Incidence["Incidence"]
        D_N["N"]:::epiLatent
        D_Softplus["Softplus"]:::transform
        D_ScaleN["Scale by N"]:::observationModifier
        D_AR["AR(1)"]:::statistical
        D_Exp["Exp"]:::transform
        D_Ascertainment["Ascertainment"]:::observationModifier
        D_Obs["Poisson"]:::observation

        D_SIR --> D_Incidence
        D_Incidence --> D_Softplus
        D_Softplus --> D_ScaleN
        D_N --> D_ScaleN
        D_ScaleN --> D_Ascertainment
        D_AR --> D_Exp
        D_Exp --> D_Ascertainment
        D_Ascertainment --> D_Obs
    end

    %% Panel A: ARIMA Construction
    subgraph A["ARIMA Example"]
        direction LR
        A_AR["AR(2)"]:::statistical
        A_MA["MA(1)"]:::statistical
        A_ARMA["ARMA"]:::statistical
        A_DIFF["Differencing"]:::statistical
        A_ARIMA["ARIMA"]:::statistical
        A_Exp["Exp"]:::transform
        A_Obs["Poisson"]:::observation

        A_AR --> A_ARMA
        A_MA --> A_ARMA
        A_ARMA --> A_DIFF
        A_DIFF --> A_ARIMA
        A_ARIMA --> A_Exp
        A_Exp --> A_Obs
    end

    %% Cross-panel connections showing component reuse
    A_AR -.-> B_Exp
    A_ARIMA -.-> C_Broadcast

    %% Style panels
    style A fill:#f9f9f9,stroke:#333,stroke-width:1px
    style B fill:#f9f9f9,stroke:#333,stroke-width:1px
    style C fill:#f9f9f9,stroke:#333,stroke-width:1px
    style D fill:#f9f9f9,stroke:#333,stroke-width:1px
```

## On the derivation of the renewal equation from an age-dependent branching process: an epidemic modelling perspective {#sec-example1}

*Mishra et al.* [@mishra2020covid] estimate time-varying effective reproduction numbers ($R_t$, the average number of secondary infections caused by an infected individual at time $t$) from case data by combining the renewal equation with a negative binomial observation model.

Our replication composes an AR(2) latent process for log $R_t$ (reusing the AR component from @fig-case-studies), a renewal infection process [@cori2013new] using a discretised serial interval distribution [@wallinga2007generation], and a negative binomial observation model for case counts.
We use `AR` to generate the latent log $R_t$ trajectory, `Renewal` to compute expected infections via the renewal equation $I_t = R_t \sum_{s} g_s I_{t-s}$, and `NegativeBinomialError` to link expected infections to observed cases with overdispersion.
We assemble these components and use Pathfinder [@zhang2022pathfinder] to initialise NUTS sampling.

@fig-mishra shows model components and posterior analysis.
Panels A-C demonstrate prior predictive checks for each component in isolation: the AR(2) latent process for log $R_t$, the renewal model for latent infections, and the negative binomial observation model.
Panel D compares the continuous serial interval distribution with its discretised form.
Panels E-F show posterior predictive distributions for daily cases and time-varying $R_t$, recovering the main finding that $R_t$ in South Korea peaked at approximately 10 before rapidly dropping below 1 in early March 2020.

![Model components and posterior analysis for Case Study 1. (A) Prior samples from the AR(2) latent process for log $R_t$ over 50 days. (B) Prior samples from the renewal model conditional on a fixed $R_t$ trajectory. (C) Prior samples from the negative binomial observation model around a latent infection curve. (D) Comparison of the continuous serial interval distribution with its discretised pmf. (E) Posterior predictive distribution for daily cases with 50% and 95% credible intervals. (F) Posterior predictive distribution for time-varying $R_t$ on a log scale.](figures/fig-mishra){#fig-mishra width=100%}

## EpiNow2: Estimate Real-Time Case Counts and Time-Varying Epidemiological Parameters {#sec-example2}

`EpiNow2` [@abbott-epinow2-wellcomeopenres] is a widely used package for real-time situational awareness in infectious disease surveillance, estimating case counts and epidemiological parameters whilst accounting for reporting delays, right-truncation, and day-of-week effects.

Our replication reuses the ARIMA(2,1,1) and negative binomial components from the main text and @sec-example1 (as shown in @fig-case-studies), extending them with piecewise constant weekly $R_t$ values, incubation period and reporting delay convolutions [@charniga2024best], and day-of-week reporting effects.
Unlike @sec-example1 which uses the serial interval, this case study uses the generation time distribution; whilst serial intervals are often used as a proxy, this can be problematic [@park2023inferring] and is primarily done when generation time estimates are unavailable [@zhao2020preliminary].
We use `broadcast_weekly` to convert the ARIMA(2,1,1) process to piecewise constant weekly $R_t$ values, `LatentDelay` to convolve latent infections with incubation period and reporting delay distributions, and `ascertainment_dayofweek` to multiply expected observations by day-of-week effects via a softmax transformation.

@fig-epinow2 shows model components and posterior analysis.
Panels A-C show prior predictive checks for the piecewise constant weekly ARIMA process, the renewal model, and the composite observation model with delays and day-of-week effects.
Panel D displays the incubation period and reporting delay distributions.
Panels E-F show posterior predictive distributions, demonstrating that the model explicitly accounts for reporting delays whilst recovering similar $R_t$ dynamics to @sec-example1.

![Model components and posterior analysis for Case Study 2. (A) Prior samples from the piecewise constant by week ARIMA(2,1,1) latent process. (B) Prior samples from the renewal model. (C) Prior samples from the composite observation model including delays and day-of-week effects. (D) Incubation period and reporting delay distributions. (E) Posterior predictive distribution for daily cases. (F) Posterior predictive distribution for time-varying $R_t$.](figures/fig-epinow2){#fig-epinow2 width=100%}

## Contemporary statistical inference for infectious disease models using Stan {#sec-example3}

In _Contemporary statistical inference for infectious disease models using Stan_, *Chatzilena et al.* [@chatzilena2019contemporary] demonstrate Bayesian inference for compartmental disease models.
We recreate the single strain influenza example using data from @jombart2020outbreaks, introducing the SIR model as an alternative infection generating process to the renewal model used in the previous case studies (@fig-case-studies).
We compose an SIR compartmental model using `ODEProcess` from the SciML ecosystem [@rackauckas2017differentialequations], demonstrating two observation models: a deterministic model with direct Poisson link, and a stochastic model using `Ascertainment` for time-varying effects parameterised as an AR(1) process (equivalent to the time-discretised Ornstein-Uhlenbeck process used by *Chatzilena et al.*).
The aim of the stochastic component is to absorb noise generated by model mis-specification, improving robustness when the SIR model is an approximation to more complex transmission dynamics.
A softplus transformation ensures numerical stability when the ODE solver returns small negative values near zero.

@fig-sir shows model components and posterior analysis.
Panels A-B demonstrate prior predictive checks for the SIR dynamics and stochastic observation model including time-varying ascertainment.
Panel C compares posterior $R_0$ distributions, with both models recovering $R_0 \approx 2$, consistent with *Chatzilena et al.*
Panels D-F show posterior compartment trajectories and predictive cases.
The deterministic model posterior predictive trajectories (@fig-sir E) appear less well calibrated than those from the stochastic model (@fig-sir F), with several data points falling outside the 95% prediction envelopes.
This indicates that the flexible observation model compensates for potential misspecification in the deterministic model.

![Model components and posterior analysis for Case Study 3. (A) Prior SIR trajectories showing S (blue), I (red), R (green) compartment dynamics. (B) Prior samples from the stochastic observation model including time-varying ascertainment and Poisson sampling around a latent infection curve. (C) Posterior $R_0$ distributions comparing deterministic (blue) and stochastic (orange) models. (D) Posterior compartment trajectories for deterministic model. (E) Posterior predictive cases for deterministic model, with median (purple line) and 50% (dark ribbon) and 95% (light ribbon) credible intervals compared to observed data (black points). (F) Posterior predictive cases for stochastic model.](figures/fig-sir){#fig-sir width=100%}

# Discussion {#sec-discussion}

This paper has demonstrated that compositional approaches can address barriers in epidemiological modelling.
We presented a prototype that enables "LEGO-like" model construction, maintaining the statistical rigour of joint models whilst providing the flexibility of pipeline approaches.
The autoregressive model example illustrated how complex models emerge from simple component combinations using the struct-in-struct pattern (where structures, data containers that group related variables and their types together, contain other structures as fields to build complex models by nesting simpler components).
Our three case studies, which were based on previous studies [@mishra2020covid; @epinow2; @chatzilena2019contemporary], demonstrate model composability for a range of problems and using different underlying methods.

<!-- Strengths and weaknesses interwoven -->

A strength of our prototype approach is its modular design, which enables faster model development and component reuse, whilst also facilitating comparison of modelling assumptions without large reimplementation efforts.
The approach reduces implementation barriers for methodological advances and enables researchers to embed new components within existing models more easily.
For instance, adding a new data source such as wastewater surveillance to an existing case-based model requires only defining a wastewater submodel with its own latent and observation process, avoiding the need to reimplement the existing infection, latent, and observation models.
This modularity also enables interdisciplinary collaboration.
Domain experts such as virologists, clinicians, or environmental scientists can contribute specialised components encoding their knowledge without needing to understand the full modelling framework or probabilistic programming details.
The EpiAwareR R interface [@EpiAwareR] demonstrates that our frameworks can bridge software ecosystems.
Similar interfaces could be built for other languages using existing Julia bridges such as JuliaCall [@PythonCall.jl] for Python.
Standardised interfaces should also allow large language models to compose models programmatically with validation methods ensuring correctness.
However, a clear limitation is that this is just a prototype and not designed for ongoing use or adoption.
For example, we only partially implemented support for automated mappings between latent and observed states, which remains challenging to do well.
Similarly, we only added partial support for partial pooling approaches with no infrastructure in place to support users in using this functionality in our DSL layer.
The current component library also remains limited to basic epidemiological patterns.
Finally, the current struct manipulation tooling cannot coordinate updates of related parameters such as model order and corresponding priors, without manual intervention, requiring either avoiding this pattern or developing additional solutions.
Whilst the prototype implementation has limitations, the three real-world case studies presented here establish the viability of compositional approaches for practical epidemiological problems.
On top of this, we have laid the groundwork for future work and given clear requirements that future composable frameworks should seek to meet to address the needs of applied infectious disease modelling.
Another limitation is the learning curve required for researchers familiar with monolithic approaches to adopt this compositional paradigm.
However, as they can embed elements of our system within their existing models and as they can implement their own compositional elements with minimal understanding of the overall architecture these barriers to use should be mitigated. 
Computational overhead from abstraction layers is also a concern; the impact of this overhead and potential optimisations remains unclear.
However, `Turing.jl` [@fjelde2025turin] and Julia [@Julia-2017] are well-positioned for optimisation with new automatic differentiation backends like Enzyme [@moses2020enzyme] and Mooncake [@dalle2025differentiationinterface], which could reduce computational costs in future implementations.
Similarly, ongoing work in the `Turing.jl` ecosystem should be able to identify and resolve any performance bottlenecks that do emerge.
A strength of the Julia [@Julia-2017] ecosystem for compositional work is that domain experts develop specialised tools that interoperate through shared interfaces.
However, this distributed development also creates challenges as it can be difficult to locate appropriate tools and unclear where responsibility lies when issues emerge.
Users may not know whether problems originate in `Turing.jl`, our prototype DSL, or elsewhere in the ecosystem, and even once located, it can be difficult to determine who is responsible for resolving them.
There are also additional technical barriers within the `Turing.jl` ecosystem.
The Turing PPL DSL is not fully stable and since developing this prototype, the `@submodel` macro has changed syntax and become a function with breaking changes in how it handles prefixes and in how it manages variables within a submodel, meaning our current prototype implementation is not compatible with the latest `Turing.jl` release.
However, some of these changes do allow for potentially more flexible models as they reduce the difference between specifying something as a distribution and as a submodel.
Other recent changes in `Turing.jl`, such as the primary workflow for observed data being to condition and fix with no argument for observations, impact how data is conditioned on the model. This means not having to pass observations through layers of the model, making it easier to build composable models.
Further flexibility in conditioning on submodels at the `Turing.jl` level could simplify our DSL layer or enable new workflows, such as fixing the infection process to known values whilst inferring observation model parameters.
`Turing.jl` also has limited handling of numerical instability, and so things like large counts being simulated can cause errors, which makes evaluating and developing models frustrating.
An advantage of the Julia [@Julia-2017] ecosystem for a composable modelling tool built on top of a PPL is access to the full features of a programming language.
However, in practice, some of these utilities, such as profiling tools, can be frustrating and difficult to use with `Turing.jl` when compared to similar tools offered in other ecosystems because the probabilistic programming language abstractions and macro expansions obscure the relationship between source code and runtime behaviour, making it challenging to identify performance bottlenecks in model components.
The ecosystem needs further development in areas such as debugging tools that can trace through model execution whilst preserving the semantic structure of probabilistic models, better error messages that relate numerical issues to model specification rather than low-level implementation details, and standardised approaches for model validation and testing.
The `EpiMethod` approach for chaining inference (combining pre-sampling like Pathfinder [@zhang2022pathfinder] with sampling like the No U-Turn Sampler (NUTS) [@hoffman2014nuts]) shows promise but should be a `Turing.jl` general solution rather than epi-specific because many domains face similar challenges of difficult posterior geometries where adaptive warmup strategies could improve both efficiency and reliability of inference across the broader probabilistic programming ecosystem.
<!-- Comparison to literature - Algebraic Julia -->

Our prototype could draw more heavily on category theory [@fong2018seven], which provides formal mathematical foundations for composability.
This theory enables automatic modifications to the model when changes are made to underlying components.
The AlgebraicJulia ecosystem demonstrates how category theory can be operationalised in software, with `AlgebraicPetri.jl` [@libkind2022algebraic] and `AlgebraicDynamics.jl` [@libkind2021operadic] implementing operadic composition through structured cospans and wiring diagrams [@vagner2014algebras].
These provide multiple interchangeable representations of model components as open Petri nets, with connection "ports" allowing composability with other components via "junction" porting [@libkind2022algebraic].
Another symbolic-numeric approach to defining dynamical systems, `ModelingToolkit.jl` [@modelingtoolkit2021] and `Catalyst.jl` [@loman2023catalyst] from the SciML ecosystem [@SciML], allow for acausal component-based models which achieve performance improvements through automated parallelisation, sparsity detection, and equation simplification.
`AlgebraicPetri.jl` uses the direct association between Petri nets and reaction networks [@baez2017compositional] to link the graphical/algebraic representation of the model to its computational semantics via `ModelingToolkit.jl` [@modelingtoolkit2021] and `Catalyst.jl` [@loman2023catalyst], allowing models composed using this approach access to the SciML ecosystem.
However, all of these tools are currently designed for representing the generators of dynamical systems and do not naturally extend to general probabilistic models.
Our probabilistic programming foundation offers more direct support for statistical inference and uncertainty quantification, supports a broader range of modelling approaches, but lacks the formal compositional guarantees of category theory approaches and automated optimisations of symbolic-numeric frameworks.
The SIR model in @sec-example3 uses a complete ODE specification, but more complex compartmental models could be composed from reusable reaction components using `AlgebraicPetri.jl` or `Catalyst.jl`, with our approach managing the probabilistic aspects such as priors and observation models.

<!-- Comparison to literature - Other approaches -->

Alternative probabilistic programming languages could support similar compositional approaches.
`Gen.jl` [@cusumanotowner2019gen] focuses on lower-level implementation of probabilistic programs compared to `Turing.jl`, with composition support through nested generative function calls and combinators of generative functions.
However, `Gen.jl` operates more independently from the broader Julia ecosystem, maintaining its own distribution types rather than using `Distributions.jl` [@JSSv098i16], which negates a key strength of Julia approaches where packages interoperate through shared interfaces.
Despite this, Gen-based tools demonstrate useful functionality for epidemiological modelling, such as `AutoGP.jl` [@saad2023sequential], which implements real-time inference and automated composition of Gaussian process kernels that could be useful for modelling time-varying epidemiological parameters.
Genify [@tan2021genify] provides an approach that translates Julia code into Gen models, potentially easing adoption by allowing modellers to write in familiar Julia syntax whilst accessing Gen's programmable inference capabilities.
Python-based probabilistic programming languages such as NumPyro [@phan2019composable] and Oryx [@oryx2020] built on JAX [@jax2018github] could enable similar composability [@pyrenew2024, @coix2024], with potential advantages from JAX's focus on efficiency and GPU scaling.
However, the smaller JAX-specific ecosystem compared to general Python packages, JAX's optimisation for neural network tasks, and Python PPLs' more programmer-oriented syntax that diverges from mathematical notation may create barriers for epidemiological modellers.
As well as imperative probabilistic programming languages (specifies how to perform computations through explicit sequences of commands) such as `Turing.jl`, there are declarative graph-based approaches (specifies what should be computed by stating relationships and constraints) available such as `JuliaBUGS.jl` [@sun2024juliabugs] and `RxInfer.jl` [@bagaev2023rxinfer] where users specify directed graphical models by explicitly stating conditional dependencies between variables.
This graph-based representation offers several advantages including clearer understanding of dependencies, more transparent model structure and assumptions, and efficient inference through algorithms that leverage the model's graphical structure to identify conditional independence relationships.
However, the declarative approach trades off the flexibility of `Turing.jl`'s imperative style, which allows procedural code, such as a loop over recursive updates for a dynamical system, that can be more expressive for certain complex modelling patterns.
Building a domain-specific backend on `Distributions.jl` rather than `Turing.jl` could enable compatibility with multiple PPLs including `JuliaBUGS.jl` whilst trading off `Turing.jl`'s expressive submodel interface.

<!-- Future work -->

Areas for future work include expanding the component library to address epidemiological applications across multiple scales and data types.
More work is also needed to allow for modifying deeply nested model specifications without the user needing to be aware of the structure of the nested model.
Methodological advances are also needed including for the joint estimation of interdependent epidemiological parameters, and then integration of individual and population-level observations.
Alternative approaches also need to investigated, particularly more formal category theory based methods that use operadic composition for mathematically rigorous hierarchical model construction, as demonstrated in `AlgebraicPetri.jl` and `AlgebraicDynamics.jl` [@libkind2022algebraic].
Symbolic-numeric frameworks like `ModelingToolkit.jl` [@modelingtoolkit2021] and `Catalyst.jl` [@loman2023catalyst] offer potential performance improvements through automatic optimisation and code generation.
However, these approaches require generalisation to explicitly model probabilities and support a range of different modelling approaches which are both needed for infectious disease modelling applications.
An alternative potential abstraction approach would be to build the domain-specific language on `Distributions.jl` rather than `Turing.jl`, which would enable compatibility with multiple probabilistic programming languages like `JuliaBUGS` whilst trading off the expressiveness of Turing's submodel interface.
Further investigation of `Gen.jl` [@cusumanotowner2019gen], Genify [@tan2021genify], and `JuliaBUGS.jl` [@sun2024juliabugs] is needed, as Gen's programmable inference capabilities and tools like `AutoGP.jl` [@saad2023sequential] may overcome some limitations of `Turing.jl`, Genify's metaprogramming bridge could ease adoption by allowing modellers to write familiar Julia code, and JuliaBUGS's graph-based approach could enable more efficient inference through explicit model structure.
Performance optimisation through parallelisation and approximate inference methods will be needed for practical adoption.
Ongoing work on compiling Julia applications to standalone executables could enable interfaces in other languages with fewer dependencies.
The compositional framework creates opportunities for large language model integration.
Language models could serve as model construction agents, using a composable framework to construct epidemiological models from component libraries [@aygun2025ai].
The explicit structure and validation tools of a composable framework should enable language models to reason about model design and propose structural adaptations more easily and with less room for error.
The high-level component interface could also reduce context and reasoning requirements by allowing language models to compose models without understanding backend details such as `Turing.jl` syntax, distribution parameterisations, or inference algorithm specifications, potentially enabling deployment of smaller models on local compute in resource-constrained settings.
Further work is needed to realise this potential.

<!-- Conclusions -->

A complete implementation of the prototype we present here could improve real-time analysis of infectious disease dynamics by enabling "LEGO-like" assembly of epidemiological components.
This prototype establishes the feasibility of integrating diverse expertise whilst maintaining statistical rigour, addressing limitations of current modelling approaches.
By lowering technical barriers, compositional frameworks could enable interdisciplinary teams to contribute directly to model development rather than relying on modellers to translate their knowledge.
Such frameworks are also likely key for enabling, and increasing the robustness of, large language model assisted model construction, especially in resource-constrained settings where such capabilities could prove most valuable.
Given the unpredictable nature of future infectious disease threats such adaptable modelling capabilities that can incorporate diverse data sources and domain expertise are needed for future public health decision making.

## Acknowledgements {.appendix}

We thank the epiforecasts team for helpful comments and suggestions.
We thank Poppy for growling as needed.

## Data and Software Availability {.appendix}

All code and data for reproducing the analyses are available at: [https://github.com/EpiAware/PrototypeCompositionalProbablisticInfectiousDiseaseModelling](https://github.com/EpiAware/PrototypeCompositionalProbablisticInfectiousDiseaseModelling).

## Funding Information {.appendix}

We acknowledge the financial support from CDC Grant NU38FT00008 (K.J., S.A, S.F.).
This project was made possible by cooperative agreement CDC-RFA-FT-23-0069 from the CDC's Center for Forecasting and Outbreak Analytics.
Its contents are solely the responsibility of the authors and do not necessarily represent the official views of the Centers for Disease Control and Prevention.
We acknowledge the financial support from Wellcome 210758/Z/18/Z (S.F.).

## AI Disclosure {.appendix}

Claude Sonnet 4.5 (https://www.anthropic.com/claude/sonnet) and Claude Opus 4.5 (https://www.anthropic.com/claude/opus) were used to assist with preparation of the manuscript text and as part of code review for the EpiAware and EpiAwareR packages and the analysis applying them to the case studies presented here.

# References {.unnumbered}

::: {#refs}
:::
